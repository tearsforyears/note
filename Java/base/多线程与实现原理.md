# 多线程

---

[TOC]



## 文档使用说明

---

java的多线程内容十分庞大从原理到理解到实现到应用学习曲线都是非常不稳定的,因此拆分成以下部分

-   java线程的基础认识,分析手段(线程状态,创建和使用,jstack日志,JOL包)
-   多线程的重要特性(原子性,可见性,重排序)
-   jvm多线程实现基础 (CPU三级缓存,内存屏障,缓存行,CPU乱序执行,sychronized的实现,volidate的实现,字节码执行)
-   锁的分类和理解实现 (乐观锁/悲观锁,独享锁/共享锁,互斥锁/读写锁,可重入锁,公平锁/非公平锁,分段锁,偏向锁/轻量级锁/重量级锁,自旋锁,分布式锁)
-   多线程的底层机制 (CAS,AQS,锁的升级过程)
-   实现多线程的应用 (java.util.concurrent,hashmap等JUC容器,线程池,读写模式)

在理解的过程中发现应该拆分成以下几个方向去理解,仅供参考

-   java与原生多线程 wait notify synchronized volatile 
-   jvm与硬件实现 操作系统 原语 内存屏障 缓存行 锁升级过程
-   JUC包实现 C++的unsafe AQS JUC工具 线程池

需要注意的是上面的各个部分的知识相互缠绕攀升,并无绝对分立



## jvm与内存结构

此章主要讲jvm的内存结构以及一些机制,如果不熟悉jvm的话在jvm的学习结束之前不要学习多线程原理相关的知识,分析多线程堆栈锁结构的时候会有相应的阻碍,本章已经在另一jvm文档详细说明了

### JVM普通内存结构

---

#### jvm内存结构

**heap 用于存放process级别数据** class内的变量等 new 出来的变量等 数组等

这一区域在jdk1.8前后发生了很大的变化谨慎起见下面的结构都是1.8以前的

**stack 存放thread/function级别数据** 局部变量操作数栈动态链接方法出口

-   vm stack虚拟机栈 线程私有,即对应thread级别的数据,一个线程的局部变量等
-   local method 本地方法栈 顾名思义是临时的方法调用所使用的栈

**方法区 process级数据** 常量池 static变量区 **类接口等加载**

**navtive 方法区 global级别数据** 被jvm环境使用 存放c++实现的方法 主要针对字节码操作

![](https://s2.ax1x.com/2019/05/26/VECQk4.png)

**pc程序计数器** 这个记载着每条指令的字节码地址,如果是本地方法则为空

更为详细的数据结构如下

![](https://img2018.cnblogs.com/blog/645365/201905/645365-20190515062344241-2072850649.png)



---

#### jdk1.7升级到1.8内存区域的变化

![](https://img-blog.csdnimg.cn/20190305150132242.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTk4MDEx,size_16,color_FFFFFF,t_70)



### JMM内存模型

---

即多线程下内存模型 java memory model 我们要研究的主体为线程堆栈(thread stack)

#### 线程栈 Thread Stack

线程栈对于其他线程是不可见的,包含了线程的局部变量等

进程的栈和线程的栈也是不互通的 只有堆中的局部变量能够进行互相访问

而且堆中的内存都是拷贝的线程的栈中才能进行使用的

![JMM内存结构示意图](https://upload-images.jianshu.io/upload_images/15168036-12ead20bc89a8e9b.png)

**如果有对JVM的具体认识的话,上述图可以表达为方法区(元空间)和堆内存线程间共享,对于其他每个线程而言其有独立的stack**

-   方法区一般是常量池,static变量,和类的元信息(还有ClassLoader)
-   堆是需要new出来的对象

### 对象结构与锁

从jvm中我们知道锁的实现和对象的内存结构有关系

![](https://img-blog.csdnimg.cn/20190115141050902.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NDRE5fQ1A=,size_16,color_FFFFFF,t_70)

而markword是线程中控制锁的区域,markword各位置表达的意思如下

![](https://img-blog.csdnimg.cn/20190111092408622.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdWR1bl9jb29s,size_16,color_FFFFFF,t_70)

markword涉及到锁的升级过程,上面偏向锁`thread:54`指的是54位用于指向偏向的线程,`biased_lock`用于标志是否为偏向锁,`epoch`用于表示偏向锁的时间戳,关于markword和锁的升级过程在后续说明,此数据结构非常重要

而当我们开启了` -XX:+UseCompressedOops`会采用32位的Klass指针

而markword是8Byte(64位)无法压缩,如上





## java 多线程基础

---

这一章讲多线程的基本操作和常识性的问题



### 线程安全问题

要保证线程安全就要考虑以下3个特性,这三个问题就是多线程最重要的特点

1.  原子性 在java中主要是锁机制 可以用原语或其他机制实现
2.  可见性 final volatile **内存屏障** **脏读问题** 
3.  有序性 **happen-before原则** **重排序**

 

### 常用线程安全集合

collections中的数据结构例如hashtable vector之类的是线程安全的,但是其实现的时候是通过锁住操作来完成的,效率低下,而concurrent包中的线程对此进行了改进,故优先使用,以下是我们平时会用到的一些数据结构

| interface | non-thread-safe         | concurrent-thread-safe                   | collections-thread-safe |
| --------- | ----------------------- | ---------------------------------------- | ----------------------- |
| List      | ArrayList               | CopyOnWriteArrayList                     | Vector(弃用)            |
| Map       | HashMap                 | ConcurrentHashMap                        | HashTable(弃用)         |
| Set       | HashSet / TreeSet       | CopyOnWriteArraySet                      |                         |
| Queue     | ArrayDeque / LinkedList | ArrayBlockingQueue / LinkedBlockingQueue |                         |
| Deque     | ArrayDeque / LinkedList | LinkedBlockingDeque                      |                         |



### 创建线程

```java
new Thread(()->{System.out.print(Thread.currentThread().getName())}).start();
```

-   线程对象

    线程对象我们相当于声明了一个对象,在调用`start()`方法之前系统只是在堆中创建了这么一个相应的数据结构(在方法区和堆中有相应的数据结构),而执行还得交由系统fork

-   线程

    和操作系统线程一致,为运行中的程序拥有`PCB`接受CPU调度

#### 继承Thread类

```java
class MyThread extends Thread{
  @Override
  public void run() {
    System.out.println("hello Thread");
  }
}
@Test
public void test(){
  new MyThread().start();
}
```

#### 实现Runnable接口

```java
class MyThread2 implements Runnable {
  @Override
  public void run() {
    System.out.println("hello Thread 2");
  }
}

@Test
public void test() {
  new Thread(new MyThread2()).start(); // 这方法有点扑街
}
```

#### ExecutorService接口的execute和submit

```java
ExecutorService service = Executors.newScheduledThreadPool(4);
for (int i = 0; i < 200; i++) {
  service.submit(() -> {
    System.out.println("hello " + Thread.currentThread().getName());
  });
}
```

#### 关于Runnable和Callable

两者都是用于实现任务的接口 不同的是Runnable接口为没有返回值的接口 对应线程池中的execute方法 而Callable是有返回值的方法 通过拿到future对象可以获取返回值

#### 总结

可以看到创建线程是比较简单的,本质上都是借助了Thread的run方法,在堆内存和方法区中声明了相应的内存区域



### CPU核心与I/O性能

这里主要讨论I/O与线程切换之间的性能问题.

#### 单核心结构

**cpu是单核心**线程切换无非就是保存断点然后不断中断在往复,这样一来线程切换的意义仅在于切换速度让人无法感知,其实带来了大量的性能浪费(浪费在保存中断现场上),这样挂起的I/O操作切换的意义就没有了,因为I/O的进行仍然需要CPU的处理数据到内存**(于是人们发明了DMA技术)**使得这样的线程切换也存在对I/O进行加速的意义.另外一提DMA技术的出现使得I/O多路复用,java的nio等技术的出现得奠定了硬件基础

#### 多核心结构

SMP架构就是典型的多核心结构,其让线程能真正意义的在多核上运行,实现真正的并行,而不单纯是并发.对于传统的阻塞I/O,完全可以开启另一线程让CPU核心去等待I/O,本CPU核心完成剩下的计算.使得效率大大提高,另外配合线程池技术可以使得CPU利用率大大增加,如果有大量I/O开启,仍然可借助**DMA**技术使得性能进一步优化



### 线程的分析手段

线程的分析手段可以作为学习多线程的一个手段或者工具来了解线程的状态,我们这里介绍两种常见的手段

#### jstack

在jvm的调试中 `jstack <pid>`配合`jps`使用可以调试线程,是启动了个JUnit和线程池的测试程序,我们来分析下有用的片段

```java
public class createThread {
    @Test
    public void test() throws Exception{
        ScheduledExecutorService service = 
          Executors.newScheduledThreadPool(4);
        for (int i = 0; i < 200; i++) {
            service.submit(() -> {
                System.out.println("hello " + 
                                   Thread.currentThread().getName());
            });
        }
    }
}
```

我们利用jps和jstack找到相应的`<pid>`就可以分析日志了

```shell
"pool-1-thread-1" #11 prio=5 os_prio=31 tid=0x00007f82400c9800 nid=0x5903 waiting on condition [0x0000700008b56000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x000000076b33ee60> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
```

为了找寻这些对象我们看到下放的调用栈就可以知道对象`<0x000000076b33ee60>`

可能还需要用到`jmap -dump:live,format=b,file=dump.bin`和`jhat`来找到分析对象的内存状态

这个命令在服务器上debug一些线程的状态特别好用

除了三种阻塞状态,创建停止,运行就绪之外我们还有一些其他的状态或语句

-   **Deadlock** 死锁
-   **Waiting on condition** 等待某个条件或者资源来唤醒(比如sleep)
-   **Waiting on monitor entry** 等待获取锁
-   **in Object.wait()** 获取锁后又执行obj.wait()放弃锁

-   tid 线程id
-   nid 映射到系统的线程id

死锁和waiting很可能会是造成系统性能瓶颈的原因之一,stack trace的时候可以关注着之间的代码

#### VisualVM

这是一种简单的工具让我们来分析多线程的走向,其能看到线程的状态对象的情况,学习期间可以采用debug一步步分析线程在这中的进行和线程状态,图形化界面比较简单不再赘述

#### *idea debugger

idea的debugger是个相当好用的工具,无论是普通的debug还是多线程的debug这里我们讲多线程的debug方法

IDEA的debugger在默认是阻塞所有线程的,也就是说必须等debug走完,代码才会执行,我们在view breakpoints->suspend中选择Thread,然后我们在`Frames`选项卡中可以选择不同的栈帧进行调试,线程出现waiting状态时会显示`Frames not available for unsuspended thread`切换栈帧即可



#### JOL包

```xml
<!-- JOL对象分析工具 -->
<dependency>
  <groupId>org.openjdk.jol</groupId>
  <artifactId>jol-core</artifactId>
  <version>0.14</version>
</dependency>
```

常用的方法

```java
ClassLayout.parseInstance(obj).toPrintable(); // 打印实例内部的结构和占用大小
GraphLayout.parseInstance(obj).toPrintable(); // 查看类引用的对象
GraphLayout.parseInstance(obj).totalSize(); // 查看实例空间的总大小
```

我们用其打印一个hashmap如下,64位下,因为开启的压缩,所以是4

| OFFSET | SIZE | TYPE                 | DESCRIPTION        | VALUE       |
| ------ | ---- | -------------------- | ------------------ | ----------- |
| 0      | 4    |                      | (object header)    | 01 00 00 00 |
| 4      | 4    |                      | (object header)    | 00 00 00 00 |
| 8      | 4    |                      | (object header)    | a8 37 00 f8 |
| 12     | 4    | java.util.Set        | AbstractMap.keySet | null        |
| 16     | 4    | java.util.Collection | AbstractMap.values | null        |
| 20     | 4    | int                  | HashMap.size       | 2           |

......还有hashmap的其他成员变量

同理我们可以用其来分析线程结果结果如下

```shell
java.lang.Thread object internals:
 OFFSET  SIZE                                        TYPE DESCRIPTION                               VALUE
      0     4                                             (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)
      4     4                                             (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)
      8     4                                             (object header)                           7a 0d 00 f8 (01111010 00001101 00000000 11111000) (-134214278)
     12     4                                         int Thread.priority                           5
     16     8                                        long Thread.eetop                              0
     24     8                                        long Thread.stackSize                          0
     32     8                                        long Thread.nativeParkEventPointer             0
     40     8                                        long Thread.tid                                14
     48     4                                         int Thread.threadStatus                       0
     52     1                                     boolean Thread.single_step                        false
     53     1                                     boolean Thread.daemon                             false
     54     1                                     boolean Thread.stillborn                          false
     55     1                                             (alignment/padding gap)                  
     56     4                            java.lang.String Thread.name                               (object)
     60     4                            java.lang.Thread Thread.threadQ                            null
     64     4                          java.lang.Runnable Thread.target                             null
     68     4                       java.lang.ThreadGroup Thread.group                              (object)
     72     4                       java.lang.ClassLoader Thread.contextClassLoader                 (object)
     76     4          java.security.AccessControlContext Thread.inheritedAccessControlContext      (object)
     80     4        java.lang.ThreadLocal.ThreadLocalMap Thread.threadLocals                       null
     84     4        java.lang.ThreadLocal.ThreadLocalMap Thread.inheritableThreadLocals            null
     88     4                            java.lang.Object Thread.parkBlocker                        null
     92     4                    sun.nio.ch.Interruptible Thread.blocker                            null
     96     4                            java.lang.Object Thread.blockerLock                        (object)
    100     4   java.lang.Thread.UncaughtExceptionHandler Thread.uncaughtExceptionHandler           null
    104   128                                             (alignment/padding gap)                  
    232     8                                        long Thread.threadLocalRandomSeed              0
    240     4                                         int Thread.threadLocalRandomProbe             0
    244     4                                         int Thread.threadLocalRandomSecondarySeed     0
    248     0                                             (loss due to the next object alignment)
Instance size: 376 bytes
Space losses: 129 bytes internal + 0 bytes external = 129 bytes total
```

从上面我们可以看到锁的一些信息,可以更快的确定问题所在

若要分析其markword的锁信息参考下图和数据

![](https://img-blog.csdnimg.cn/20190111092408622.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdWR1bl9jb29s,size_16,color_FFFFFF,t_70)

```shell
# 加了锁之后
10 a9 a2 08 (00010000 10101001 10100010 00001000) (144877840)
00 70 00 00 (00000000 01110000 00000000 00000000) (28672)
# 其在内存中的由于大端存储的缘故,其真正的表示是
# 0x00 00 70 00 08 a2 a9 10 后三位是 0b00010*000* 即轻量级锁

# 没加锁
01 00 00 00 (00000001 00000000 00000000 00000000) (1)
00 00 00 00 (00000000 00000000 00000000 00000000) (0)
# 0x 00 00 00 00 00 00 00 01 后三位是 0b00000*001* 即无锁(偏向锁是101)
```

这里涉及到大端存储和小段存储,正确的解析是大端,如此一来便可以通过分析markword的瞬时状态来观测线程的状态



### 线程的状态

---

![线程状态](https://img-blog.csdn.net/2018070117435683?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BhbmdlMTk5MQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

-   正在执行(Running) # 系统I/O属于正在执行状态(BIO)
-   就绪(Ready) # yield() 系统调度
-   不同的阻塞 
    -   阻塞(Blocked) # 等待进入synchronized
    -   等待(Waiting) # wait() **join()** LockSupport.park()
    -   超时等待(Timed_waiting) # wait(long) sleep(long) join(long) parkUntil() parkNanos()
-   新建(New)
-   终止(Terminate)

而对于操作系统层面看到的可能就不是如此了

![](https://static.oschina.net/uploads/img/201612/14203516_znrd.png)

如上图,在jvm中`BLOCKED`,`RUNNABLE`,`WAITING`,`TIMED_WATING`都可能是在操作系统阻塞的线程

下列代码中`Thread`代表Thread类,`thread`代表Thread实例,obj同

```java
thread.start() 
// 加入jvm等待就绪队列 并不会立即执行 等待main线程执行结束之后
Thread.yield() // 让步 放入就绪队列队尾 要慎重使用 因为有准备时间 所以实际是running一会在回到就绪队列的慎用
Thread.sleep() // Time_waiting

synchronized(this){ // 获得堆中对象
  obj.wait() 
  // 释放锁对象 可传入参数 在参数的时间结束后开始等待
  // 可带参数 100 意味着100ms之后可以被notify
  // 当前线程释放该对象的锁,与该线程持有的其他对象无关
	// 随后该线程进入等待队列或者同步队列(看有无在次获取锁)
  obj.notify() 
  obj.notifyAll() // 唤醒所有想持有该对象的线程(同步队列的所有线程)
}
```

wait()的执行原理如下

![](https://img-blog.csdn.net/20180701221233161?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BhbmdlMTk5MQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

我们可以看到wait与当前线程有关和调用wait的对象有关,其实现为上图的等待队列和同步队列,配合后文中synchronized关键字获得的对象的锁,可以分析其代码所要完成的东西

```java
int i = 0; // 堆区共享数据 mutex
public void fun1(){
  synchronized(this){ // 获得当前对象的锁(使用权)
    if(i==0){
      // 操作1
    }
    i = 1;
    this.notifyAll(); 
    // 通知其他持有该对象锁(使用权)的线程(同步队列的所有线程)可以使用该对象了
  }
  // 释放了对象的锁
}
public void fun2(){
  synchronized(this){
    if(i!=0){
    	this.wait(); // 该线程等待其他线程使用 释放锁(使用权)
    }
  }
}
```

```java
otherThread.join()
// 当前线程调用其他线程实例的join(),当前线程进入waiting状态,而不是该对象的线程waiting
// 下方的wait的思路是这个join()的核心,平常我们可以认为是当前线程的一个让权函数
// join()方法原本的含义是等待otherThread执行完毕在执行接下来的代码
// join(1000) 表示等待其他线程执行1s后并发执行接下来的代码
  public final synchronized void join(long millis) throws InterruptedException{
  long base = System.currentTimeMillis();
  long now = 0;

  if (millis < 0) {
    throw new IllegalArgumentException("timeout value is negative");
  }

  if (millis == 0) {
    while (isAlive()) { // 如果(t1.join()的t1)线程还活着的话
      wait(0); 
			// 直接使用wait在同步代码块里,而同步的普通方法锁的是当前线程的实例对象
      // wait方法是当前线程释放持有的线程的实例对象
      // 当该方法被调用的时候当前线程(比如main),先获得实例的锁,然后在释放实例的锁
      // 随后进入等待队列或同步队列(看是否在次获取锁)
    }
  } else {
    while (isAlive()) {
      long delay = millis - now;
      if (delay <= 0) {
        break;
      }
      wait(delay);// 当前线程释放锁,其他线程(t1.join()的t1线程)获得锁和cpu使用权
      now = System.currentTimeMillis() - base;
    }
  }
}
```

### 线程的执行逻辑

线程的执行逻辑和操作系统一致,有等待队列有CPU时间片使用权等等,对java而言main函数本质上就是一个线程 而非进程,进程可视作jvm管理资源

每个线程执行之后会释放自己所持有的锁 同时this.notifyAll() 此处this指代线程对象

也就是说,释放本线程对象的锁(释放资源) 其他线程如果有等待该线程则会被notifyAll通知到

### ***synchronized关键字***

---

synchronized 关键字时java多线程中比较重要的东西 其可以实现原子性和可见性 可用于代替下面的volatile关键字

synchronized 保证代码块或者方法在运行时 同一时刻**只有一个对象(不是一个线程)可以进入到临界区**，同时它还可以保证共享变量的内存可见性

我们说的加了线程获取了对象的锁(使用权) 持有该对象的其他线程必须等待,synchronized关键字只是把对象的锁注入进了当前线程中仅此而已

1.  ### 普通同步方法（实例方法），锁是当前实例对象 ，进入同步代码前要获得当前实例的锁

2.  ### 静态同步方法，锁是当前类的class对象 ，进入同步代码前要获得当前类对象的锁

3.  ### 同步方法块，锁是括号里面的对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁

从上面三条性质不难看出实例方法由实例(堆)调用,要获得实例的锁,而静态方法由实例和类名调用,类名即是调用的本质,所以要获得类的对象(堆)的锁,而同步方法块是我们平时用的最多的,我们可以手动指定线程要获取堆中哪个对象的锁.

简单点来讲就是 我们想阻断i++交替访问 直接在方法上加锁就可以了

#### 普通方法加synchronized关键字

```java
public class synctest extends Thread{
    static int im = 0;

    @Override
    public synchronized void run() {
        for (int i = 0; i < 10000; ++i) {
            im++;
        }
      	System.out.println(im); 
      // 最后输出结果不是20000 但加上sync关键字后就变成了20000
      // 其原因就在于对对象加了锁 意味着只有一个对象能调用此函数
      // 我们也可以对static加锁 那就是对Class的对象加锁 一个
    }

    public static void main(String[] args) throws InterruptedException {
        synctest s1 = new synctest();
        Thread t1 = new Thread(s1);
      	Thread t2 = new Thread(s1); // 因为是普通方法所以引用得一样
        s1.start();
        s2.start();
    }
}
```

如果一个类中有两个不同的同步方法 必须等待其中一个执行完之后才能执行第二个

因为虽然说都是同一个类的不同方法但都获取了对象的锁 所以没办法实现 并发

这个就体现出该关键字设计的臃肿了 当然 也只有同步方法会要求锁 普通方法还是随意使用

**所以普通方法的关键点就是获取实例对象的锁 相同实例对象持有相同的锁 不同实例对象持有不同的锁**

#### 静态方法加synchronized关键字

```java
public static void main(String[] args) throws InterruptedException {        
  Thread t2 = new Thread(()->{
    for (int i = 0; i < 10000; i++) {
      stMethodTest.ins();
    }
  });
  Thread t1 = new Thread(()->{
    for (int i = 0; i < 10000; i++) {
      stMethodTest.ins();
    }
  });
  t1.start();
  t2.start();
  t1.join(); // 主线程进入等待/阻塞 子线程开始执行 
  t2.join(); // 主线程进入等待 子线程开始执行
  System.out.println(stMethodTest.i); 
  // 不会是20000 而加上sync关键字之后 只要是调用该(同一)类的方法(不是对象)就
  // 就会被阻塞 直到前一个类退出临界区为止
}
class stMethodTest{
    static int i=0;
    static void ins(){
        i++;
    }
}
```

可以看见 其因为持有类对象的锁所以并发性进一步减小 显得臃肿

#### 同步代码块

如果在一个大方法内执行全部同步代码显得操作及其耗时耗力 所以只用一小部分代码完成同步就可以实现并发了 基于这个思想 java有了同步代码快的机制 其可以写在方法里

```java
public void run(){
  synchronized(this){ // 作用域该对象 可以视为对普通方法进行同步
    for(int j=0;j<10000;j++){
      i++;
    }
  }
}
public void run(){
  synchronized(this.getClass()){ // 作用域该类 可以视为对静态方法进行同步
    for(int j=0;j<10000;j++){
      i++;
    }
  }
}
```

### final关键字

我们从java的基础知识中学过 final关键字用在变量和方法中的用途,其基本意思在只能赋值一次(值注入一次),而且从其特性上知道,final到引用是可改变引用的内存区域而不改变引用特性的.final类不允许继承,

在多线程中的应用也相对简单,其能一定程度保证可见性(ArrayList等引用不可保证)但是`final int x=3`等因为其已经不可变了,所以可以默认为是对所有线程可见



### volatile关键字

其本质的实现保证的线程安全 主要实现的原理是 主内存(进程堆中的值立刻更新) 而不是更新堆栈的值 其保证了一个变量的可见性(能够立即读取更新值),从实现上来讲其禁止了写的重排序

可以用于解决重排序问题 但不可解决原子性问题所以依然可能会发生线程安全问题

volatile修饰`数组`或者`对象的引用`等变量时,其含义是数组或变量的地址本身的赋值操作具有可见性,而volatile**对数组内部成员的读写,或者对象成员变量的读写不具有可见性**.

```java
public class threadstest3 extends Thread{
    /**
     * 测试volatile关键字可读性
     * */
    boolean flag = false; 
  	// 不加关键字时 死循环依然在执行 因为主线程的操作并不可见(即主线程的flag未刷新到堆中)
 		// 加了关键字之后 因为主线程的vt.flag=true;操作在内存中可见就能被vt读取到
    int i = 0;
    @Override
    public void run() {
        while (!flag) {
            i++;
          	// System.out.println(i); // 解开这行代码就会停下
          	// 我们从这里知道volatile关键字的内存屏障是在任何情况可见且禁止重排序
          	// 而不加的时候我们可以看到,读内存的内容会刷新缓存导致看不到现象
        }
    }

    public static void main(String[] args) throws Exception {
        threadstest3 vt = new threadstest3();
        vt.start();
        Thread.sleep(2000);
        vt.flag = true;
        System.out.println("stop at " + vt.i);
    }
}
```

而保证了可见性并不代表是线程安全的 如下就是一个例子 如果操作不是原子性线程依然不安全

```java
package com.test.sync;

public class threadstest2 {
    /**
     * 证明了volatile破除了关键字 不一定能保证线程安全
     */

    public static void main(String[] args)throws Exception{
        TestClass tc = new TestClass();
        for (int i = 0; i < 1000; i++) {
            tc.startThread();
        }
    }
}

class TestClass {
    volatile Integer count = 0;
    // 不加关键字的时候 最后输出的结构随机
    // 加了关键字之后 依然没有能够完全按照我们的逻辑去执行
    // 其原因就是volatile只是线程间可见 但如果操作不是原子性的话依然有可能出错

    public void startThread() throws Exception{
        new Thread(() -> {
            count++;
            System.out.println(count);
        }).start();
    }
}
```

![JMM内存结构示意图](https://upload-images.jianshu.io/upload_images/15168036-12ead20bc89a8e9b.png)

回顾JMM的结构以及代码执行时候的结果 volatile关键字的现象是比较难以看见的

那么本地内存的变量缓存是何时刷新到主内存里取得呢?

```note
In essence, releasing a lock forces a flush of all writes from working memory employed by the thread, and acquiring a lock forces a (re)load of the values of accessible fields. While lock actions provide exclusion only for the operations performed within a synchronized method or block, these memory effects are defined to cover all fields used by the thread performing the action.
```

当线程释放一个锁时会强制性的将工作内存中之前所有的写操作都刷新到主内存中去，而获取一个锁则会强制性的加载可访问到的值到线程工作内存中来.

而我们常见的System.out.println()方法是一个同步方法 所以有获得锁会刷新内存

这就给了我们一个最基本的启示 尽量使用调试器去观察变量的值 而不是打印 因为打印会刷新缓存







## ***线程池**

---

我们平时自己写线程的时候可能会造成不必要的开销,为了监控负载,更合理的调用资源,更重要的是我们平时自己写的`new Thread(()->{})`会被垃圾回收

线程池有以下特点

1.  复用线程 控制最大并发数
2.  实现任务线程队列缓存策略和拒绝机制
3.  实现某些与时间相关的功能
4.  隔离线程环境

其优点在于

**降低资源消耗,提高响应速度,提高线程的可管理性**

其设计示意图如下,其核心有两变量corePoolSize,maximumPoolSize用来限制如下

![设计示意图](https://images2018.cnblogs.com/blog/1425453/201807/1425453-20180729173817132-1865329285.jpg)

### Executor接口

线程池可以通过Excutors的下列方法快速构造

- newFixedThreadPool
- newCachedThreadPool
- newScheduledThreadPool
- newSingleThreadExecutor

前面两个比较常用,详细的使用方法如下

```java
Executors.newFixedThreadPool(4); 
// 指定核心线程数和最大并发数为4 失活时间默认为0
// 此时失活时间无意义
// 也就是说不会开辟新的线程去执行任务,一共就4个线程自己轮询执行任务
Executors.newCachedThreadPool();
// 核心线程数为0 最大并发数为Integer.MAX_VALUE 失活时间为60秒
// 而且没有缓冲(阻塞)队列 也就是说以缓存形式执行线程 不会加入队列
// 现有线程池无法接收任务时,会创建新的线程去接受执行任务
Executors.newScheduledThreadPool(4); 
// 指定核心线程数为4 最大并发数为Integer.MAX_VALUE 失活时间为0
// 失活时间为0意味着额外的线程一旦执行结束就立刻被回收

ScheduledExecutorService service = Executors.newScheduledThreadPool(4);
service.schedule(new Runnable() {
  public void run() {
    System.out.println(Thread.currentThread().getName()+"延迟三秒执行");
  }
}, 3, TimeUnit.SECONDS); // 延迟3秒
service.scheduleAtFixedRate(new Runnable() {
  public void run() {
    System.out.println(Thread.currentThread().getName()+"延迟三秒后每隔2秒执行");
  }
}, 3, 2, TimeUnit.SECONDS);

Executors.newSingleThreadExecutor();
// 核心线程和最大并发数都是1 失活时间为0
// 意味着所有该线程池执行的线程每次只有1个线程在运行 其他线程在等待
// 就是单线程模式 不会存在线程同步问题
```

这是线程池继承链顶端的接口 如下

![线程池的继承链](https://uploadfiles.nowcoder.com/files/20190118/7380095_1547784444679_4685968-eaaaf8fd88497757.png)



### 构造ThreadPoolExecutor

我们核心思路是要指定其**核心数**和**最大线程数**然后自定义**ThreadFactory**和**RejectedExecutionHandler**,其构造函数如下

```java
public ThreadPoolExecutor(int corePoolSize, // 核心数
                          int maximumPoolSize, // 最大线程数
                          long keepAliveTime, 
                          TimeUnit unit, // 控制空余线程存活时间
                          BlockingQueue<Runnable> workQueue, // 阻塞队列
                          ThreadFactory threadFactory, // 线程工厂
                          RejectedExecutionHandler handler) // 拒绝策略
{
  if (corePoolSize < 0 ||
      maximumPoolSize <= 0 ||
      maximumPoolSize < corePoolSize ||
      keepAliveTime < 0)
    throw new IllegalArgumentException();
  if (workQueue == null || threadFactory == null || handler == null)
    throw new NullPointerException();
  this.acc = System.getSecurityManager() == null ?
    null :
  AccessController.getContext();
  this.corePoolSize = corePoolSize;
  this.maximumPoolSize = maximumPoolSize;
  this.workQueue = workQueue;
  this.keepAliveTime = unit.toNanos(keepAliveTime);
  this.threadFactory = threadFactory;
  this.handler = handler;
}
```

-   corePoolSize

核心线程数 如果为0则 则任务执行完之后 线程池关闭

如果不为0 则在执行完任务之后也不会销毁

过大会浪费资源 过小会频繁创建线程和加大资源开销

-   maximumPoolSize

最大并发数

-   keepAliveTime

空闲时间达到了keepAliveTime时,线程会被销毁 直到剩下corePoolSize为止

当线程池中线程数大于corePoolSize的时候keepAliveTime才起作用

也就是说 线程数常驻内存的只有corePoolSize个线程 其他的都有失活时间

-    unit

时间单位,通常是TimeUnit.SECONDS

-   workQueue

缓冲队列 像BlockingQueue和LinkedBlockingQueue,如果线程请求数大于maximumPoolSize则会进入缓冲队列进行阻塞,另外上面两个队列的入队和出队操作由锁机制保证了原子性

看类型参数里面是Runnable 如果是Callable需要加入到缓冲队列 会转换成Runnable类型

-   ***threadFactory***

它用来生产一组相同任务的线程,

-   handler

当workQueue的缓存区达到了上限的时候 我们可以拒绝线程的请求

这是一种简单的限流保护 这是请求的处理器

友好的拒绝策略如下

1.  保存到数据库进行削峰填谷;在空闲时再提取出来执行
2.  转向某个提示页面
3.  打印日志

默认策略是 AbortPolicy 则是对其任务直接抛弃并抛出异常

CallerRunsPolicy:只用提交任务所在线程来运行任务,有反馈机制,使任务提交的速度变慢

DiscardOldestPolicy:若没有发生shutdown,尝试丢弃队列里最近的一个任务,并执行当前任务, 丢弃任务缓存队列中最老的任务，并且尝试重新提交新的任务

DiscardPolicy:不处理,丢弃掉,拒绝执行,不抛异常

自定义拒绝策略可以通过实现RejectedExecutionHandler实现reject(),例如日志持久化



### 简单使用

```java
ExecutorService service = new ThreadPoolExecutor(8, 16, 8, TimeUnit.SECONDS, new LinkedBlockingQueue<>());
```

我们可以通过execcute方法或者submit方法向线程池提交任务,其后面的代码把其封装成一个Worker加入到Workers里面去 Worker是对线程的封装,线程池内部使用一个Set存储worker不会使得worker重复 `HashSet<Worker> workers=new HashSet<>();`

线程会重阻塞队列workQueue中poll()取出任务放到核心线程中去执行

#### execute 方法

该方法没有返回值所以无法确定有没有执行成功

```java
service.execute(new Runnable() {
  public void run() {
    System.out.println("提交任务");
  }
});
```

其内部是如果核心线程空闲addIfUnderCorePollSize

#### submit方法

该方法针对的是Callable对象

```java
Future<Integer> future = service.submit(new Callable<Integer>() {
  @Override
  public Integer call() throws Exception {
    System.out.println("submit方式");
    return 2;
  }
});
try {
  Integer number = future.get();
} catch (ExecutionException e) {
  // TODO Auto-generated catch block
  e.printStackTrace();
}
```

#### Future/FutureTask类的使用

```java
Callable<Integer> thread = new Callable<Integer>() {
  @Override
  public Integer call() throws Exception {
    System.out.println(Thread.currentThread().getName() + " execute");
    return 3;
  }
};
Future<Integer> ft = new FutureTask<>(thread);
new Thread(ft).start();
Integer i = ft.get(); // 该方法阻塞
```

关于该类的原理在上面的原理中有讲述



#### shutdown方法

.shutdown(); .shutdownNow(); // 两个方法上用于关闭线程池

shutdown() 线程不能接受新的任务 会等待当前线程执行结束

shutdownNow() 线程不能接受新的任务并且尝试终止现在的任务



#### 线程池运行状态监测

```java
pool.getQueue().size(); // 等待队列的线程数目
pool.getCompletedTaskCount() // 已经完成的线程数
```



---

#### 线程池状态

-   RUNNING
-   SHUTDOWN shutdown后 线程池不能接受新任务,等待线程执行完成
-   STOP shutdownNow后 线程池不能接受新任务,并尝试销毁其他任务
-   TERMINATED 当工作线程已经销毁,任务缓冲队列清空或执行结束之后

**队列、线程工厂、拒绝处理服务**都必须有实例对象,但编程中我们很少亲自实例化对象

```java
ExecutorService service = new ThreadPoolExecutor(8, 16, 8, TimeUnit.SECONDS, new LinkedBlockingQueue<>());
```

这样子的代码 java内部配置了许多已经实现好的的线程池类



#### ScheduleThreadPool的使用

此线程池行为和其他三种略微不同,因此单独拿出来说下,在spring中我们使用过quartz定时调度,线程池里面也就类似的机制存在就叫ScheduleThreadPool.其有自己的api,如下为其主要特有的api

-   schedule 延时任务
-   scheduleAtFixedRate 周期性调度,固定周期,如果任务执行时间过长,那以任务为优先
-   scheduleWithFixedDelay 周期性调度,固定时间调度

```java
ExecutorService pool = Executors.newScheduledThreadPool(3); 
// 创建一个定时调度线程池
pool.scheduleAtFixedRate(()->{},50,1000,TimeUnit.MILLISECONDS);
// 如果任务执行时间过重的话两次调度的周期就会被拉长
pool.scheduleAtFixedDelay(()->{},50,1000,TimeUnit.MILLISECONDS);
// 每隔1000ms进行调度,50ms延时开始
```

因为其同样实现executor接口,所以也可以像其他线程池一样使用executor和submit方法,但其还多了一个方法就是**`schedule`**,schedule用于执行延时任务.

```java
public void execute(Runnable command) {
  schedule(command, 0, NANOSECONDS);
}
public Future<?> submit(Runnable task) {
  return schedule(task, 0, NANOSECONDS);
}
public ScheduledFuture<?> schedule(Runnable command,long delay,TimeUnit unit) {
  if (command == null || unit == null)
    throw new NullPointerException();
  RunnableScheduledFuture<?> t = decorateTask(command,new ScheduledFutureTask<Void>(command, null,triggerTime(delay, unit)));
  delayedExecute(t); // 延时执行
  return t;
}
```





#### 简单线程池map-reduce方法实现

```java
package com.test.sync;
import javafx.util.Pair;
import java.util.*;
import java.util.concurrent.*;
import java.util.function.BiFunction;
import java.util.function.Function;
public class _MapReduce {
  // 任务队列
  static List<Callable> mapTaskList = null;
  // 任务队列
  static List<Callable> reduceTaskList = null;
  // map结果集
  static List<Future> mapResultSet = null;
  // reduce结果集
  static List<Future> reduceResultSet = null;

  static ExecutorService mapPool = Executors.newCachedThreadPool();
  static ExecutorService reducePool = Executors.newCachedThreadPool();
  // 这里的线程池没有进行好的配置 只是为了说明测试的效果

  public static void main(String[] args) throws Exception {
    // init tasklist and resultset
    initComputeEnvironment();
    try {
      // 简单的计算
      _map(new Integer[]{1, 2, 3}, (i) -> {
        return i * 2;
      });
      printMapResultSet();
      clearList(mapResultSet);

      // 简单的单词分割任务
      _map(new String[]{"hi hello", "world wolf", "pig"}, (str) -> {
        return Arrays.asList(str.split(" "));
      });
      printMapResultSet();
      clearList(mapResultSet);

      Integer result = _reduce(new Integer[]{1, 3, 5, 7, 9}, (x, y) -> {
        return x * y;
      });
      System.out.println("reduce output:" + result);

      String _result = _reduce(new String[]{"1", "2", "3", "4", "5"}, (str1, str2) -> {
        return str1 + str2;
      });
      System.out.println("reduce output:" + _result);
    } finally {
      clearComputeEnvironment();
    }
  }

  public static List getResultSet(List<Future> resultSet) throws ExecutionException, InterruptedException {
    List ls = new ArrayList<>();
    for (Future f : resultSet) {
      ls.add(f.get());
    }
    return ls;
  }

  public static void printMapResultSet() throws ExecutionException, InterruptedException {
    System.out.print("map result:");
    for (Future f : mapResultSet) {
      System.out.print(f.get() + " ");
    }
    System.out.println();
  }

  public static void printReduceResultSet() throws ExecutionException, InterruptedException {
    System.out.print("after reduce:");
    long start = System.currentTimeMillis();
    for (Future f : reduceResultSet) {
      System.out.print(f.get() + " ");
    }
    System.out.println(System.currentTimeMillis() - start + "ms for execute");
  }

  public static void clearList(List ls) {
    ls.clear();
  }

  public static void initComputeEnvironment() {
    /**
         * 任务队列 CopyOnWriteArrayList
         */
    mapTaskList = new CopyOnWriteArrayList<>();
    mapResultSet = new CopyOnWriteArrayList<>();
    reduceTaskList = new CopyOnWriteArrayList<>();
    reduceResultSet = new CopyOnWriteArrayList<>();
  }

  public static void clearComputeEnvironment() {
    /**
         * 清空任务队列
         */
    mapTaskList.clear();
    mapResultSet.clear();
    reduceTaskList.clear();
    reduceResultSet.clear();
  }

  public static <I, O> void _map(I[] datas, Function<I, O> func) throws ExecutionException, InterruptedException {
    /**
         * 加入任务队列
         * 执行队列任务
         */
    add2TaskList(datas, func, mapTaskList);
    submitTask(mapTaskList, mapResultSet);
  }

  public static <I, O> I _reduce(I[] datas, BiFunction<I, I, O> func) throws ExecutionException, InterruptedException {
    /**
         * 加入任务队列
         */
    I[] ls = reduceTasks(datas, func);
    return ls[0];
  }

  public static <I, O> I[] reduceTasks(I[] datas, BiFunction<I, I, O> func) throws ExecutionException, InterruptedException {
    System.out.println("reduce debug: " + Arrays.asList(datas) + " length:" + datas.length);
    if (datas.length > 1) {
      boolean isOdd = false;
      if (datas.length % 2 != 0) { // 奇数个的时候进行特殊处理
        isOdd = true;
      }
      for (int i = 0; i < datas.length - 1; i += 2) {
        // 这个遍历是 奇数个的时候是没有最后一个数的 偶数个的时候是能完全遍历的
        int finalI = i;
        reduceTaskList.add(new Callable<O>() {
          @Override
          public O call() throws Exception {
            return func.apply(datas[finalI], datas[finalI + 1]);
          }
        });
      }
      submitTask(reduceTaskList, reduceResultSet); // 提交任务到线程池
      List resultList = getResultSet(reduceResultSet);
      if (isOdd) {
        resultList.add(datas[datas.length - 1]);
      }
      I[] resultSet = (I[]) resultList.toArray(); // 获得结果集
      clearList(reduceResultSet);
      clearList(reduceTaskList);
      return reduceTasks(resultSet, func);
    } else { // 等于1
      return datas;
    }
  }

  public static <I, O> void add2TaskList(I[] datas, Function<I, O> func, List<Callable> taskList) {
    for (I data : datas) {
      taskList.add(new Callable() {
        @Override
        public O call() throws Exception {
          return func.apply(data);
        }
      });
    }
  }
  public static void submitTask(List<Callable> taskList, List<Future> resultSet) {
    /**
         * 提交任务到线程池中
         */
    if (taskList.size() < 1) {
      throw new RuntimeException("没有要执行的任务");
    } else {
      for (Callable c : taskList) {
        resultSet.add(mapPool.submit(c));
      }
    }
  }
}
```



### 拒绝策略

ExecutorThreadPool的拒绝策略分为以下4种

-   AbortPolicy 调用者的线程直接抛出异常,作为默认策略.
-   CallerRunsPolicy 用调用者的线程来执行任务
-   DiscardOldestPolicy  抛弃线程池最久的任务
-   DiscardPolicy 抛弃当前任务

执行的线程数已经到达了线程池的上限且任务队列满了,shutdown线程池之后.如果还在提交任务就会执行拒绝策略handler的方法.其具体实现会在如下的线程池实现中详细表述.



### ThreadGroup

ThreadGroup是利用一种组合策略管理线程的方式,是线程池的底层基础之一,我们可以通过其管理一系列线程.如下结构

![](https://img-blog.csdn.net/20181012162426786?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hzaHFpYW5n/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

```java
public static void main(String[] args){               
  ThreadGroup currentGroup = Thread.currentThread().getThreadGroup();
  ThreadGroup groupA = new ThreadGroup("GroupA");
  // 等价 new ThreadGroup(currentGroup,"GroupA");
  ThreadGroup groupB = new ThreadGroup(group1, "GroupB");
  new Thread(()->{},"Thread1");
  new Thread(currentGroup,()->{},"Thread2");
  new Thread(groupA,()->{},"Thread3");
  
  
  groupA.list();
  groupA.destory(); // 释放资源
}
```

如上代码就可以构建出上面的树形结构.ThreadGroup通过维护内部的`Thread[]`数组来管理线程组我们可以如下方法调用各个线程.

```java
Thread[] threads = new Thread[10];
threadGroup.enumerate(threads); // 活动线程复制到threads
```

ThreadGroup使用不慎会有内存泄漏的风险,ThreadPoolExector有用到相应的实现,但是我们平时自己就不要轻易使用该类,应当使用自己的数据结构或者线程池来规避内存泄漏的风险.



### ForkJoin

forkjoin是一个线程框架JDK1.7的主要线程工具 如果任务足够小就进行计算 如果不够小就拆分成若干小任务进行计算

***工作窃取模式***

当执行新的任务时它可以将其拆分成更小的任务执行，并将小任务加到线程队列中.所以我们能够看到不同的任务是处于不同的队列中的,不同的队列中包含的都是没有冲突的线程.当没有任务执行时，再从一个随机线程的队列中偷一个并把它放在自己的队列中.这就是工作窃取

相对于一般的线程池实现 ，fork/join 框架的优势体现在对其中包含的任务的处理方式上，在一般的线程池中，如果一个线程正在执行的任务由于某些原因无法继续运行,那么该线程会处于等待状态。而在fork/join 框架实现中，如果某个子问题由于等待另外一个子问题的完成而无法继续运行。那么处理该子问题的线程会主动寻找其他尚未运行的子问题（窃取过来）来执行，这种方式减少了线程的等待时间，提高了性能.

继承` RecursiveTask `或者 `RecursiveAction`就行 不过后者不会返回结果

```java
class SumTask extends RecursiveTask<Long> {
    static final int THRESHOLD = 500; // 计算的最小阈值
    long[] array;
    int start;
    int end;

    SumTask(long[] array, int start, int end) {
        this.array = array;
        this.start = start;
        this.end = end;
    }

    @Override
    protected Long compute() {
        if (end - start <= THRESHOLD) {
            long sum = 0;
            for (int i = start; i < end; i++) {
                sum += this.array[i];
            }
            return sum;
        }
        int middle = (end + start) / 2;
        SumTask subtask1 = new SumTask(this.array, start, middle);
        SumTask subtask2 = new SumTask(this.array, middle, end);
      	
        invokeAll(subtask1, subtask2);
        Long subresult1 = subtask1.join(); // 等待结果完成
        Long subresult2 = subtask2.join();
        Long result = subresult1 + subresult2;
        return result;
    }
}
```

计算调用

```java
ForkJoinTask<Long> task = new SumTask(array, 0, array.length);
Long result = ForkJoinPool.commonPool().invoke(task);
```





---

## *多线程技术核心实现

本章是多线程的重中之重,可以说多线程的绝大多数精髓和使用方式全在本章里面,相对于程序员而言只用知道`synchronized`和`wait`,`notify`就可以编写程序之外,本章主要介绍这些原理,以及真正的多线程的底层.

另外值得注意的是本章下半部分涵盖了从java原生同步到JUC的自旋同步的所有机制及原理,如不熟悉api可以跳转到相应章节进行学习,中间会掺杂着大量的源码分析实例,详细的源码分析文档请参照源码分析

### JMM的硬件实现机制

JMM是java的内存模型,以下讨论的是JMM在具体物理硬件上的实现的机制,比如内存屏障,MESI协议等,这一章理解之后可以深刻理解上述关键字的设计思想

---

#### CPU 三级缓存与内存屏障

-   CPU一般有多级缓存系统,一般为L1,L2,L3分别代表三级缓存,不同的缓存离CPU的位置不同,造价和速度也不同,L1缓存分为指令缓存和数据缓存,都在CPU内部和CPU并行运行,因为各级缓存间的访存时间周期都差距很大,和主存差距更是巨大,缓存做的是性能匹配的工作
-   缓存和内存的修改时间并不一致,造成了数据的差异性.而并非所有硬件系统的CPU都能实时可见内存中的变化,CPU要通过一些特殊指令把缓存中的数据刷新到内存中(或者是设置内存中的数据无效位),这就是所谓的内存屏障.

内存屏障除了保证CPU的可见性之外还禁止指令的重排序,硬件层次的内存屏障一般分为**Load Barrier**,**Store Barrier**,从volatile关键字中我们可以看出来读写屏障是存在的.volatile关键字的存在使得程序员可以屏蔽硬件的内存屏障的实现.

-   Load Barrier 在指令前插入读屏障,可以让高速缓存中的数据失效,强制从主内存取。
-   Store Barrier 在指令后插入写屏障,可以让写指令立即刷新到内存

如果读完了下面的MESI协议我们可以得出以下实质上的操作

-   Load Barrier **告诉CPU在执行任何的加载前,所有已经在I状态的缓存写回主存操作**
-   Store Barrier **告诉CPU在执行这之后的指令之前,应用所有已经在本CPU缓存行中的数据**

 内存屏障的作用


-  阻止屏障两侧指令重排序
-  强制把写缓冲区/高速缓存中的脏数据等写回主内存,让缓存中相应的数据失效.

在我们使用volatile关键字的时候会在该变量的读写前后加入读写屏障,保证了可见性,而即使不加的情况,如果我们在一些关键操作上进行读写,那么JVM解释器/JIT编译器优化有可能也会帮我们刷新缓存但总不如我们加上直接保证可见性来的好(如volatile关键字例子所示)

#### 缓存行 Cache line

缓存行可以理解为CPU中缓存的最小单位,现在比较常见的是64Byte的缓存行,CPU一次性从缓存中最大容量就是缓存行(与寄存器大小有关),所以L1缓存可以分为多个缓存行,如L1缓存有512B则有512/64=8个缓存行,其实我们在计算机操作系统的Cache行优先读取(如下)上能看到这个结果(因为一次性把数组的元素加入缓存行)

```c
for(int i = 0; i < n; i++) {
    for(int j = 0; j < n; j++) {
        int num;   
        arr[i][j] = num; // 写入行,每个都命中cache,时间更快
    }
}
for(int i = 0; i < n; i++) {
    for(int j = 0; j < n; j++) {
        int   num;       
        arr[j][i] = num; // 调入cache基本次次不命中,调入缓存次数过多效率下降
    }
}
```

单核与缓存与总线结构示意图

![](https://img2018.cnblogs.com/blog/941117/201809/941117-20180904124240312-612747180.png)

但是我们都知道现在cpu都是多核的,多线程的出现使得cpu架构更加复杂

多核的工作流程会引发如下问题

-   CPU0 读取一个字节,该字节和其相邻的字节以缓存行的形式读入L1缓存
-   CPU1 重复同样的工作
-   CPU0 修改缓存中的数据
-   CPU1 修改缓存中的数据

但是CPU0和CPU1的缓存都没有刷新到RAM中,导致了数据不同步(可见性问题),为此CPU设计了如下MESI协议控制访存,其实设计思路也比较简单,当某一CPU修改缓存的时候通知其他CPU该缓存的数据已经失效



#### 硬件的MESI协议

保证缓存一致性MESI协议表示了缓存行的4个状态(MESI),一般使用2bit位表示.

如下表格,需要声明的一点是下列状态都是缓存行的状态,和java的锁并无关系

| 状态              | 描述                                                         | 监听任务                                                     |
| :---------------- | ------------------------------------------------------------ | :----------------------------------------------------------- |
| M 修改 (Modified) | 该Cache line**有效**,数据被修改了,和内存中的数据**不一致**,数据**只存在于本Cache中**. | 缓存行必须时刻监听所有试图读该缓存行相对就主存的操作,这种操作必须在缓存将该缓存行**写回**主存并将状态变成S(共享)状态之前被延迟执行. |
| E 独占(Exclusive) | 该Cache line**有效**,数据和内存中的数据一致,数据**只存在于本Cache**中. | 缓存行也必须监听其它缓存读主存中该缓存行的操作,一旦有读取内存/其他缓存,该缓存行需要变成S(共享)状态. |
| S 共享 (Shared)   | 该Cache line**有效**,数据和内存中的数据一致,数据**存在于很多Cache**中. | 缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求,并将该缓存行变成无效(Invalid) |
| I 无效 (Invalid)  | 该Cache line无效                                             | 无                                                           |

下图的状态是每个CPU Core自己的缓存行的变化

![](https://images2018.cnblogs.com/blog/1195582/201805/1195582-20180503162525310-2087402052.png)

需要注意的是修改状态E的缓存不需要通过总线事务

-   local read cpu读自己的缓存
-   local write cpu写自己的缓存
-   remote read 从其他缓存读或者主存读数据到自己缓存,**需要经过总线**
-   remote write 把本地缓存的数据写到远程的缓存或内存

如上图,比如CPU的缓存行是状态M,如果CPU要读写自己的缓存不需要改变状态M,如果是remote read,即要用内存读取数据(原来数据丢弃),那么该状态会变成S,如果是remote write,即要写回内存,故状态会变更为S

关于状态E,表示该Cache line**有效**,数据和内存中的数据**一致**,数据**只存在于本Cache**中.我们不应该像java的同步锁那样去理解该状态,其更像是一个中间状态,表明缓存行已经被该core**(只被该core)**被占用了,从状态上我们看到了remote write触发的时候会变成I,即不允许写回,因为是中间状态,很可能CPU要写东西进缓存行但还没写进来,更详细的变化情况如下表

|       State       |                         触发本地读取                         |                            write                             |                         remote read                          |                         remote write                         |
| :---------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|         M         |             本地cache:M 触发cache:M 其他cache:I              |             本地cache:M 触发cache:M 其他cache:I              | 本地cache:M→E→S 触发cache:I→S 其他cache:I→S 同步主内存后修改为E独享,同步触发、其他cache后本地、触发、其他cache修改为S共享 | 本地cache:M→E→S→I 触发cache:I→S→E→M 其他cache:I→S→I 同步和读取一样,同步完成后触发cache改为M，本地、其他cache改为I |
| **E状态（独享）** |             本地cache:E 触发cache:E 其他cache:I              | 本地cache:E→M 触发cache:E→M 其他cache:I 本地cache变更为M,其他cache状态应当是I（无效） | 本地cache:E→S 触发cache:I→S 其他cache:I→S 当其他cache要读取该数据时，其他、触发、本地cache都被设置为S(共享) | 本地cache:E→S→I 触发cache:I→S→E→M 其他cache:I→S→I 当触发cache修改本地cache独享数据时时，将本地、触发、其他cache修改为S共享.然后触发cache修改为独享，其他、本地cache修改为I（无效），触发cache再修改为M |
|  **S状态(共享)**  |             本地cache:S 触发cache:S 其他cache:S              | 本地cache:S→E→M 触发cache:S→E→M 其他cache:S→I 当本地cache修改时，将本地cache修改为E,其他cache修改为I,然后再将本地cache为M状态 |             本地cache:S 触发cache:S 其他cache:S              | 本地cache:S→I 触发cache：S→E→M 其他cache:S→I 当触发cache要修改本地共享数据时，触发cache修改为E（独享）,本地、其他cache修改为I（无效）,触发cache再次修改为M(修改) |
| **I状态（无效）** | 本地cache:I→S或者I→E 触发cache:I→S或者I →E 其他cache:E、M、I→S、I 本地、触发cache将从I无效修改为S共享或者E独享，其他cache将从E、M、I 变为S或者I |  本地cache:I→S→E→M 触发cache:I→S→E→M 其他cache:M、E、S→S→I   |           既然是本cache是I，其他cache操作与它无关            |           既然是本cache是I，其他cache操作与它无关            |

一些常见的CPU行为如下

##### 两个core读cpu内存

![](https://images2018.cnblogs.com/blog/1195582/201805/1195582-20180503162619534-683579600.png)

CPU A发出了一条指令，从主内存中读取x。
CPU A从主内存通过bus读取到 cache a中并将该cache line 设置为E状态。
CPU B发出了一条指令，从主内存中读取x。
CPU B试图从主内存中读取x时，CPU A检测到了地址冲突。这时CPU A对相关数据做出响应。此时x 存储于cache a和cache b中，x在chche a和cache b中都被设置为S状态(共享)。

##### 修改数据

![](https://images2018.cnblogs.com/blog/1195582/201805/1195582-20180503162633779-1465275811.png)

CPU A 计算完成后发指令需要修改x.
CPU A 将x设置为M状态（修改）并通知缓存了x的CPU B, CPU B将本地cache b中的x设置为I状态(无效)
CPU A 对x进行赋值。

##### 同步数据

从这里可以看到两个线程发生变量同步的时间在读或者写的瞬间

![](https://images2018.cnblogs.com/blog/1195582/201805/1195582-20180503162644640-382839091.png)

CPU B 发出了要读取x的指令。
CPU B 通知CPU A,CPU A将修改后的数据同步到主内存时cache a 修改为E（独享）
CPU A同步CPU B的x,将cache a和同步后cache b中的x设置为S状态（共享）

---

引入MESI协议之后,内存的数据一致性得到了保证,但状态切换也是需要时间的,CPU会一致等待缓存状态更新,造成少量性能下降

对MESI的优化在操作系统中也有提到过就是**延迟写回**,即其他线程对此缓存行中的数据由读写需求的时候才会花大开销写回内存,该种机制称为**Store Bufferes**,而在多线程中,写回的时间是无法保证的,比如

```java
value = 3；
void exeToCPUA(){
  value = 10;
  isFinsh = true;
}
void exeToCPUB(){
  if(isFinsh){
    assert value == 10;
  }
}
```

而影响`assert`结果的一个重要的东西就是重排序,即所见指令非CPU执行指令



#### 重排序 reordings

重排序是多线程中最难的点,重排序可能发生在编译期,运行时,JIT即时优化上.

所谓的重排序是编译器或解释器能在不改变语义的前提下把某些操作的顺序改变用来提高效率.这种重排序导致的问题就是如果优化的语句排到了后边(比如写操作)那么该操作对其他线程而言是不可见的.重排序不只是会移动到后面,也可能移动到前面.

此节点关联着`happen-before原则`但因为多线程的学习目的不是为了设计重排序,所以这里只是把机制说明,我们只要清楚内存屏障和锁能有效的阻止重排序防止多线程的歧义

-   编译优化重排序 编译器在不改变单线程程序语义的前提下,可以重新安排语句的执行顺序
-   指令并行重排序 现代处理器采用了指令级并行技术来将多条指令重叠执行.如果不存在数据依赖性,处理器可以改变语句对应机器指令的执行顺序
-   内存系统重排序 由于处理器使用缓存和读/写缓冲区,这使得加载和存储操作看上去可能是在乱序执行的

按照程序员的逻辑,代码的先后发生,拥有以下特性是不能被重排序的

-   数据依赖性 `a=3;b=4;c=a+b;`c需要依赖`a=3`和`b=4`的执行才能执行
-   控制依赖性 由`if`相关的代码,需要执行判断条件才能往下执行



### 有序性的happen-before原则

---

**它真正的意思是前面的操作对后续的操作都是可见的 可见意味着结果按执行先后的顺序可以确定下来 但是执行顺序却未必如同我们意料中的那样**

**无论如何重排序程序的语义不变,即程序的执行结果是一样的**

这一章的目的只是让我们了解如何设计重排优化的,实际上为了避免产生歧义,我们一般使用**synchronized**关键字的锁技术和**volatile**的内存屏障来禁止指令重排

再来,此原则有一前提是重排序不会影响线程前后的执行顺序,如果是确定了有先后顺序的才能够使用happen-before原则,不确定顺序且跨线程之间的重排序是没有的,我们应该如此理解下面的规则,是对顺序执行的指令**即是发生重排序依然存在的先后发生关系**,而不应该理解为不确定指令执行顺序时的规则,也不能理解为这些指令不发生重排序,而应该理解为**实际效果看上去和不发生重排序一样**.

---

**happen-before是jmm维护的内存关系用于保证可见性** 

A线程的读和B线程的写如果之间存在happen-before关系那么就保证了B的写对A的读可见,也一定意味着B的写在A之前执行,但是两个操作之间存在happens-before关系,并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行.如果重排序之后的执行结果,与按happens-before关系来执行的结果一致,那么这种重排序并不非法（也就是说，JMM允许这种重排序）

#### 程序的顺序性规则

​	一个线程中的每个操作，happens-before于该线程中的任意后续操作

#### ***监视器锁规则***

​	对一个锁的解锁(释放锁),happens-before于随后对这个锁的加锁(获得锁).

#### ***volatile变量规则***

对一个volatile域的写,happens-before于任意后续对这个volatile域的读.

#### 传递性

A happens-before B,且B happens-before C,那么A happens-before C

#### ***start()规则***

如果线程A执行操作ThreadB.start() (启动线程B),那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作

#### ***Join()规则***

如果线程A执行操作ThreadB.join()并成功返回,那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回

#### 程序中断规则

对线程interrupted()方法的调用先行于被中断线程的代码检测到中断时间的发生

#### 对象finalize规则

一个对象的初始化完成（构造函数执行结束）先行于发生它的finalize()方法的开始

#### 利用上面的规则通过传递性等可以确定结果,但不一定可确定执行顺序



### 初始化\<clinit>和\<init>方法的线程安全问题

先说结论`<clinit>`方法是线程安全的`<init>`方法是线程不安全的

`<clinit>`是类的初始化方法,jvm会去收集static字段和static代码块进行执行和注入,因为其存储区域都在方法区,所以所有该类的实例共用,**jvm的规范中要对其初始化的类的Class的实例进行加锁**,所以该方法是线程安全的

`<init>`方法是实例的初始化方法,而new一个类时在堆区分配内存不存在竞争现象,故不需要加锁.

这个机制告诉了我们我们可以使用类的静态初始化当成加锁使用 比如如下代码其功能上等同

```java
private static class LazySomethingHolder {
  public static Something something = new Something();
}

public static Something getInstance() {
  return LazySomethingHolder.something;
}
// 等价于下面代码
public static synchronized Something getInstance(){
  return new Something();
}
// 等价于下面代码
public static Something getInstance(){
  synchronized(this.getClass()){
  	return new Something();
  }
}
```



### **synchronized锁的升级过程**

synchronized涉及到锁升级过程的数据结构是堆中对象的markword如下

![](https://img-blog.csdnimg.cn/20190111092408622.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdWR1bl9jb29s,size_16,color_FFFFFF,t_70)

从上图我们就知道,锁的升级过程是通过标志markword中的bit位去让虚拟机感知的,其有以下4种

-   没有加锁001
-   偏向锁101
-   轻量级锁(自旋锁)00
-   重量级锁10

JDK1.6之后才有了这种锁的升级过程,之前synchronized默认是使用重量级锁的,锁的升级过程是不可逆的只能从低状态到高状态.这样做的目的是提高了获得锁的效率.

其升级过程大致如下,`偏向锁启动`需要添加JVM参数,在JDK1.8版本默认是不开启的

![](https://img-blog.csdnimg.cn/20200723142024695.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTAwNzkxNg==,size_16,color_FFFFFF,t_70)

#### 偏向锁(纸老虎)

只有设置了`-XX:BiasedLockingStartupDelay=0`的时候在对一个Object实例synchronized获取锁的时候,JVM才会给该对象加上偏向锁,如上markword会记录加锁线程的id.**第一个获取到偏向锁的线程优先**.其适用场景比较狭窄,只有一个线程(无竞争的时候)才有作用,其并不会出现多线程问题,所以虚拟机就不会出现**同步操作**当出现线程竞争的时候(哪怕只有一个)才会升级成轻量级锁(自旋锁).

其实现和管理也很简单,用CAS设置markword中的线程id,偏向锁的状态bit位即可.jvm对此种对象不做任何处理.

#### 轻量级锁(自旋锁)

所谓的轻量级锁就是原子性操作CAS(见下文),在某一域上循环等待占有权.

-   lock-record 锁记录创建于每个线程自己的线程栈中,而要被使用的对象的markword中的相应区域被各个线程用CAS抢占修改

每个线程都用CAS的方式去把markword中的lock-record改成自己线程栈中的地址,那个线程成功意味着哪个线程获取到自旋锁.

#### 重量级锁

当自旋次数超过了某些阈值(定值或者JDK1.8以后动态),就会升级成重量级的锁,重量级的锁是操作系统级别的锁,涉及到上下文切换,对性能开销的要求不小,其向操作系统申请锁,接受操作系统的调度,挂起线程进入阻塞.



### volatile关键字的实现原理

这个实现原理在JMM概述中就已经有了,其本质上就是c语言读写屏障函数(c++已有volatile关键字)

-   Load Barrier **告诉CPU在执行任何的加载前,所有的缓存写回主存操作,且强制从主存读取**
-   Store Barrier **告诉CPU在执行这之后的指令之前,把本CPU中缓存的数据立即刷新到主存**

在volatile关键字前后插入读写屏障,让缓存失效即是volatile关键字的管理



volatile能保证读写数据的时候**一次性读和写**

---

这里提一个没说明白的语义问题,32位处理机读写64位数据的问题,该读写操作必是原子性的,只是其读写根据CPU实现内存屏障的不同有不同的指令,常见的处理器intel如下

-   sfence: 也就是save fence，写屏障指令。在sfence指令**之前的写操作必须在sfence指令后的写操作前**完成。
-   lfence: 也就是load fence，读屏障指令。在lfence指令**之前的读操作必须在lfence指令后的读操作前**完成。
-   mfence: 在mfence指令前得读写操作必须在mfence指令后的读写操作前完成。

我们可以认为cpu指令插入的内存屏障,使得64位的两次读写之间可以被线程中断,而jvm则保证了该读写不可以被中断.




### **synchronized关键字的实现原理**

`monitorenter`和`monitorexit`指令是synchronized关键字实现的关键,我们利用`javap -v`来反汇编上面的代码段就会发现这两个字节码指令环绕在synchronized(){}代码块的两侧.

```java
public synchronized void doSth(){
  System.out.println("Hello World");
}
public void doSth1(){
  synchronized (SynchronizedTest.class){
    System.out.println("Hello World");
  }
}
```

```assembly
 public synchronized void doSth();
    descriptor: ()V
    flags: ACC_PUBLIC, ACC_SYNCHRONIZED
    Code:
      stack=2, locals=1, args_size=1
         0: getstatic     #2
         # // Field java/lang/System.out:Ljava/io/PrintStream;
         3: ldc           #3 // String Hello World
         5: invokevirtual #4                  
         # // Method java/io/PrintStream.println:(Ljava/lang/String;)V
         8: return

public void doSth1();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=2, locals=3, args_size=1
         0: ldc           #5    // class com/hollis/SynchronizedTest
         2: dup
         3: astore_1
         4: monitorenter
         5: getstatic     #2 
         # // Field java/lang/System.out:Ljava/io/PrintStream;
         8: ldc           #3                  // String Hello World
        10: invokevirtual #4                  
        # // Method java/io/PrintStream.println:(Ljava/lang/String;)V
        13: aload_1
        14: monitorexit
        15: goto          23
        18: astore_2
        19: aload_1
        20: monitorexit
        21: aload_2
        22: athrow
        23: return
```

从字节码我们可以看到其实现完全不一样,对同步方法采用`ACC_SYNCHRONIZED`标记符来实现同步,该标记符存在于方法区的常量池(从这里也可以看出运行时常量池是方法独有的).当线程要访问方法时,会检查`ACC_SYNCHROIZED`,如果有设置需要先获得监视器的锁,开始执行方法,执行完方法之后释放锁,其他线程的请求都会被拒绝.

`monitorenter`和`monitorexit`为两个加锁的字节码,这两个字节码可以理解为指令级别的加锁和释放锁,每个对象会被分配一个**monitor(监视器)**,其地址引用被保留在markword中如下图重量级锁`ptr_to_heavyweight_monitor`.

![](https://img-blog.csdnimg.cn/20190111092408622.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdWR1bl9jb29s,size_16,color_FFFFFF,t_70)

其本质是个计数器,当有线程获得其锁**(使用monitorenter时)**,计数器自增,当该线程多次获取的时候(称为可重入),计数器也会相应的自增,当释放的时候**(使用monitorexit时)**,计数器自减,当减少到0时释放锁.其他线程如果发现计数器不为0了也就进行阻塞(对应线程状态SYNCHRONIZED)了.

#### monitor的实现

monitor这词原本指的是监视器,但在操作系统里面也可以用来指**管程**

>   管程 (英语：Monitors，也称为监视器) 是一种程序结构，结构内的多个子程序（对象或模块）形成的多个工作线程互斥访问共享资源。这些共享资源一般是硬件设备或一群变量。管程实现了**在一个时间点，最多只有一个线程在执行管程的某个子程序**。与那些通过修改数据结构实现互斥访问的并发程序设计相比，管程实现很大程度上简化了程序设计。 管程提供了一种机制，线程可以临时放弃互斥访问，等待某些条件得到满足后，重新获得执行权恢复它的互斥访问.

![](https://www.hollischuang.com/wp-content/uploads/2017/12/java-monitor-associate-with-object.jpg)

如上图,monitor定义了一种方式,去管理各种各样的线程,上图的Special Room(owner)表示monitor中唯一被线程执行的程序.而Entry Set就是等待调度的队列,如果因为某些原因线程被调用.wait()/挂起,那么其就会进入Wait Set.而当其被notify唤醒之后就可以再次进入Special Room(owner)了.

我们可以人为管程中正在运行的程序拥有某种许可,拥有这种许可的线程才能够执行,离开时其许归还或者运行时主动释放许可.其实熟悉机制的话,上面对应的java代码就能够写出来了.

而monitor是由[**ObjectMonitor(c++类)**](https://github.com/openjdk-mirror/jdk7u-hotspot/blob/50bdefc3afe944ca74c3093e7448d6b889cd20d1/src/share/vm/runtime/objectMonitor.cpp)实现的

![](https://www.hollischuang.com/wp-content/uploads/2017/12/monitor.png)

其关键操作,比如修改owner的指针修改代码依然是通过CAS修改值的,所谓的计数器也是在其enter方法中进行维护的一个变量值,其在monitorenter的时候使用`ObjectMonitor::enter`进行加锁,在monitorexit的时候使用`ObjectMonitor::exit`进行锁的释放

该类还实现了wait/notify/notifyAll等方法



### **wait和notify实现原理**

从上面看来wait/notify就是ObjectMonitor类实现的,如下为其数据结构,无论是monitor的实现还是

```c++
 ObjectMonitor() {
    _header       = NULL;
    _count        = 0; // 记录线程的获取锁次数
    _waiters      = 0, 
    _recursions   = 0; // 可重入锁,重入次数
    _object       = NULL;
    _owner        = NULL; // 指向真正运行的线程
    _WaitSet      = NULL; // 等待队列(WAITING状态的线程队列)
    _WaitSetLock  = 0 ;
    _Responsible  = NULL ;
    _succ         = NULL ;
    _cxq          = NULL ;
    FreeNext      = NULL ;
    _EntryList    = NULL ; // 存放block状态的线程(即synchronized获取锁)
    _SpinFreq     = 0 ;
    _SpinClock    = 0 ;
    OwnerIsThread = 0 ;
}
```

```c++
// 其三个方法定义如下
void wait(jlong millis, bool interruptable, TRAPS); 
void notify(TRAPS);
void notifyAll(TRAPS);
```

其中wait的行为和代码我们所了解的最为接近

-   ObjectMonitor::AddWaiter把线程添加到_waitSet
-   调用ObjectMonitor::exit释放monitor
-   调用Self->_ParkEvent->park()挂起线程

notify的实现大致如下

-   如果_waitSet为空,没有等待的线程,直接返回
-   ObjectMonitor::DequeueWaiter,让等待队列的**第一个节点**出队(唤醒顺序LIFO)
-   **根据不同的策略**,加入到EntryList竞争,或是自旋获得_owner字段的修改权.

所以我们在这里可以看到三个事情,notify不是随机唤醒的,其可能会回到SYNCHRONIZED或者WAITING状态,二是其可能进入EntryList与其他线程竞争也可能是自旋获取锁,三是其不会**释放锁**(因为其本质上并没有调用ObjectMonitor::exit)

notifyAll则是通过for循环去出所有节点,并根据不同方法加入到EntryList或是自旋获取monitor线程唯一使用权.

我们来分析下最常用的wait/notify的使用场景

```java
static final Object lock = new Object(); // 永久代和heap分配内存,引用不可修改
Thread t1 = new Thread(()->{
  synchronized(lock){ // ObjectMonitor::enter 修改markword
   	lock.wait(); // try catch没写
    // 线程加入_waitSet 修改markword 
    // ObjectMonitor::park 操作系统挂起线程
    // ObjectMonitor::exit 其他线程可以抢占,进入WAITING状态
    System.out.println("下次被唤醒才会执行下面代码");
  }
});
Thread t2 = new Thread(()->{
  synchronized(lock){ // ObjectMonitor::enter 修改markword
    lock.notify(); // _waitSet出队一线程唤醒加入等待队列或者自旋指向_owner
    // while(true){} // 没有退出monitor 所以线程不会结束
  } // ObjectMonitor::exit 修改markword
});

// run threads
t1.start(); // t2.start();
t2.start(); // t1.start();
```



### Thread.sleep实现原理

Thread.sleep不是Object类的方法,自然其实现不在ObjectMonitor这个类里面Thread.sleep的本意是让出cpu的使用权,Thread.sleep(0)表示的意思是允许其他cpu抢占,按照竞争的激烈程度该线程能否抢占得到使用权不好说.

sleep的执行过程相比synchronized要简单很多

-   挂起线程并修改其运行状态为TIME_WAITING
-   设置定时器
-   当定时器到时间的时候把TIME_WAITING状态设置成Runnable,和其他线程抢占CPU

相比于synchronized,sleep本身的实现可以由c的alarm进行.

就语义而言,其和**LockSupport.park(time)**一样



---

**上半部分是jvm原生锁的一些控制,下半部分的原理性会更强,且将是JUC设计的核心技术,下半部分主要设计一些基本组件的构成包括AQS,包括线程池,请直接跳过参考JUC的使用之后阅读下面文段**

---



### JIT锁优化

JDK1.5到1.6是高效并发的大迈进,JDK1.6拥有了一系列的多线程技术,重量锁升级,自适应自旋锁,锁消除,锁粗化,轻量级锁和偏向锁.这里我们说明下之前没提到过的**锁粗化**和**锁消除**.

#### 锁粗化

在正常情况下我们应该减小锁的粒度(换言之就是尽可能使用小范围synchronized代码块),锁粗化则是加大锁的粒度,这是因为如果短时间内大量请求释放锁会带来很大的开销.比如以下情况

```java
public void doSomethingMethod(){
    synchronized(lock){
        //do some thing
    }
    //这是还有一些代码，做其它不需要同步的工作，但能很快执行完毕
    synchronized(lock){
        //do other thing
    }
}
public void doSomethingMethod(){
    synchronized(lock){
        //do some thing
    }
}
/*上面的代码块应该合并,因为重新申请锁需要涉及到内核态和用户态的切换非常浪费时间*/


for(int i=0;i<size;i++){
    synchronized(lock){
    }
}
synchronized(lock){
    for(int i=0;i<size;i++){
    }
}
/*反复的切换也会造成大量开销不如用下面代码一次申请到位*/
```

上面两种情况都可以根据JIT进行优化成相应的下面的代码,而这些优化仅在`java -server`模式下才会执行更高效的JIT优化.

#### 锁消除

锁消除同样是基于JIT的逃逸分析技术来判定锁是否会逃逸到线程以外,其需要开启参数`-sever -XX:+DoEscapeAnalysis -XX:+EliminateLocks`,举个例子就是栈变量StringBuffer其append方法是同步方法,如果我们只把其当成同步方法的话会产生不必要的切换,这个时候JIT就会帮我们优化把其加锁的部分去掉.



### CAS原子性保证

CAS Compare and Swap 又称**自旋锁**是一种典型的**乐观锁**,自旋指的是loop compare and swap,乐观是指,

CAS的伪代码实现如下

```c
void CAS(memoryAddress,func){
  a = getValueFromMemory(memoryAddress);
  // compute a by function and cost time
  b = func(a)
  if(a == getValueFromMemory(memoryAddress)){
    // if
    setMemory(memoryAddress,b)
  }else{
    // do nothing
  }
}
```

这个循环的运行结果只有一种情况 其思想相当简单 如果旧数据被改那么我重新再执行一遍计算 如果没被改 我就能把计算的值放到里面去 由于CAS 只用执行一条CPU指令所以其为原子性操作(当然也有很特殊的情况默认为是原子性)

其是一种无锁算法

三个参数内存值V 旧的期望值A 新的期望值B 当A=V时 把V修改为B 否则什么也不做.

#### 中断与最小实现

我们知道如果单纯用java去完成cas的话是有可能发生上下文切换的,这个之后我们的cas操作不是原子性的,所以unsafe类给了c++的一种实现,下面我们说下基本用法

```java
native boolean compareAndSwapInt(Object obj,long offset,int except,int value){
  int tmp = this.getIntVolatile(obj,offset);
  if(except == tmp){
    this.putIntVolatile(obj,offset,value);
    return true;
  }else{
    return false;
  }
} // 注意该方法是不可被中断的

// 然后我们实现下CAS循环修改对象中某字段的值
void compareAndAddInt(Object obj,long offset,int value){
  for(;;){
    int tmp = this.getIntVolatile(obj,offset);
    if(compareAndSwapInt(obj,offset,tmp,tmp+value)){
      break;
    }
  }
}

// 另一种写法
int compareAndAddInt(Object obj,long offset,int value){
 	int tmp;
  do{
  	tmp = this.getIntVolatile(obj,offset);
  }while(!compareAndSwapInt(obj,offset,tmp,tmp+value));
  return tmp;
}
```



#### ABA 问题

ABA问题,内存值本来为A,一线程用CAS修改A为B,另一线程用CAS修改A为A,两个线程如果交替的话可能会在第一个线程发生类似死锁的现象,A备份修改B,但备份过程中,另一线程修改回A导致反复不可抢占.所以正确的解决方式就是在变量后面加入版本号的机制,和变量本身一起进行判断.

在JUC中`AtomicStampedReference`有用来解决ABA问题.

```java
 public boolean compareAndSet(V   expectedReference,
                            V   newReference,
                            int expectedStamp,
                            int newStamp) {
   Pair<V> current = pair;
   return
       expectedReference == current.reference &&
       expectedStamp == current.stamp &&
       ((newReference == current.reference &&
         newStamp == current.stamp) ||
        casPair(current, Pair.of(newReference, newStamp)));
}
```

---

`sun.misc.Unsafe`提供了CAS的原子性实现,`java.util.concurrent.atomic.*`中大量调用了该类实现的CAS方法.其是一种在竞争不是特别激烈下性能比`synchronized`更高效的锁,后续在JUC包的使用下会理解更加深刻.



### **AQS 队列同步器(AbstractQueuedSynchronizer)**

AQS全称是AbstractQueuedSynchronizer,译为**队列同步器**,实际上在操作系统中是**等待队列**,AQS是JDK下提供的一套用于实现**基于等待队列**的阻塞锁和相关的同步器的一个同步框架.CAS代表了对资源抢占操作的一个实现,AQS同样如此,根据操作系统相关知识,其更加类似于队列的方式实现了多线程的核心机制.JUC包中`ReentrantLock`,`ReentrantReadWriteLock`,`Semaphore`是以此为基础构建的.

在基于AQS构建的同步器中,只能在**一个时刻发生阻塞**,从而降低上下文切换的开销,提高了吞吐量.总的来说AQS单独只是实现了等待队列的功能,其只需要负责线程的阻塞即可,线程的就绪和运行还是采用原生java的机制来执行(即EntrySet).

AQS的主要使用方式是继承,子类通过继承同步器并实现它的抽象方法来管理同步状态.

```java
class AQS extends AbstractQueuedLongSynchronizer{}
```

AQS内部用一个`(long)state`来表示线程状态,state>0表示获取了锁,state=0表示释放了锁,当线程获取锁失败时,AQS会把其同步信息封装成一个`Node`扔到等待队列去,等锁释放在从队列中唤醒该线程.我们在自定义同步器在实现时只**需要实现共享资源state的获取与释放方式**即可,至于具体线程等待队列的维护(如获取资源失败入队/唤醒出队等),AQS 已经在顶层实现好了.

---

在java的机制里就类似调用`wait`方法进入等待队列阻塞,等待`notifyAll`唤醒.而AQS充当等待队列的作用.

我们把AQS中分为三类

-   固定方法
-   可重写方法
-   模板方法

#### 固定方法

-   getState
-   setState
-   compareAndSetState(except,update) //CAS 原语操作,需要配合for循环获得自旋锁的效果

任何JUC或者我们自定义的锁都会用到这三个方法把队列给设置,`compareAndSetState`是`Unsafe`的方法,其为原语级别,保证CAS的原子性.



#### 可重写方法

我们需要自己实现一些方法才能使用AQS,独占模式下只用实现`*`的方法,因为AQS中其他维护队列方法调用了下列方法,所以我们实现的方法应当满足以下条件

-   *tryAcquire(int) 独占方式,尝试获取资源,成功true,失败false
    -   @Return true/false
-   *tryRelease(int) 独占方式,尝试释放资源,成功true,失败false
    -   @Return true/false
-   tryAcquireShared(int) 共享方式,尝试获取资源(看资源能否被同时使用)
    -   @Return  **失败时为负值,只能单个线程获取为0,所有线程都可获取为正**
-   tryReleaseShared(int) 共享方式,尝试释放资源
    -   @Return true/false
-   isHeldExclusively 该线程是否独占资源,只有用到`Condition`才需要实现它
    -   @Return true/false
    -   当前AQS是否在独占模式下被线程占用，一般表示是否被前当线程独占

#### 模板方法

模板方法即是AQS利用我们重写好的方法,封装了队列的操作后对外部提供的一种api

##### 独占锁的api

-   acquire(int arg)  请求独占锁
-   **acquireInterruptibly(int arg)**  请求独占锁,且可以响应中断
-   **tryAcquireNanos(int arg,long nanos)**  在上面函数的基础上,超时未获取到同步信息就返回false,否则返回true
-   release(int)  释放独占锁

##### 共享锁的api

-   acquireShared(int)  请求共享锁
-   **acquireSharedInterruptibly(int arg)** 获取共享锁,响应中断
-   **tryAcquireSharedNanos(int arg,long nanos)** 在上面函数的基础上,超时未获取到同步信息就返回false,否则返回true
-   releaseShared(int arg)   释放共享锁
-   getQueuedThreads()  获取等待在同步队列上的线程集合

简单实现下一次性独占锁

```java
private static class Sync extends AbstractQueuedSynchronizer {
  @Override
  protected boolean isHeldExclusively() {
    return getState() == 1;
  }
  
  @Override
  public boolean tryAcquire(int acquires) {
    if (compareAndSetState(0, 1)) {
      setExclusiveOwnerThread(Thread.currentThread());
      return true;
    }
    return false;
  }
  
  @Override
  protected boolean tryRelease(int releases) {
    if (Thread.currentThread() != getExclusiveOwnerThread()) {
      throw new IllegalMonitorStateException();
    }
    setExclusiveOwnerThread(null);
    setState(0);
    return true;
  }
  Condition newCondition() {
    return new ConditionObject();
  }
}

private static class Sync extends AbstractQueuedSynchronizer {
  Sync(int num) {
    if (num <= 0) {
      throw new RuntimeException("锁资源数量需要大于0");
    }
    setState(num);
  }

  @Override
  protected int tryAcquireShared(int arg) {
    for (;;) {
      int currentState = getState();
      int newState = currentState - arg;
      if (newState < 0 || compareAndSetState(currentState, newState)) {
        return newState;
      }
    }
  }

  @Override
  protected boolean tryReleaseShared(int arg) {
    //只能成功
    for (;;) {
      int currentState = getState();
      int newState = currentState + arg;
      if (compareAndSetState(currentState, newState)) {
        return true;
      }
    }
  }
}
```

可以看到实现独占锁的时候不需要实现CAS线程安全操作,这是因为一次只可能有一个线程获取成功才去修改状态,而共享锁是多个线程获取,所以涉及到状态修改的都要用CAS操作来保证其稳定性.



#### AQS内部原理以及代码分析

AQS内主要维护两个东西,`volatile int state`以及同步队列`CLH`,而队列的基本结构`Node`定义在AQS里面,这是一个`双端队列`,这个队列是`CLH锁`的一个变种,其每个Node在其**前置Node被释放的时候都会获得通知**,入队操作即是线程阻塞,原子性的添加到队尾,出队操作即是唤醒线程,并节点,需要注意的是该队列的头部只是个填充物(称为哨兵)无任何意义



##### CHL锁

CHL锁(Craig，Landin andHagersten创造)是一种基于链表的自旋锁,AQS内的队列是CHL锁的一个变种.用于SMP架构.申请加锁的线程通过**前驱节点的变量进行自旋**.在前置节点解锁后,当前节点会结束自旋,并进行加锁.如下

![](https://img-blog.csdnimg.cn/20181107191206507.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NsYXJhbQ==,size_16,color_FFFFFF,t_70)

线程B在等线程A执行完毕之后获取到了Node4,因为前面线程C还没执行结束,所以线程B在其前置节点上自旋等待

-   加锁逻辑(入队阻塞)
    -   获取当前线程的节点如果空就初始化
    -   同步方法获取tail
        -   如果不为空设为Node的前驱,并把tail设置为当前节点,当前线程自旋
        -   如果为空,则加锁成功
-   释放逻辑(出队唤醒)
    -   获取当前的线程节点(如果为空/无加锁状态则直接返回)
    -   CAS方法给tail赋值null
        -   赋值不成功则证明当前节点不是尾节点
        -   赋值成功修改状态

##### 条件队列

除了一CLH为模板实现的等待队列,还有为了Condition实现的条件队列,其和synchronized的wait/notifyAll不同的点在于,同一把锁的条件队列能有多个.条件队列类似于原生monitor中的\_waitSet,普通AQS队列类似于\_EntrySet,该队列是对线程等待功能的实现.

-   EntrySet和AQS的CLH队列用于线程抢占失败的等待
-   waitSet和Condition队列用于条件等待(必须受到notify/signal才能唤醒线程)

由于java的多线程是要依赖操作系统的多线程的,所以如果直接操控队列的话会比较困难,和monitor的实现有两项不同

-   其支持进入等待队列的线程不响应中断
-   其支持当前线程进入等待队列到未来的某个时间醒来

其常规方法在下面的JUC中有详细的说明,其两组方法对应如下

-   await / wait
-   signal / notify



##### 源码分析

源码分析主要分为7个部分,这几个部分共同构成了AQS

-   Node数据结构及状态
-   独占锁获取(入队阻塞)
-   独占锁释放(出队唤醒)
-   共享锁获取(入队阻塞)
-   共享锁释放(出队唤醒)
-   条件队列
-   其他辅助方法

其整个思路就是把Thread以及其状态封装成一个节点加入等待队列中去.以下为其实现加入的代码

AQS的队列结构可以看做CHL队列的改进

![](https://img-blog.csdnimg.cn/20200702231831934.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzc2NzAxNQ==,size_16,color_FFFFFF,t_70)

其中**头结点是获得锁的当前节点,而后续节点都是等待节点**

---

在说明下面具体实现时,我们先来看看这些队列线程安全方法的线程安全问题,涉及到对**共享变量**的读写.以下为AQS,JUC源码中体现出来的设计规范

-   如果是要读取某个值的指针(4Byte),则可认定其为原子性行为,无需做操作(比如AQS读取节点到局部变量中进行修改等),**但有可能会因为不保证可见性造成其错误**
-   如果要对某个指针进行判断,其相当于读取变量到栈中在移送CPU,理解逻辑按读处理
-   当写某个指针或是变量时,一定要用到CAS操作,写操作大多都是破坏线程安全的.(例如AQS中的state,head,tail,ConditionObject中的firstWaiter,lastWaiter等)
-   一切操作尽量发生在栈(stack)中,到最后在去修改堆(heap)中的值,使得CAS操作的粒度尽可能的小,不要**每个各操作都修改堆内存**,对堆内存的操作尽量减少到CAS赋值和读指针两种情况下.计算操作全部利用栈去操作.
-   关于if和while,如果是condition内部,容易发生中断等,且中断可认为时间比较长,在恢复中断后,if的条件仍然可能发生变化的不能用if,而要用while,其他情况下不需要反复判断的可以使用if,**或者在有显示或隐式释放锁(park)发生的使用使用while**
-   读写一致性的问题可以由volatile关键字(JVM规范保证)而不用借助指令集级别的原子性操作.
-   关于condition队列中大量的线程不安全操作,其实是因为获取了锁,所以其实方法调用时就已经不会发生线程安全问题了,不必在此处进行处理

###### Node的数据结构及其状态

我们先看下其数据结构Node

```java
static final class Node {

  /*AQS支持共享模式和独占模式两种类型，下面表示构造的结点类型标记*/
  /*共享模式下构造的结点，用来标记该线程是获取共享资源时被阻塞挂起后放入AQS 队列的*/
  static final Node SHARED = new Node();
  /*独占模式下构造的结点，用来标记该线程是获取独占资源时被阻塞挂起后放入AQS 队列的*/
  static final Node EXCLUSIVE = null;
  
  /*指示当前结点(线程)需要取消等待 由于在同步队列中等待的线程发生等待超时、中断、异常，即放弃获取锁，需要从同步队列中取消等待，就会变成这个状态如果结点进入该状态，那么不会再变成其他状态*/
  static final int CANCELLED = 1;
  
  /**指示当前结点（线程）的后续结点（线程）需要取消等待（被唤醒）如果一个结点状态被设置为SIGNAL，那么后继结点的线程处于挂起或者即将挂起的状态当前结点的线程如果释放了锁或者放弃获取锁并且结点状态为SIGNAL，那么将会尝试唤醒后继结点的线程以运行 这个状态通常是由后继结点给前驱结点设置的。一个结点的线程将被挂起时，会尝试设置前驱结点的状态为SIGNAL*/
  static final int SIGNAL = -1;
  /*线程在等待队列里面等待，waitStatus值表示线程正在等待条件原本结点在等待队列中，结点线程等待在Condition上，当其他线程对Condition调用了signal()方法之后该结点会从从等待队列中转移到同步队列中，进行同步状态的获取*/
  static final int CONDITION = -2;
  /*释放共享资源时需要通知其他结点，waitStatus值表示下一个共享式同步状态的获取应该无条件传播下去*/
  static final int PROPAGATE = -3;
  /*记录当前线程等待状态值，包括以上4中的状态，还有0，表示初始化状态*/
  volatile int waitStatus;

  volatile Node prev;
  volatile Node next;

  /*当前获取到同步状态的线程*/
  volatile Thread thread;
  
  Node nextWaiter; // 条件队列会使用到该字段,AQS的同步队列

  
  final boolean isShared() {
    return nextWaiter == SHARED;
  }

  Node() {
  }

  Node(Thread thread, Node mode) {
    this.nextWaiter = mode;
    this.thread = thread;
  }
```

AQS中于队列相关的数据结构

```java
public abstract class AbstractQueuedSynchronizer
            extends AbstractOwnableSynchronizer
            implements java.io.Serializable {
	private transient volatile Node head;
	private transient volatile Node tail;
	private volatile int state; 
  // 同步队列的核心状态,所有操作本质上都要尝试使用cas进行修改
}

public abstract class AbstractOwnableSynchronizer
    implements java.io.Serializable {
  private transient Thread exclusiveOwnerThread;
  // 对于排它锁的核心字段,有点像monitor中使用_owner字段来表示占用锁的线程
}
```

上面就是同步双端队列的基础数据结构



###### 独占锁的获取

利用上面数据结构(等待队列)对新线程进行加锁的逻辑

```java
// 获取独占锁
public final void acquire(int arg) {
   // 首先尝试获取,不成功的话则将其加入到等待队列,再for循环获取
   if (!tryAcquire(arg) &&
       acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
     // if这里做了个断点判断,如果tryAcquire成功的话,就不会入队
     // 如果失败的话那就尝试加入队列acquireQueued,这个函数一般返回true见下
     // Node.EXCLUSIVE 为null 仅用来标识
     selfInterrupt(); // 加入队列失败的话自己中断
 }

// 把封装好的线程节点加入队列,锁控制相关
// 这个方法调用的前提是tryAcquire失败和addWaiter成功把节点加入队列尾部
// @Return 如果在等待中被中断了返回true,否则返回false
final boolean acquireQueued(final Node node, int arg) {
  boolean failed = true;
  try {
    boolean interrupted = false;
    
    for (;;) {
      final Node p = node.predecessor();
      if (p == head && tryAcquire(arg)) {
        // 当节点的先驱是head的时候(这个head是随便new的见下无意义)
        // 就可以抢占资源唤醒线程了,这就相当于第二个节点在自旋(因为是独占锁)
        // 如果获取到资源,则将当前节点设置为头节点head
        setHead(node);
        p.next = null; 
        failed = false;
        return interrupted;
      }
      // 没获取到资源的情况(自然应该阻塞),或者不是头节点的情况(没有独占锁的意义阻塞)
      // 根据节点的等待状态判断是否应该park,如果应该就parkAndCheckInterrupt阻塞掉
      if (shouldParkAfterFailedAcquire(p, node) &&
          parkAndCheckInterrupt()) // 内部调用了park,如果应该中断返回true
        interrupted = true;
    }
  } finally {
    if (failed)
      cancelAcquire(node); 
    // 其内部判断完之后会调用LockSupport.unpark唤醒线程
    // 该方法是为了响应中断的,大部分情况下是不会执行此代码的
  }
}

// 把线程封装成节点
// 这里的mode为空,从数据结构的定义可知只是标识,独占锁不需要用到这成员变量
// 也就是说该方法把进入队列中等待的线程给加上了队列中已经获取到锁的线程
// @Return 封装好的节点,该节点在队列尾部
private Node addWaiter(Node mode) {
  // 封装当前线程和模式为新的节点,并且添加其等待的线程节点mode
  Node node = new Node(Thread.currentThread(), mode);
  
  // 加入到队列
  Node pred = tail; // 这个tail定义在AQS里面表示队列的结尾
  if (pred != null) { // 如果该队列有线程等待的话
    node.prev = pred; // 该节点入队(指向队尾) 
    if (compareAndSetTail(pred, node)) { 
      // CAS操作不允许中断,unsafe更改队尾指针,如果更改失败
      pred.next = node;
      return node;
    }
  }
  enq(node); 
  // 如果队列的尾部是空(即无线程等待)或者加入尾部失败(多个线程抢占)的话调用enq
  return node;
}  

// CAS保证入队(编程队尾)线程安全(如果没有初始化就初始化,否则就抢占加入尾部)
private Node enq(final Node node) {
  for (;;) {
    Node t = tail;
    if (t == null) { 
      // 队列的尾部是空的情况
      if (compareAndSetHead(new Node())) 
        // 循环CAS给队列初始化,如果其中一个初始化了,那么就会循环抢占插入尾部(妙啊)
        tail = head;
    } else {
      // 加入尾部失败的情况,循环抢占加入尾部
      node.prev = t;
      if (compareAndSetTail(t, node)) {
        t.next = node;
        return t;
      }
    }
  }
}
```

从其后者的实现来看,其本质上就是CLH队列,其不断尝试获取锁然后加入队列,然后获取到锁即设为头节点,没有获取到则进行阻塞并且扔到CLH队列里.

-   关于`doAcquireInterruptibly`的方法大同小异只是多了响应中断的功能,其核心使用了try-finally机制和`cancelAcquire(node)`去取消申请的锁使得线程可以响应中断

其核心的实现思路都一样,只是响应中断的这部分线程是遇到中断的线程就抛异常



###### 独占锁的释放

```java
public final boolean release(int arg) {
  if (tryRelease(arg)) { // 尝试释放锁,如果成功的话
    Node h = head;
    if (h != null && h.waitStatus != 0)
      unparkSuccessor(h); 
    // 尝试唤醒该线程的下个线程,每个后继节点都是前驱节点释放锁唤醒的
    // 公平锁此时会让排队节点获得锁,但非公平锁会让后继节点和当前节点抢占
    return true;
  } // 没有成功释放什么都不做返回false
  return false;
}

private void unparkSuccessor(Node node) {
  // 检查等待状态,如果还没改则改回去
  int ws = node.waitStatus;
  if (ws < 0)
    compareAndSetWaitStatus(node, ws, 0);

  // 唤醒后继节点,换言之就是唤醒第二节点
  Node s = node.next; 
  if (s == null || s.waitStatus > 0) {
    s = null;
    for (Node t = tail; t != null && t != node; t = t.prev)
      if (t.waitStatus <= 0)
        s = t;
  }
  if (s != null)
    LockSupport.unpark(s.thread);
}
```

独占锁的释放极其简单,其只用到等待队列里面唤醒线程即可,线程会自己进入c++的_EntrySet,并按照jvm的执行逻辑继续执行.

一般在我们自己实现tryAcquire里面,要使用`setExclusiveOwnerThread(Thread.currentThread())`来设置独占的线程,在tryRealse里面要使用`setExclusiveOwnerThread(null)`来设置其为空,

---

独占锁的获取exclusiveOwnerThread会记录获取锁的线程,我们要操控该字段和state字段,在获取时就可以通过判断exclusiveOwnerThread来确定自己是否是当前持有排他锁的线程.获取锁的失败的时候进入AQS然后挂起,而释放则直接判断是否能够释放,改变队列的指针,唤醒后继节点的线程.

其头部节点代表当前运行的线程,其后继节点即为等待的线程,公平锁的实现要判断下是否是第二个节点也就是第一个排队的节点.



###### 共享锁的获取

共享锁的设计和独占锁的最大不同是,独占锁需要时刻关注是否是本线程获得了锁在进入CLH队列进行挂起,而共享锁对锁的获取可以是多个线程一起获取(具体多少个看实现,独占为1),获取失败也要进入CLH队列.CountDownLatch,Semaphore都是共享锁实现的组件.所以唤醒线程的时机也会有不同,独占锁需要等待线程释放锁之后,而共享锁因为有多个线程一起同时获取,所以只要获取到锁以后就可以尝试唤醒下面的线程了.

另外tryAcquireShared,其返回值是有三种情况的1,0,-1分别代表获取成功,单个线程可获取获取失败,

**后面的源码告诉我们,tryAcquireShared和tryRealseShared都是需要我们自己用CAS实现线程安全的,**因为其需要多个线程同时唤醒节点,同时获取锁,同时释放锁

```java
public final void acquireShared(int arg) {
  if (tryAcquireShared(arg) < 0) // 尝试获取锁失败了
    doAcquireShared(arg);
}

/**
	如果获取锁失败了的话会执行以下方法,让节点进入等待队列
**/
private void doAcquireShared(int arg) {
  final Node node = addWaiter(Node.SHARED); 
  // 和独占锁区别封装节点,节点封装当前线程加入等待队列,CAS进入队列
  boolean failed = true;
  try {
    boolean interrupted = false;
    for (;;) {
      final Node p = node.predecessor();
      
      // 拿到该node前驱节点
      // 如果该线程不是第一个排队的线程的话,则判断是不是要阻塞
      if (p == head) {
        
        int r = tryAcquireShared(arg); // 尝试CAS获取共享锁
        if (r >= 0) {
          setHeadAndPropagate(node, r); 
          // 设置头部且判断后续节点要不要唤醒,设置头部表明当前节点的线程正在执行
          // 设置头部的操作可以理解为唤醒线程
          p.next = null; // Help GC
          if (interrupted) // 响应中断
            selfInterrupt();
          failed = false;
          return;
        } // 获取失败了,cas重新获取
      }
      
      // 该节点不是AQS第一排队节点,检查状态看看要不要进行挂起
      // 如果长时间获取不到会挂起
      if (shouldParkAfterFailedAcquire(p, node) &&
          parkAndCheckInterrupt())
        interrupted = true;
    
    } // for结束
  } finally {
    if (failed)
      cancelAcquire(node); // 线程被中断才会取消
  }
}

// propagate为传播,在这里理解为尝试获取锁的结果 1,0,-1
// 该方法,除了设置head之外还根据条件判断了要不要唤醒后面的节点
// 该方法由第一个排队节点调用,如果唤醒了下一个节点,那么下个节点会重新尝试获取共享锁
// 如果获取到了的话又继续往下唤醒,直至把所有线程都唤醒
private void setHeadAndPropagate(Node node, int propagate) {
  Node h = head;
  setHead(node);
  if (propagate > 0 || h == null || h.waitStatus < 0 ||
      (h = head) == null || h.waitStatus < 0) {
    // 如果是0的话就会进行后续断点判断,
    // 判断旧的头是不是空新的头是不是空,以及等待状态
    // 上面的判断的意思是如果该排队节点和以前的头结点都不为空的话
    Node s = node.next;
    if (s == null || s.isShared()) 
      // 根据该节点的下一个节点是否为共享节点决定唤醒,因为共享锁获取了锁之后就可以尝试
      // 唤醒后续的节点
      doReleaseShared();
  }
}
```

可以看到其实共享锁和独占锁都使用了addWaiter进入了相同的队列里面不同的是,独占锁使用了exclusiveOwnerThread字段来标识只能有当前线程进行使用.

###### 共享锁的释放

```java
public final boolean releaseShared(int arg) {
  if (tryReleaseShared(arg)) { // 如果尝试释放成功了就释放
    doReleaseShared();
    return true;
  }
  return false;
}
// 尝试唤醒一个后继节点,如果节点被唤醒可能会获取锁后setHeadAndPropagate继续唤醒线程
// 这样引起不断的传播最后会导致所有节点都被唤醒
private void doReleaseShared() {
  for (;;) {
    Node h = head;
    
    if (h != null && h != tail) {
      // 如果是队列中有不止一个节点
 
      int ws = h.waitStatus;
      if (ws == Node.SIGNAL) {
        // 多个线程同时抢占头结点修改其状态,但最终只会有一个修改成功
        if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
          continue;            // loop to recheck cases
        unparkSuccessor(h); // 如果能修改成功,那就唤醒线程
        
      }else if (ws == 0 && !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
        // ws==0 很显然已经被上面 CAS操作修改了,其他线程只需要把头结点改成了
        // 那显然该节点已经被唤醒了,把节点的状态修改成PROPAGATE,否则继续修改
        
        continue;                // loop on failed CAS
    }
    
    // 如果队列只有头节点的话
    // 检查有没有被替换,如果其他线程在这个过程中调用了setHeadAndPropagate
    // 那么久尝试唤醒新的头部,否则就结束循环
    if (h == head)                   // loop if head changed
      break;
  }// for结束
}
```

和独占锁不同,独占锁只有线程醒来之后才会唤醒后继节点,而共享锁无论是获取还是释放都有
可能唤醒下一个线程,获取锁之后就可以唤醒线程了,而不必等到释放.**这是因为共享锁的获取是多个线程同时获取,而共享锁的释放也是多个线程同时释放,所以我们必须要获取和释放的时候使用cas保证线程安全**



###### 条件队列

条件队列同样是使用了和CLH同样的数据结构内部节点Node.所以行为上和CLH队列一致,所有调用await()方法的线程会进入Condition队列进行等待.其会使用addWaiter封装成Node.CONDTION的节点插入等待队列的尾部挂起(WAITING).而等到其他线程使用signal后条件队列被唤醒的线程会**进入到同步队列**中抢占锁.相对于AQS类直接内部实现的同步队列一样,条件队列是在AQS的内部类ConditionObject中实现的,如果熟悉JUC的源码就会发现.ConditonObject相当于Sync的实现.

虽说数据结构和AQS的同步队列一致,但是节点内容和AQS还是不同的

```java
public class ConditionObject implements Condition, java.io.Serializable {
	private transient Node firstWaiter;
	private transient Node lastWaiter; 
}
```

和AQS一样都是双端队列的结构,相比同步队列的不同即没有哨兵节点

![](https://img-blog.csdnimg.cn/20200703115521789.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzc2NzAxNQ==,size_16,color_FFFFFF,t_70)

await方法实现

await方法和wait一样是会直接释放锁的,其行为基本一致

```java
public final void await() throws InterruptedException {
  if (Thread.interrupted())
    throw new InterruptedException();
  
  Node node = addConditionWaiter(); // 加入等待队列队尾
  int savedState = fullyRelease(node); // 保存锁的状态,尝试释放线程的锁
  
  int interruptMode = 0;
  while (!isOnSyncQueue(node)) { // 节点不在AQS队列上
    LockSupport.park(this); // 挂起当前线程这个this只是用来记录那个对象挂的
   
    // 这下面是线程被唤醒的,如果中断状态不对重新park,如果中断的话退出循环
    if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
      break;
    // 如果没有发生中断那就是被signal掉的,已经加入了AQS就isOnSyncQueue就会为true
  }
  
  // 走到这说明线程节点在同步队列中了,即刚进入条件队列就被signal了
  // acquireQueued自旋获取条件队列独占锁,然后清除条件队列节点
  if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
    interruptMode = REINTERRUPT;
  if (node.nextWaiter != null) // clean up if cancelled
    unlinkCancelledWaiters();// 清除条件队列所有不在等待的节点,更新条件队列
  if (interruptMode != 0)
    reportInterruptAfterWait(interruptMode);
  // 如果被signal掉了就往下执行其他语句,所以这里就不用释放锁了,上下文中的代码
  // lock.unlock会释放锁
}

// 把节点添加到条件队列
private Node addConditionWaiter() {
  Node t = lastWaiter;
  // If lastWaiter is cancelled, clean out.
  if (t != null && t.waitStatus != Node.CONDITION) {
    unlinkCancelledWaiters();
    t = lastWaiter;
  }
  
  // 封装当前线程节点(注意这个是全新的节点,和AQS在堆内存的节点毫无关系)
  Node node = new Node(Thread.currentThread(), Node.CONDITION);
  if (t == null) // 如果是第一个节点
    firstWaiter = node;
  else // 如果不是第一个节点
    t.nextWaiter = node; // 那就把节点添加到后面
  lastWaiter = node; // 队尾指针指向当前节点
  return node;
}

// 清楚所有不在等待的节点,组建新的条件队列
private void unlinkCancelledWaiters() {
  Node t = firstWaiter; // 条件队列头结点
  Node trail = null; // 用来存储下一个等待节点,用于更新头结点
  while (t != null) {
    Node next = t.nextWaiter;
    if (t.waitStatus != Node.CONDITION) {
      // 不在等待状态,要清理节点
      t.nextWaiter = null;
      if (trail == null)
        firstWaiter = next; // 更新头结点
      else
        trail.nextWaiter = next; // 更新头结点的下一个等待节点
      if (next == null)
        lastWaiter = trail;
    }
    else // 如果是条件队列的节点在等待状态
      trail = t;
    t = next; // 指针更新
  }
}

// 完全释放锁
final int fullyRelease(Node node) {
  boolean failed = true;
  try {
    int savedState = getState();
    if (release(savedState)) {
      failed = false;
      return savedState;
    } else {
      throw new IllegalMonitorStateException();
    }
  } finally {
    if (failed)
      node.waitStatus = Node.CANCELLED;
  }
}

// AQS中的释放锁,唤醒节点,判断释放是否成功
public final boolean release(int arg) {
  if (tryRelease(arg)) { // 这个tryRelase是使用了AQS中的方法,和unlock的实现一致
    Node h = head;
    if (h != null && h.waitStatus != 0)
      unparkSuccessor(h);
    return true;
  }
  return false;
}

```

我们看下signal和signalAll的实现

```java
public final void signal() {
  if (!isHeldExclusively())
    throw new IllegalMonitorStateException();
  // 判断队列是否是可以被signal的
  Node first = firstWaiter;
  if (first != null)
    doSignal(first);
}

public final void signalAll() {
  if (!isHeldExclusively())
    throw new IllegalMonitorStateException();
  
  Node first = firstWaiter;
  if (first != null)
    doSignalAll(first);
}

private void doSignal(Node first) {
  do {
    if ((firstWaiter = first.nextWaiter) == null) 
      // 条件队列头指针往下移,如果下个节点为空
      lastWaiter = null; // 那么条件队列队尾指向空,即唤醒唯一线程first
    first.nextWaiter = null; 
    // 如果条件队列只有一个节点那么这句话就没啥用,虽然也没啥损失
    // 如果条件队列的节点有很多个的话,那么头结点的等待线程消失(因为头节点的
    // 等待线程已经变成了新的头结点) 可以把这句话理解为Help GC
    
  } while (!transferForSignal(first) && (first = firstWaiter) != null);
  // first = firstWaiter 指针往下移一次 其实就是frist = frist.waiter
  // 整个while的终止条件就是first.nextWaiter == null,这个时候会清空队列和节点
}

// CAS修改等待状态,并把节点转义到同步队列,如果该方法返回false,则会一直修改,如果修改成功了就会一直执行到下面返回true把上面的while循环break掉
// 也就完成了loop-CAS执行的操作
final boolean transferForSignal(Node node) {
    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
        return false;

    Node p = enq(node); // 添加到同步队列
    int ws = p.waitStatus;
  	// 下面这个CAS是用来修改同步队列的状态的,如果修改失败的话就不唤醒线程,
  	// 属于条件队列进入CAS抢占CPU
    if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
        LockSupport.unpark(node.thread); // 唤醒线程
    return true;
}


private void doSignalAll(Node first) {
  lastWaiter = firstWaiter = null;
  do {
    Node next = first.nextWaiter;
    first.nextWaiter = null;
    transferForSignal(first); // 把所有线程都尝试唤醒一遍,即加入等待队列
    first = next;
  } while (first != null);
}
```



###### 其他辅助方法

-   setExclusiveOwnerThread 
    -   通常在获取独占锁tryAcquire的时候需要使用该方法设置当前线程
    -   在tryRealse释放独占锁的时候需要设置为null
-   getExclusiveOwnerThread
    -   该方法在读锁里面可以判断写者是否在独占
    -   在其他独占锁的tryAcquire里通过判断状态和是否有线程在使用锁来尝试获取
-   hasQueuedPredecessors
    -   是否有头结点,即是否有线程在运行
-   apparentlyFirstQueuedIsExclusive
    -   排队的节点(即第二节点)是不是排他锁
-   isHeldExclusively
    -   本线程是否占有exclusiveOwner,即是否本线程获得了排它锁
-   newCondition
    -   产生一个condtion对象



---

#### JUC的例子(AQS的应用)

AQS实现`CountDownLatch`和`ReentrantLock`,此处需要了解JUC工具的使用之后再回头来看,同时建议参考AQS的其他实现代码,Unsafe类来看下面实现理解会更深

##### ReentrantLock源码分析

我们看其实现就是利用sync队列去实现

```java
private final Sync sync;
public void lock() {
  sync.lock();
}
public void unlock() {
  sync.release(1);
}
// 其队列的初始化在构造函数的时候就有了
public ReentrantLock(boolean fair) {
  sync = fair ? new FairSync() : new NonfairSync();
}
```

我们先看下其队列的实现

```java
static final class NonfairSync extends Sync {
  final void lock() {
    if (compareAndSetState(0, 1))
      setExclusiveOwnerThread(Thread.currentThread());
    	// 非公平锁的加锁逻辑,如果是第一个线程就相当于直接获得锁了不需要AQS同步队列
    	// 如果是不能直接获得锁,就要去请求获取锁,对于公平锁而言,获取锁的永远是AQS的首个
    	// 排队的线程,则体现出公平,而不需要CAS抢占
    	/*上锁的线程可以直接抢占,不用经过AQS,公平锁就没这么多事了*/
    else
      acquire(1);
  }

  protected final boolean tryAcquire(int acquires) {
    return nonfairTryAcquire(acquires); 
    // 该方法在Sync实现,而tryAcquire实现了AQS的机制,所以tryAcquire
  }
}

static final class FairSync extends Sync {
  final void lock() {
    acquire(1); // 和上面比起来巨没有CAS直接去抢占了,我们看下这下面的逻辑如何走
  }

  protected final boolean tryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) { // AQS的state设计0代表没有上锁的状态,即初始化
      if (!hasQueuedPredecessors() &&
          compareAndSetState(0, acquires)) { 
        // 检查AQS队列是否有头部,如果有头部证明有线程在运行(头结点的含义)
        // 入过没有头部就开始第一次申请锁,CAS操作下,修改值,修改不成功证明有其他锁抢占
        // 那就
        setExclusiveOwnerThread(current);
        return true;
      }
    } // state>0 证明已经有线程获取到了排它锁
    else if (current == getExclusiveOwnerThread()) {
      int nextc = c + acquires; 
      // acquires一般是1,表意为获取一个锁,此处即是可重入锁
      if (nextc < 0) // 非法值
        throw new Error("Maximum lock count exceeded");
      setState(nextc); // 这里不需要CAS是因为AQS在实现的时候已经是CAS获取锁
      return true;
    } // 本线程没有获取到排它锁不允许
    
    
    return false;
  }
}
```

剩余的实现都在Sync同步队列内部

```java
abstract static class Sync extends AbstractQueuedSynchronizer {
  private static final long serialVersionUID = -5179523762034025860L;

  abstract void lock(); // 公平队列和非公平队列的实现都不一样

  final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
      if (compareAndSetState(0, acquires)) { 
        // 唯一的不同就是此处无需判断头部是否有节点,非公平队列直接进行抢占,
        // 抢占失败直接进入AQS队列
        setExclusiveOwnerThread(current);
        return true;
      }
    }
    else if (current == getExclusiveOwnerThread()) {
      int nextc = c + acquires;
      if (nextc < 0)
        throw new Error("Maximum lock count exceeded");
      setState(nextc);
      return true;
    }
    return false;
  }
  
  protected final boolean tryRelease(int releases) {
    int c = getState() - releases; // 释放锁,可重入的支持
    // 看看有无锁,如果没有获取锁抛出异常
    if (Thread.currentThread() != getExclusiveOwnerThread())
      throw new IllegalMonitorStateException();
    
    boolean free = false;
    if (c == 0) {
      free = true;
      setExclusiveOwnerThread(null);
    }
    setState(c);
    return free; // 当降到0的时候可以释放锁,没降到0只是更新state
  }
  
	// 我们来看下AQS其他方法的实现
  protected final boolean isHeldExclusively() {
    return getExclusiveOwnerThread() == Thread.currentThread();
  }

  final ConditionObject newCondition() {
    return new ConditionObject(); // 实现了条件队列,我们可以使用Condition的功能
  }

  final Thread getOwner() {
    return getState() == 0 ? null : getExclusiveOwnerThread();
  }

  final int getHoldCount() {
    return isHeldExclusively() ? getState() : 0; 
    // 简单获取状态,0表示有没有线程获取到锁
  }

  final boolean isLocked() {
    return getState() != 0;
  }
  
	// 利用流反序列化
  private void readObject(java.io.ObjectInputStream s)
    throws java.io.IOException, ClassNotFoundException {
    s.defaultReadObject();
    setState(0); // reset to unlocked state
  }
}

```



##### CountDownLatch源码分析

countdowlatch的源码在这三者之间算是最为简单的,因为其只用维护状态count而并不像其他两者需要的状态之多

```java
public class CountDownLatch {
    /**
     * 基于AQS的内部Sync同步队列
     * 我们要自定义一种锁,这种锁加载一种资源上,这种资源能用count表示其状态,当
     * count=0的时候表示该资源可用(可以获取其锁/使用权),在count不为0的时候不允许使用
     * (不允许其他线程获得锁/获取锁失败)当count=0刚好可用的时候允许其他线程获得锁
     * 这里共享并无释放意义只是作为状态count更改,所以AQS并不是完全按照java原生那般
     *
     * 用原生java的思路去做就是,获取资源的锁,使用资源,释放锁
     * 但与java原生不同的是java获取的是1个对象的锁情况比较简单,而AQS可能涉及到条件
     * 获取锁,获取失败可能改变状态,条件释放锁,把这里的获得和释放理解为状态的变化,或者是
     * 锁资源/锁条件(不是资源加锁的意思)的生产和消费/达成和创造会很容易操作
     *
     * CountDownLatch/AQS的思路是线程tryAcquireShared消耗锁资源(失败进入队列等
     * 待,成功继续执行代码)tryReleaseShared生产锁资源(成功唤醒线程unpark,失败返回
     * false)
     */
    private static final class Sync extends AbstractQueuedSynchronizer {
        private static final long serialVersionUID = 4982264981922014374L;

        Sync(int count){setState(count);} // Sync的构造函数
				
        int getCount(){return getState();} // 获取count属性

        // 在共享模式下尝试获取锁
        protected int tryAcquireShared(int acquires) {
						// 失败时为负值,只能单个线程获取为0,所有线程都可获取为正
            return (getState() == 0) ? 1 : -1;
        }

        // 在共享模式下尝试释放锁
        protected boolean tryReleaseShared(int releases) {
          	// true释放成功,false释放失败
          	// 下面是CAS操作确保c-1操作成功
            for (;;) { // 如果后续compareAndSetState设置失败了会返回
                int c = getState();
                if (c == 0)
                    return false; // 如果已经是0了就已经资源用完了,所以释放失败
                int nextc = c-1; // compute | 消耗资源生产 	
                if (compareAndSetState(c, nextc)) // 原语
                    return nextc == 0; 
// 如果不是0的话不会释放,如果已经降到了0说明刚好,可以释放资源的锁(返回true)
            }
        }
    } // 定义Sync完毕,可以看到Override了2个方法,利用一个方法传禁了AQS内部

    private final Sync sync;

    
    public CountDownLatch(int count) {
        if (count < 0) throw new IllegalArgumentException("count < 0");
        this.sync = new Sync(count); // 初始化同步队列
    } // 构造函数

    // 让当前线程阻塞直到计数count变为0，或者线程被中断
    public void await() throws InterruptedException {
        sync.acquireSharedInterruptibly(1);
      	// 获取锁(同步状态)(使用权)
      	// 因为当没进行完countDown时tryAcquireShared返回-1,则调用该方法的线程阻塞
    }

    // 阻塞当前线程，除非count变为0或者等待了timeout的时间。当count变为0时，返回true
    public boolean await(long timeout, TimeUnit unit)
        throws InterruptedException {
        return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
    }

    // count递减
    public void countDown() {
        sync.releaseShared(1); // 这个参数无意义瞎写都行
      	// 释放锁(其实是改变状态),每次countDown完后,count这种资源减少1
    }
}
```

从其内部状态我们也可以知道,tryReleaseShared方法其实是一个用来改变状态的方法,tryAcquireShared也是用来判断锁的状态的,其在AQS的源码中?



##### ReentrantReadWriteLock源码分析

`Sync`其有`HoldCounter`和`ThreadLocalHoldCounter`这两个内部类

```java
/**
	* A counter for per-thread read hold counts.
	* Maintained as a ThreadLocal; cached in cachedHoldCounter
  */
static final class HoldCounter {
  int count = 0;
  // Use id, not reference, to avoid garbage retention
  final long tid = getThreadId(Thread.currentThread());
}

/**
	* ThreadLocal subclass. Easiest to explicitly define for sake
	* of deserialization mechanics.
	*/
static final class ThreadLocalHoldCounter
  extends ThreadLocal<HoldCounter> {
  public HoldCounter initialValue() {
    return new HoldCounter();
  }
}
private transient ThreadLocalHoldCounter readHolds;
```

上面三行就是典型的ThreadLocal的用法,其让每个使用`Sync`线程有个count.然后我们看`Sync`的其他部分的实现.

```java
// 高16位为读锁，低16位为写锁
static final int SHARED_SHIFT   = 16;
// 读锁单位
static final int SHARED_UNIT    = (1 << SHARED_SHIFT);
// 读锁最大数量
static final int MAX_COUNT      = (1 << SHARED_SHIFT) - 1;
// 写锁最大数量
static final int EXCLUSIVE_MASK = (1 << SHARED_SHIFT) - 1;
// 线程计数器
private transient ThreadLocalHoldCounter readHolds;
// 缓存的计数器
private transient HoldCounter cachedHoldCounter;
// 第一个读线程
private transient Thread firstReader = null;
// 第一个读线程的计数
private transient int firstReaderHoldCount;
```

![](http://static.open-open.com/lib/uploadImg/20151031/20151031223319_397.png)

其state的设计思路如上,高16位用于读状态,低16位用于写状态.我们就把4Byte的int分成了16位读16位写

-   获取读状态 state>>>16
-   获取写状态 state&0xffff
-   读状态+1 state+=(1<<16)
-   写状态+1 state+=1

当读/写状态都>0时可以说明已经读写/锁被线程获取了.其值的大小表示重入的次数

```java
class WriteLock{
  ...
  public void lock() {
      sync.acquire(1);
  }

  public void unlock() {
      sync.release(1);
  }
  ...
}
// 获取写锁(排他锁)
protected final boolean tryAcquire(int acquires) {
  Thread current = Thread.currentThread();
  int c = getState();
  // 写线程数量（即获取独占锁的重入数）
  int w = exclusiveCount(c);

  
  if (c != 0) { // 有其他线程获取了读锁或写锁
    if (w == 0 || current != getExclusiveOwnerThread())
      return false; 
    	// 如果没有写锁或者非当前线程在独占写锁的话,不能获取,如果只有读锁则无所谓直接获取
			// 从下面读者的操作来看,如果有线程在读不可以直接获取读锁的,除非该线程获取了写锁
    
    // exclusive获取的是低16位的状态
    if (w + exclusiveCount(acquires) > MAX_COUNT)
      throw new Error("Maximum lock count exceeded");
    // 更新状态
    setState(c + acquires); //  acquires为1在lock的时候,即自增 
    return true; // 可以获取写锁
  }

  // 读锁和写锁都没有被获取
  // writerShouldBlock表示是否应该阻塞,即写者是否需要等待,公平锁要等待(加入AQS),
  // 而非公平锁就直接用了(写优先)
  if (writerShouldBlock() ||
      !compareAndSetState(c, c + acquires))
    return false;

  // 设置锁为当前线程所有,设置了之后,如果是再度获取读锁就可以通过队列变量判断锁获取的
  // 情况,从而完成一个重要的机制锁降级
  setExclusiveOwnerThread(current); // 独占锁需要设置该函数
  return true;
}
```

这里我们研究下`writerShouldBlock`其是一个抽象方法,其实现有两种

```java
static final class NonfairSync extends Sync {
  private static final long serialVersionUID = -8159625535654395037L;
  final boolean writerShouldBlock() {
    return false; // writers can always barge
  }
  final boolean readerShouldBlock() {
    return apparentlyFirstQueuedIsExclusive(); // 当前执行线程的是否独占写锁
  }
}

static final class FairSync extends Sync {
  private static final long serialVersionUID = -2274990926593161451L;
  final boolean writerShouldBlock() {
    return hasQueuedPredecessors();
  }
  final boolean readerShouldBlock() {
    return hasQueuedPredecessors();
  }
}
```

我们看一看到,公平队列判断了是否有线程在队列等待,而不公平锁是writer不会相应等待队列,即writer优先抢占.**即公平的读写锁是读锁写锁按序入AQS按顺序进行cpu抢占,而非公平锁即写优先锁**

写锁的释放如下

```java
protected final boolean tryRelease(int releases) {
    // 若锁的持有者不是当前线程,抛出异常
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
    // 写锁的线程数
    int nextc = getState() - releases;
  
    boolean free = exclusiveCount(nextc) == 0;
  	if (free)
        // 若写锁的新线程数为0，则将锁的持有者设置为null
        setExclusiveOwnerThread(null);
    
  	// 设置写锁的新线程数,即降到0则释放,如果没降到0就表示可重入次数少1
    setState(nextc);
    return free;
}
```

从上面写锁的实现,我们就可以看出来读锁应该怎么去设计,例如`getExclusiveOwnerThread()`可以判断写锁是否在使用,而读锁的难点在于怎么让读锁共享的同时还和写锁互斥如下

```java
class ReadLock{
  ...
  public void lock() {
    sync.acquireShared(1);
  }
  public void unlock() {
    sync.releaseShared(1);
  }
}

// 我们来看读锁的实现
// 读锁也需要获取
protected final int tryAcquireShared(int unused) {
  // 获取当前线程
  Thread current = Thread.currentThread();
  // 获取状态
  int c = getState();

  // 如果写锁线程数!=0,且独占锁不是当前线程则返回失败,因为存在锁降级
  // 换句话说就是队列存在独占锁的情况且独占锁不是当前线程就不能获取读锁
  // 要么是全部线程都没在写,要么只有本线程在写
  /*
 		从这里我们看下锁降级过程,获取读锁的时候如果持有写锁,那么getExclusiveOwnerThread
 		获取的是本线程,如果本线程不持有写锁,那么本线程得看看有没有其他线程在写,如果有其他线
 		程在写,那么获取锁失败,加入AQS列等待,反之则获取锁成功,那对于锁升级而言,获取了读锁再
 		去获取写锁会进入阻塞(参考共享锁实现)
  */
  if (exclusiveCount(c) != 0 &&
      getExclusiveOwnerThread() != current)
    return -1;
  
  // 读锁数量
  int r = sharedCount(c);
  
  // 读线程是否应该被阻塞,本质上是
  // apparentlyFirstQueuedIsExclusive/hasQueuedPredecessors.
  // 这两个是非公平对列/公平队列AQS内部方法,对公平锁而言,只要有线程在AQS等待就得阻塞
  // 对非公平锁而言,只要没有排它锁存在直接用即可
  if (!readerShouldBlock() &&
      r < MAX_COUNT &&
      compareAndSetState(c, c + SHARED_UNIT)) {
    if (r == 0) {
      // firstReader和firstReaderHoldCount是Sync的变量
      // 记录下读的线程
      firstReader = current;
      firstReaderHoldCount = 1;
    } else if (firstReader == current) { 
      firstReaderHoldCount++;
    } else { // 如果当前线程不是第一个读线程
      HoldCounter rh = cachedHoldCounter; 
      // cachedHoldCounter为一个HoldCounter缓存
      // 如果没有缓存HoldCouter,或者缓存了其他线程的HoldCounter则需要刷新缓存
      if (rh == null || rh.tid != getThreadId(current))
        // 从ThreadLocalMap中,缓存并刷新rh的引用
        cachedHoldCounter = rh = readHolds.get();
      else if (rh.count == 0)
      // 加入到readHolds中,readHolds为一ThreadLocal变量,在Sync构造的时候初始化
        readHolds.set(rh);
      // 计数+1
      rh.count++;
    }
    return 1;
  }
  // 上面这一串代码都是能否立即获取到读锁,如果能立即获取到读锁进行的一些处理
  // 如果不能获取到读锁的话,进行fullTryAcquireShared,即完成版本的获取读锁
  // 所以上面更多的是看出来一种优化,对特殊情况进行快速处理而不必CAS占资源
  return fullTryAcquireShared(current);
}
final int fullTryAcquireShared(Thread current) {
  HoldCounter rh = null;
  for (;;) { // CAS经典写法,循环获取锁
    
    int c = getState();
    if (exclusiveCount(c) != 0) { // 有写锁
      if (getExclusiveOwnerThread() != current)
        return -1; // 当前线程没有获取写锁,则不能读
    } else if (readerShouldBlock()) { // 没有写锁且应该阻塞
      // 下面代码确保没有重复获取可重入锁
      if (firstReader == current) {
        // assert firstReaderHoldCount > 0;
      } else { // 当前线程不是第一个读线程的情况下
        
        if (rh == null) {
          // 获取读线程的个数缓存,刷新缓存
          rh = cachedHoldCounter; 
          if (rh == null || rh.tid != getThreadId(current)) {
            rh = readHolds.get();
            if (rh.count == 0) // 没有线程在读就去掉缓存
              readHolds.remove();
          }
        }
        if (rh.count == 0) 
          // rh上次for的时候已经获取到了就检查下count是不是有线程在读
          return -1; 
        
      } // 获取到正确的rh即读线程的计数器
    }
    
    
    if (sharedCount(c) == MAX_COUNT)
      throw new Error("Maximum lock count exceeded");
    
    if (compareAndSetState(c, c + SHARED_UNIT)) { // 尝试CAS获取读锁
      if (sharedCount(c) == 0) {
        firstReader = current;
        firstReaderHoldCount = 1;
      } else if (firstReader == current) {
        firstReaderHoldCount++;
      } else { // 如果不是第一个读线程的话
        if (rh == null)
          rh = cachedHoldCounter;
        if (rh == null || rh.tid != getThreadId(current))
          rh = readHolds.get();
        else if (rh.count == 0)
          readHolds.set(rh);
        rh.count++;
        cachedHoldCounter = rh; // cache for release
      }
      return 1; // 返回状态,告诉tryAcquired 尝试获取成功
    } // CAS操作完毕
  } // loop完毕
}
```

我们看下读锁的释放

```java
protected final boolean tryReleaseShared(int unused) {
  Thread current = Thread.currentThread();
  if (firstReader == current) {
    // assert firstReaderHoldCount > 0;
    if (firstReaderHoldCount == 1)
      firstReader = null;
    else
      firstReaderHoldCount--;
    // 维护标识状态
  } else { // 如果当前线程不是第一读者线程的话
    HoldCounter rh = cachedHoldCounter;
    if (rh == null || rh.tid != getThreadId(current))
      rh = readHolds.get();
    int count = rh.count;
    if (count <= 1) {
      readHolds.remove();
      if (count <= 0)
        throw unmatchedUnlockException(); // 没锁异常
    }
    --rh.count; // 读者线程数量减少1,只要减少一次
  }
  for (;;) {
    int c = getState();
    int nextc = c - SHARED_UNIT;
    if (compareAndSetState(c, nextc)) // 尝试改变状态
      return nextc == 0; // 等待所有读者退出线程那么就可以释放了
  }
}
```

ReentrantReadWriteLock可以说把Sync/AQS对列的特点发挥到了极致,涉及到了排它锁和共享锁同时存在,通过count的状态去判断读锁和写锁的各种逻辑的设计.也可以说该锁的实现原理充分说明了AQS应该如何去设计和使用.

-   设计AQS内部state状态
-   考虑清楚独占和共享的获取条件,对于一些特殊的结构(多个读者线程需要通过ThreadLocal补全数据结构等).



### Future模式

Future是多线程中的一种接口模式,如下Future能够帮助耗时计算记录计算结果,让主线程能够直接进行下一阶段的调度而不是花时间到计算上.如下模式,我们通过IO知道其很容易去实现,就是开启一个额外的线程使得耗时的计算或I/O由另一核心来完成.

![](https://img-blog.csdn.net/20180822223159761?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTk4MDEx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![](https://img-blog.csdn.net/20180822223415451?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTk4MDEx/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

我们利用接口对上面的流程进行封装

```java
interface Future {
    Object computeFuture();
    Object getResult();
}

class FutureTask implements Future {
    volatile boolean isReady = false;
    volatile Object result;
    volatile Computable computable;
    final Lock lock = new ReentrantLock();
    final Condition ready = lock.newCondition();

    FutureTask(Computable computable) {
        this.computable = computable;
    }


    @Override
    public Object getResult() {
        lock.lock();
        try {
            while (!isReady) {
                ready.await();
            }
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            lock.unlock();
        }
        return result;
    }

    @Override
    public Object computeFuture() {
        lock.lock();
        try {
            this.result = computable.compute();
            isReady = true;
            ready.signalAll();
            return this.result;
        } finally {
            lock.unlock();
        }
    }
}

@FunctionalInterface
interface Computable {
    Object compute();
}
// 其实就是额外开个线程去执行,总共用时5秒,这里需要两个核心线程就满载了
@Test
public void test() throws InterruptedException {
  FutureTask futureTask = new FutureTask(() -> {
    try {
      System.out.println("begin compute");
      Thread.sleep(5000);
      System.out.println("finish compute");
    } catch (InterruptedException e) {
      e.printStackTrace();
    }
    return "finish";
  });

  Thread t = new Thread(() -> {
    futureTask.computeFuture();
  });
  t.start();
  System.out.println("do other things");
  Thread.sleep(3000);
  System.out.println("finish other things");
  System.out.println(futureTask.getResult());
}
```

我们可以看下jdk原生的java是如何实现的如上结构的

```java
public interface Future<V> {
    boolean cancel(boolean mayInterruptIfRunning); // 取消计算
    boolean isCancelled(); 
    boolean isDone();
    V get() throws InterruptedException, ExecutionException;
    V get(long timeout, TimeUnit unit)
        throws InterruptedException, ExecutionException, TimeoutException;
}
@FunctionalInterface
public interface Runnable {
    public abstract void run();
}
public interface RunnableFuture<V> extends Runnable, Future<V> {
    void run();
}
public class FutureTask<V> implements RunnableFuture<V> {...}
```

我们从继承关系可以看出`FutureTask`是`Runnable`的实现类,且其实现了`Future`接口,如上我们就知道了其有一get函数相当于我们实现的`computeFuture`.`Future`接口会控制`FutureTask`的完成与否,下面是`FutureTask.run`方法的实现,其方法用到Unsafe(参考多线程文档)

```java
public void run() {
  if (state != NEW ||
      !UNSAFE.compareAndSwapObject(this, runnerOffset,
                                   null, Thread.currentThread()))
    // CAS运行修改Task的线程,修改成功了才能及所需
    return;
  try {
    Callable<V> c = callable;
    if (c != null && state == NEW) {
      V result;
      boolean ran;
      try {
        result = c.call();
        ran = true;
      } catch (Throwable ex) {
        result = null;
        ran = false;
        setException(ex); // 保存call方法抛出的异常
      }
      if (ran)
        set(result); // 保存call方法的执行结果
    }
  } finally {
    // runner must be non-null until state is settled to
    // prevent concurrent calls to run()
    runner = null;
    // state must be re-read after nulling runner to prevent
    // leaked interrupts
    int s = state;
    if (s >= INTERRUPTING)
      handlePossibleCancellationInterrupt(s);
  }
}
```

其实和我们实现的很像run的过程就是调用函数保存状态,包括了异常状态的处理.

其内部还维护着一个队列`waiters`内部类`NodeWaiter`的数据结构,该结构简单封装线程,其状态标识state主要有这几种情况

-   执行过程顺利完成：NEW -> COMPLETING -> NORMAL
-   执行过程出现异常：NEW -> COMPLETING -> EXCEPTIONAL
-   执行过程被取消：NEW -> CANCELLED
-   执行过程中，线程中断：NEW -> INTERRUPTING -> INTERRUPTED

```java
public V get() throws InterruptedException, ExecutionException {
  int s = state;
  if (s <= COMPLETING)
    s = awaitDone(false, 0L);
  return report(s);
}
/*等待nanos纳秒,如果到时间还没计算出来则直接返回state*/
private int awaitDone(boolean timed, long nanos)
        throws InterruptedException {
  final long deadline = timed ? System.nanoTime() + nanos : 0L;
  WaitNode q = null; // WaitNode是一内部类
  boolean queued = false;
  
  for (;;) {
    if (Thread.interrupted()) { // 如果线程被中断了就退出等待队列
      removeWaiter(q);
      throw new InterruptedException();
    }

    int s = state;
    if (s > COMPLETING) {  // 说明要么正常结束,要么就是异常取消了
      if (q != null)
        q.thread = null; // 那么直接把该线程所在的节点置空
      return s;
      
      
    }else if (s == COMPLETING) // cannot time out yet
      Thread.yield();
    else if (q == null)
      q = new WaitNode(); // 如果是新来获取数据的线程直接等待
    else if (!queued) // 如果还未入队就入队等待,CAS抢占入队
      queued = UNSAFE.compareAndSwapObject(this, waitersOffset,
                                           q.next = waiters, q);
    else if (timed) { // 如果是耗时等待的话
      nanos = deadline - System.nanoTime();
      if (nanos <= 0L) { // 如果超过了耗时就直接不要了返回state移除等待
        removeWaiter(q);
        return state;
      }
      LockSupport.parkNanos(this, nanos); 
      // 如果还在耗时就让其阻塞等待相应的秒数(如果在此秒数内没有被unpark,那么久返回)
    }
    else // 不等待就直接挂起
      LockSupport.park(this);
  }
}
```

查看set方法,完成时唤醒线程

```java
protected void set(V v) {
  if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) {
    // CAS修改计算状态
    outcome = v; // 设置结果
    UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state
    finishCompletion(); // 完成计算,移除等待队列状态,唤醒等待的线程.
  }
}
private void finishCompletion() {
  // assert state > COMPLETING;
  for (WaitNode q; (q = waiters) != null;) {
    // CAS尝试把waiters置空
    if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) {
      
      // 循环移除最后的节点,尝试把所有节点的线程唤醒
      for (;;) {
        Thread t = q.thread;
        if (t != null) {
          q.thread = null;
          LockSupport.unpark(t); // 唤醒线程
        }
        WaitNode next = q.next;
        if (next == null)
          break;
        q.next = null; // unlink to help gc
        q = next;
      }
      break;
    }
  }
  done();
  callable = null;        // to reduce footprint
}
```

JDK6的实现是通过`Sync extends AbstractQueuedSynchronized`来维护队列显得臃肿

#### FutureTask的使用

用其来实现数据库连接池

```java
public class ConnectionPool {

  private ConcurrentHashMap<String, Connection> pool = new ConcurrentHashMap<String, Connection>();

  public Connection getConnection(String key) {
    Connection conn = null;
    if (pool.containsKey(key)) {
      conn = pool.get(key);
    } else {
      conn = createConnection(); // 耗时操作
      pool.putIfAbsent(key, conn);
    }
    return conn;
  }

  public Connection createConnection() {
    return new Connection();
  }

  class Connection {}
}
```

上面代码的效率其实还不够高,因为get方法虽然是原子性的方法,但问题是`createConnection`方法并不是原子性的,也就是说,线程调用其仍需要原子性,这样一来创建连接可能会发生多次,但只有一次成功,这个创建的过程其实是可以用`FutureTask`避免的.

```java
public class ConnectionPool {

  private ConcurrentHashMap<String, FutureTask<Connection>> pool = new ConcurrentHashMap<String, FutureTask<Connection>>();

  public Connection getConnection(String key) throws InterruptedException, ExecutionException {
    FutureTask<Connection> connectionTask = pool.get(key);
    if (connectionTask != null) {
      return connectionTask.get();
    } else {
      FutureTask<Connection> newTask = new FutureTask<Connection>(()->{
         return createConnection(); // 耗时操作
      });
      connectionTask = pool.putIfAbsent(key, newTask);
      if (connectionTask == null) {
        connectionTask = newTask;
        connectionTask.run();
      }
      return connectionTask.get();
    }
  }

  public Connection createConnection() {
    return new Connection();
  }

  class Connection {
  }
}
```

我们可以来分析下为什么做可以,Future的创建,相比真正的计算更加快速.这是因为`FutureTask`被三个线程加入了三次,但只有一次成功了,而普通的数据库连接池加入的则是连接,而创建连接需要耗费大量时间,我们把计算放到了后面,加入了在进行计算,否则就取消掉.所以从这个角度看FutureTask是异步计算的.

以上我们也可以看出线程安全在耗时操作的前后并不一定是高性能的,其虽然线程安全,但因为操作的不当还是有可能会浪费大量资源的.



### 线程池实现原理

线程池是我们平时使用线程的一个工具,前面已经简单讲述了该工具的基本使用,下面进行线程池源码的解析.Executor执行框架对Java线程进行了更细致的划分,并且进行了功能的增强.

-   线程任务 Callable 处理异常机制和返回值增强
-   执行器 Executor 任务和线程解耦合
-   异步执行结果 Future接口

有了上面的这些工具,我们不用再关心线程的创建回收开启执行复用等,我们只需要专注于任务本身即可.三个部分以Executor为核心,共同构建了JDK1.5以后的多线程工具.

JDK的线程池还具备很好的扩展性,像ForkJoin框架,Junit的test等都是基于JDK做的扩展.如下为其总体的结构,可以看到其本质上就分为2类,普通线程池和调度线程池.我们下面要讲的重点是ThreadPoolExecutor的实现原理.

![线程池的继承链](https://uploadfiles.nowcoder.com/files/20190118/7380095_1547784444679_4685968-eaaaf8fd88497757.png)

#### 数据结构

我们来看看ThreadPoolExecutor的数据结构.

```java
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
// ctl保存两个数据,线程池的运行状态runState,线程池中线程的数量workerCount
// 其中高3位保存runState后29位保存workerCount,利用下面的结构保存

private static final int COUNT_BITS = Integer.SIZE - 3;
private static final int CAPACITY = (1 << COUNT_BITS) - 1;

// 利用高三位定义基本状态
private static final int RUNNING = -1 << COUNT_BITS; // 负数
private static final int SHUTDOWN = 0 << COUNT_BITS;
private static final int STOP = 1 << COUNT_BITS;
private static final int TIDYING = 2 << COUNT_BITS;
private static final int TERMINATED = 3 << COUNT_BITS;

private static int runStateOf(int c) {
    return c & ~CAPACITY; // 取前三位
}
private static int workerCountOf(int c) {
    return c & CAPACITY; // 取后COUNT_BITS位
}
private static int ctlOf(int rs, int wc) { 
  return rs | wc; // 计算ctl值,或是true断点,即 1|*=1
  // 因为是错位所以位或就是加法,同样可以理解位与乘法 0&*=0
}

// 任务队列
private final BlockingQueue<Runnable> workQueue;
// 工作线程队列(线程和任务解耦合),需要持有mainLock才可访问该数据结构
private final HashSet<Worker> workers = new HashSet<Worker>();

private int largestPoolSize; // 需要mainLock,使用的最大线程数
private long completedTaskCount; // 需要mainLock,完成任务数

// 用于线程池状态修改的锁,同时用于添加工作线程,停止线程等
private final ReentrantLock mainLock = new ReentrantLock();
private final Condition termination = mainLock.newCondition();

private volatile int corePoolSize;
private volatile int maximumPoolSize;
private volatile ThreadFactory threadFactory;
private volatile RejectedExecutionHandler handler;


private volatile long keepAliveTime; // 只对空闲工作线程有效
private volatile boolean allowCoreThreadTimeOut; // 是否允许核心线程超时

private final AccessControlContext acc; // 用于GC标记的线程池,辅助释放资源
```

 从上面我们就能看到线程池的状态和功能.我们来看其状态变换,可以

![](https://img-blog.csdnimg.cn/20200815124659802.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzc2NzAxNQ==,size_16,color_FFFFFF,t_70#pic_center)

TIDYING意为整理,是一个所有任务都执行完了的中间状态,准备清除线程池资源.其他状态如图进行转换.我们看其构造器

```java
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler) {
    if (corePoolSize < 0 ||
            maximumPoolSize <= 0 ||
            maximumPoolSize < corePoolSize ||
            keepAliveTime < 0)
        throw new IllegalArgumentException();

    if (workQueue == null || threadFactory == null || handler == null)
        throw new NullPointerException();
    //初始化用于安全管理器的上下文参数
    this.acc = System.getSecurityManager() == null ? null :AccessController.getContext();
    this.corePoolSize = corePoolSize;
    this.maximumPoolSize = maximumPoolSize;
    this.workQueue = workQueue;
    this.keepAliveTime = unit.toNanos(keepAliveTime);
    this.threadFactory = threadFactory;
    this.handler = handler;
}
private static final RejectedExecutionHandler defaultHandler = new AbortPolicy();
// 由其他几个重载方法可以确定其默认参数
// threadFactory = Executors.defaultThreadFactory()
// handler = new AbortPolicy();
```

#### 线程池的执行特点

```java
// 任务队列
private final BlockingQueue<Runnable> workQueue;
// 工作线程队列(线程和任务解耦合),需要持有mainLock才可访问该数据结构
private final HashSet<Worker> workers = new HashSet<Worker>();
```

-   线程池是采用lazy-init来创建线程的.即线程数少于corePoolSize的时候,就会通过工厂创建线程并加入workers队列.
-   当当前线程队列workers满了的时候就会加入阻塞的任务队列workQueue.
-   线程队列的线程会不断从workQueue中拉取任务执行.
-   当线程数在corePoolSize和maximunPoolSize之间的时候,又会通过工厂创建线程
-   当存在空闲线程的时候清理,保持至少corePoolSize的线程数

#### ThreadFactory

主要使用默认工厂`Executors.defaultThreadFactory`创建线程,具有pool-N-thread-M的线程命名,N是线程工厂的编号,M是线程产品的编号.

```java
static class DefaultThreadFactory implements ThreadFactory {
  private static final AtomicInteger poolNumber = new AtomicInteger(1);
  private final ThreadGroup group;
  private final AtomicInteger threadNumber = new AtomicInteger(1);
  private final String namePrefix;

  DefaultThreadFactory() {
    // 初始化常见的线程信息
    SecurityManager s = System.getSecurityManager();
    group = (s != null) ? s.getThreadGroup() :
    Thread.currentThread().getThreadGroup();
    namePrefix = "pool-" +
      poolNumber.getAndIncrement() +
      "-thread-";
  }
	
  @Override
  public Thread newThread(Runnable r) {
    Thread t = new Thread(group, r,
                          namePrefix + threadNumber.getAndIncrement(),
                          0); // 这个0最终表示stacksize即由JVM决定大小
    if (t.isDaemon())
      t.setDaemon(false);
    if (t.getPriority() != Thread.NORM_PRIORITY)
      t.setPriority(Thread.NORM_PRIORITY);
    return t;
  }
}
```

我们也可以继承ThreadFactory接口自行定义线程工厂,一般来讲默认的工厂就够用了,如有自定义的情况,可以是优先级线程,也可以是创建时候的日志信息,也可以是规定size大小,线程工厂能够操作的空间不多,因此在一般情况下,用普通的工厂即可.

#### workQueue任务队列

`BlockingQueue workQueue`作为任务队列的缓存,不同的队列其对线程池的影响不一样

```java
public static ExecutorService newCachedThreadPool() {
  return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                60L, TimeUnit.SECONDS,
                                new SynchronousQueue<Runnable>());
}
public static ExecutorService newFixedThreadPool(int nThreads) {
  return new ThreadPoolExecutor(nThreads, nThreads,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue<Runnable>());
}
public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
  return new ScheduledThreadPoolExecutor(corePoolSize);
}
public ScheduledThreadPoolExecutor(int corePoolSize,
                                   ThreadFactory threadFactory) {
  super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
        new DelayedWorkQueue(), threadFactory);
}
public static ExecutorService newSingleThreadExecutor() {
  return new FinalizableDelegatedExecutorService
    (new ThreadPoolExecutor(1, 1,
                            0L, TimeUnit.MILLISECONDS,
                            new LinkedBlockingQueue<Runnable>()));
}
```

我们可以看到其有着不同的队列,这些队列帮我们完成了或任务的缓存或延迟的功能,下面介绍几种出现的队列的特点

-   SynchronousQueue **直接提交**其没有内部容量,必须有一对入队出队操作才能够不阻塞
-   LinkedBlockingQueue 有界/无界队列,可以无限缓存任务,需要自己指定大小才有界
-   DelayedWorkQueue 一个特殊的优先级队列,时间越短排的越前,使用take和put来操作

DelayedWorkQueue出队和入队特点是.入队的时候按照时间大小加入优先级队列,出队的时候,如果没到期就(内部的优先队列返回null)阻塞.如果队列元素到期了,才会出队,需要经过至少delay才会被拿走,如果拿的线程多的话,就是delay秒后就能够出队了.

#### rejectHandler拒绝策略

```java
public static class AbortPolicy implements RejectedExecutionHandler {
  	// r是新来的任务,e是执行任务的线程池,当线程池两个队列都满了就执行此
    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
        throw new RejectedExecutionException("Task " + r.toString() +
                " rejected from " +
                e.toString());
    }
}
public static class CallerRunsPolicy implements RejectedExecutionHandler {
    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
        if (!e.isShutdown()) {
            r.run(); // 调用线程自行处理
        }
    }
}
public static class DiscardOldestPolicy implements RejectedExecutionHandler {
    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
        if (!e.isShutdown()) {
            e.getQueue().poll(); // 丢弃头部的任务,也就是最老的还在运行的任务
          	// getQueue指的是workQueue,换句话说头部线程去掉在尝试创建新线程
            e.execute(r);
        }
    }
}
public static class DiscardPolicy implements RejectedExecutionHandler {
    public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
    		// 什么也不做,直接丢弃任务
    }
}
```

#### 核心方法execute

execute方法是线程池的核心方法,其都没有用啥锁,因为发生线程安全问题的地方在addWorker粒度更小.

```java
public void execute(Runnable command) {
  if (command == null)
    throw new NullPointerException();
  
  int c = ctl.get();
  if (workerCountOf(c) < corePoolSize) { // 如果还没到核心线程数
    if (addWorker(command, true)) // 加入工作队列,开启新工作线程
      return;
    
    c = ctl.get(); // 添加新工作线程失败了赶紧更新值,这部操作原子性
    // 因为可能是一堆线程并行的调用execute的方法,肯定在这里需要锁,上同
  }
  
  
  // 已经大于等于核心线程数了,该考虑加入阻塞队列
  if (isRunning(c) && workQueue.offer(command)) { // 加入任务阻塞队列
    
    /*检查线程池状态和维持线程活性*/
    int recheck = ctl.get();
    if (!isRunning(recheck) && remove(command)) 
      // 如果已经shutdown了就移除阻塞队列workQueue中的元素
      reject(command); // 移除成就执行拒绝策略
    else if (workerCountOf(recheck) == 0)
      // 如果没有shutdown或者阻塞队列移除失败,且此时没有worker了
      // 此时处于RUNNING状态,但是却没有worker,只会在corePoolSize为0的时候
      // 出现这种情况,要特别注意
      addWorker(null, false); // 开启工作线程
    	// 这个主要调用的目的是当设置corePoolSize的时候如果线程队列里面没有线程,
    	// 那么任务就会一直阻塞进入任务队列,导致一直无法被执行,所以也说这一步是维持线程
    	// 队列的活性

  }else if (!addWorker(command, false)) 
    // 如果不在运行了或者加入workQueue失败,即worker队列满了,此时尝试开启新的线程失败
    // 那么就执行拒绝策略
    reject(command);
}
```

我们来看下上面的核心之一addWorker的实现

```java
private boolean addWorker(Runnable firstTask, boolean core) {
  // 下面这段for的代码是为了改变workcount
  // 这里需要注意下firstTask == null的情况是在线程池的corePoolSize设置为0的时候
  // 才有的,表示新增任务的执行线程,专门用来处理阻塞的任务队列的线程
  // 如果firstTask != null 则说明是正常线程池的线程增加
  // core用来确定是不是维持的corePoolSize的线程,而不是临时线程
  // 其实真正的实现在worker里面,而这里只需要确定数量就可
  
  retry:
  for (;;) {
    int c = ctl.get();
    int rs = runStateOf(c); // rs

    // Check if queue empty only if necessary.
    if (rs >= SHUTDOWN && // 当线程池不是RUNING,而是SHUTDOWN状态
        !(rs == SHUTDOWN && firstTask == null && !workQueue.isEmpty()))
      // 如果firstTask空,即因为上面原因,可能还有任务停留在任务队列里
      // 如果firstTask不为空那么就立刻返回了
      // 或者workQueue是空,那就一定返回了,因为没有任务了
      return false; 
    
    for (;;) {
      int wc = workerCountOf(c);
      if (wc >= CAPACITY ||
          wc >= (core ? corePoolSize : maximumPoolSize))
        return false; // 如果workercount不合适就返回false
      
      if (compareAndIncrementWorkerCount(c)) // CAS增加workercount
        break retry; // 跳出最外圈循环,整体执行结束
      
      c = ctl.get();  // Re-read ctl
      if (runStateOf(c) != rs) 
        continue retry;  
      // 即runState改变了,调到循环头重新执行,这是因为状态改变了就得重新判断线程池状态
      									
      // else CAS failed due to workerCount change; retry inner loop
    }
  }
  // for结束

  boolean workerStarted = false; // worker开始标记位
  boolean workerAdded = false; // worker是否加入线程队列的标记位
  Worker w = null;
  try {
    w = new Worker(firstTask); // 给线程封装成个worker,并获取其线程
    final Thread t = w.thread;
    if (t != null) {
      final ReentrantLock mainLock = this.mainLock;
      mainLock.lock();
      try {
        int rs = runStateOf(ctl.get());
				
        // 这两个条件只要满足其中之一,才能加入工作队列
        // 第一个条件是rs处于RUNING状态
        // 第二个条件是rs处于SHUTDOWN状态,且不是新增的任务
        if (rs < SHUTDOWN || (rs == SHUTDOWN && firstTask == null)) { 
          if (t.isAlive()) // precheck that t is startable
            throw new IllegalThreadStateException();
          
          workers.add(w); // 加入工作线程队列
          
          int s = workers.size();
          if (s > largestPoolSize)
            largestPoolSize = s; // 更新到达的最大值
          workerAdded = true;
        
        }
      } finally {
        mainLock.unlock();
      }
      if (workerAdded) {
        t.start(); // 如果添加到worker队列里面去了就执行任务就好了
        // 就是开启while循环读取任务
        workerStarted = true; 
      }
    }
  } finally {
    if (!workerStarted) // 如果上面的线程因为各种原因没有开始的话调用线程失败
      addWorkerFailed(w); // 回滚状态
  }
  return workerStarted; // 返回加入队列的状态
}

private void addWorkerFailed(Worker w) {
  final ReentrantLock mainLock = this.mainLock;
  mainLock.lock();
  try {
    if (w != null)
      workers.remove(w);
    // 循环尝试CAS的将ctl的WorkerCount线程数量部分自减1，直到成功为止。
    decrementWorkerCount();
    tryTerminate(); // 如果没有成功的话那么此时就尝试停止线程池
  } finally {
    mainLock.unlock();
  }
}
final void tryTerminate() {
  for (;;) {
    // 如果已经是已经停了的线程池,这个方法不会有作用就返回
    // 如果还没有执行完的任务,那么这个方法也会返回
    int c = ctl.get();
    if (isRunning(c) ||
        runStateAtLeast(c, TIDYING) ||
        (runStateOf(c) == SHUTDOWN && ! workQueue.isEmpty()))
      return;
    if (workerCountOf(c) != 0) { // Eligible to terminate
      interruptIdleWorkers(ONLY_ONE);
      return;
    }
    
		// 到这工作线程已经变为0,可以尝试结束线程池了
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
      if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { // 失败了就cas
        try {
          terminated(); // 一个回调函数,可由子类实现
        } finally {
          ctl.set(ctlOf(TERMINATED, 0)); // 改变为停止状态
          termination.signalAll(); // 尝试唤醒所有在等待停止条件的线程
        }
        return;
      }
    } finally {
      mainLock.unlock();
    }
    // else retry on failed CAS
  }
}
```

这里我们已经清楚了线程池是如何添加worker进入线程池的,上面的addWorker方法不但创建了线程还顺便开启了线程,以及做了线程池shutdown时候的各种准备,补充一点worker的数据结构如下.

其简单的定义我们就能看出来其继承了AQS,即Worker本身是一个同步队列(参考AQS的实现和用途),而Worker除了封装Thread节点之外也实现了其他的一些功能,比如一次独占锁(这个独占锁是用来控制线程可否在执行中被中断的).**获取到锁的线程可以看做工作线程,没有获取到锁的线程可以看做空闲线程.**这只是代表一种状态,其他方法不可使用该节点(如果他们也调用lock的话会挂起).



```java
private final class Worker extends AbstractQueuedSynchronizer 
  implements Runnable {

  private static final long serialVersionUID = 6138294804551838833L;
  final Thread thread;
  Runnable firstTask; // 要运行的初始任务
  volatile long completedTasks; // 统计worker完成的线程数

  Worker(Runnable firstTask) {
    setState(-1); // 禁止中断
    this.firstTask = firstTask;
    this.thread = getThreadFactory().newThread(this);
  }

  public void run() {
    runWorker(this); // runWorker方法不是类里面的该方法实现是该类的核心
    // 这个方法在上面的t.start()的时候被调用了
  }

  // Lock methods
  // The value 0 represents the unlocked state.
  // The value 1 represents the locked state.

  protected boolean isHeldExclusively() {
    return getState() != 0;
  }

  protected boolean tryAcquire(int unused) {
    if (compareAndSetState(0, 1)) {
      setExclusiveOwnerThread(Thread.currentThread());
      return true;
    }
    return false;
  }

  protected boolean tryRelease(int unused) {
    setExclusiveOwnerThread(null);
    setState(0);
    return true;
  }

  public void lock()        { acquire(1); }
  public boolean tryLock()  { return tryAcquire(1); }
  public void unlock()      { release(1); }
  public boolean isLocked() { return isHeldExclusively(); }

  void interruptIfStarted() {
    Thread t;
    if (getState() >= 0 && (t = thread) != null && !t.isInterrupted()) {
      try {
        t.interrupt();
      } catch (SecurityException ignore) {
      }
    }
  }
}

// 核心方法,如何调用worker线程
// 实现的思想就是本线程循环执行任务处理
final void runWorker(Worker w) {
  Thread wt = Thread.currentThread();
  Runnable task = w.firstTask; // 获取到task,然后把task清空
  w.firstTask = null;
  w.unlock(); // 允许线程中断 和新方法通过setState(0)
  
  boolean completedAbruptly = true; // 是否发生异常标记位
  try {
    // 如果task是null那么就从阻塞任务队列中获取任务
    // 如果不是null就准备执行,这主要是对第一次任务的
    while (task != null || (task = getTask()) != null) {
      
      w.lock(); 
      // 表示该worker处于工作状态,
      // setCorePoolSize,setMaximumPoolSize等操作无法被执行
      
      // 如果线程池状态STOP则应该被中断 
      if ((runStateAtLeast(ctl.get(), STOP) ||
           (Thread.interrupted() && 
            runStateAtLeast(ctl.get(), STOP))) &&
          !wt.isInterrupted())
        wt.interrupt();
      
      
      try {
        beforeExecute(wt, task); // 空实现,子类可以实现
        Throwable thrown = null; // 记录异常状态
        try {
          task.run(); // task实现的runnable接口自然可以run
        } catch (RuntimeException x) {
          thrown = x; throw x;
        } catch (Error x) {
          thrown = x; throw x;
        } catch (Throwable x) {
          thrown = x; throw new Error(x);
        } finally {
          afterExecute(task, thrown); // 空实现子类可以实现
        }
      } finally {
        task = null; // 清空拉取队列
        w.completedTasks++;
        w.unlock(); // 解锁允许修改
      }
    } // while循环结束
    
    completedAbruptly = false;
  } finally {
    processWorkerExit(w, completedAbruptly); // 退出然后删除worker的资源
  }
}
```

也是该类的实现,让任务和线程解耦合.我们来讲解下这个思路原先的java线程是只能执行一个Runnable接口的任务的,但我们可以转换思路,把实现Runnable接口的类Task构建出一个队列,然后线程本身开启一个死循环一直去执行从队列中获取相应的任务在调用run方法即可.我们来实现一个简单的SingelThreadPool如下,其解耦合思路并不复杂.从这里我们看出了BlockingQueue的解耦合思路.

```java
public class MySingleThreadPool {
  private final LinkedBlockingQueue<Task> queue = new LinkedBlockingQueue<>();
  private boolean started = false;
  private Thread thread = new Thread(() -> {
    try {
      Task task = null;
      while ((task = queue.take()) != null) {
        task.run();
      }
    } catch (InterruptedException e) {
      System.out.println("线程池执行完毕");
    }
  });

  public void execute(Runnable runnable) {
    if (!started) {
      thread.start();
      started = true;
    }
    queue.add(new Task(runnable));
  }

  public void terminate() {
    for (;;) {
      if (queue.size() == 0) {
        thread.interrupt();
        break;
      }
    }
  }

  static class Task implements Runnable {
    Runnable runnable;

    Task(Runnable runnable) {
      this.runnable = runnable;
    }

    @Override
    public void run() {
      runnable.run();
    }
  }

  public static void main(String[] args) {
    MySingleThreadPool pool = new MySingleThreadPool();
    for (int i = 0; i < 3; i++) {
      int finalI = i;
      pool.execute(() -> {
        System.out.println("计数器" + finalI);
      });
    }
    pool.terminate();
  }
}

```

如上,线程池的大部分都要依赖此种解耦合.我们来看下其内部方法的getTask实现,相比我们的take,显然getTask需要更加轻量级的锁实现

```java
private Runnable getTask() {
  boolean timedOut = false; // Did the last poll() time out?

  for (;;) {
    int c = ctl.get();
    int rs = runStateOf(c);

    // Check if queue empty only if necessary.
    // 如果线程池停了或者在停了且工作队列空了,就可以结束while了
    if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {
      decrementWorkerCount();
      return null;
    }

    int wc = workerCountOf(c);

    // Are workers subject to culling?
    // timed是用来判断是否应用超时等待,如果allowCoreThreadTimeOut不允许就不会停
    // 掉上面的while循环,只是在下面的workQueue.take进行阻塞
    boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;

    if ((wc > maximumPoolSize || (timed && timedOut))
        // 动态调小了最大线程数,或者上一次poll已经超时
        && (wc > 1 || workQueue.isEmpty())) { 
      // 如果超时没获取到且没有队列在等或者说不止1个worker
      if (compareAndDecrementWorkerCount(c)) // CAS减少worker
        return null;
      continue;
    }

    try {
      Runnable r = timed ?
        workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
      workQueue.take();
      // 如果没有超时就用pool尝试循环获取,如果获取了一次获取不到,那么就设置超时
      // 下一次操作在进行来的时候就使用了超时
      if (r != null)
        return r;
      timedOut = true;
    } catch (InterruptedException retry) {
      timedOut = false;
    }
  }
}
```

我们再来看其WorkerExit方法只有当runWorker的while执行完了的时候才会执行该方法,一般来说while是不会断掉的,只有当允许超时才可,下面是对无用worker回收资源的方法实现.

```java
private void processWorkerExit(Worker w, boolean completedAbruptly) {
  // 如果发生了异常,就减少worker数量,因为线程终止了
  if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted
    decrementWorkerCount();

  final ReentrantLock mainLock = this.mainLock;
  mainLock.lock();
  try {
    completedTaskCount += w.completedTasks; // 写会统计
    workers.remove(w);
  } finally {
    mainLock.unlock();
  }

  tryTerminate(); // 尝试停掉线程池

  int c = ctl.get();
  // 处于RUNNING或SHUTDOWN的线程
  if (runStateLessThan(c, STOP)) {
    if (!completedAbruptly) { // 没有发生异常
      
      // 最小需要保持的线程数
      int min = allowCoreThreadTimeOut ? 0 : corePoolSize;
      if (min == 0 && ! workQueue.isEmpty())
        min = 1; // 如果允许超时且队列为空就换成1
      if (workerCountOf(c) >= min)
        return; // replacement not needed
    }
    // worker不够了补充线程
    addWorker(null, false);
  }
}
```

#### submit方法

submit基本可以视为调用runnable和利用futuretask对execute方法进行改进,实现不难,关于FutureTask的技术细节已经在另一节中说明过,此处不再赘述

```java
public Future<?> submit(Runnable task) {
    if (task == null) throw new NullPointerException();
    RunnableFuture<Void> ftask = newTaskFor(task, null);
    execute(ftask);
    return ftask;
}
protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) {
    return new FutureTask<T>(runnable, value);
}
// FutureTask为一异步结果保存类如上,其存储着同步行的get,实现了Runnable接口
```

#### 核心线程预启动

在上面的代码中我们也可以看出来,如果不主动submit,那线程池是不会启动线程的,我们可以通过`prestartCoreThread`,`prestartAllCoreThreads`.

```java
public boolean prestartCoreThread() {
    return workerCountOf(ctl.get()) < corePoolSize &&
            addWorker(null, true);
  	// 尝试开启一个线程
}
public int prestartAllCoreThreads() {
    int n = 0;
    while (addWorker(null, true))
        ++n;
    return n;
  // 通过addWorker添加核心线程数corePoolSize
}
```

#### 关闭线程池

关闭线程池用的是shutdown方法,其实现如下

```java
public void shutdown() {
  final ReentrantLock mainLock = this.mainLock;
  mainLock.lock();
  try {
    // 安全管理器检测是否右关闭线程池的权限
    checkShutdownAccess();
    // 线程池状态转换为SHUTDOWN
    advanceRunState(SHUTDOWN);
    // 中断所有空闲线程
    interruptIdleWorkers();
    onShutdown(); // 空实现,给子类增加功能
  } finally {
    mainLock.unlock();
  }
  // 尝试终止线程池
  tryTerminate();
}
private void advanceRunState(int targetState) {
  for (;;) {
    int c = ctl.get();
    // 循环CAS,修改停止状态
    if (runStateAtLeast(c, targetState) || ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c))))
      break;
  }
}
```

和上面只修改状态的相比,还有一个方法`shutdownNow`,其能

```java
public List<Runnable> shutdownNow() {
    List<Runnable> tasks;
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        checkShutdownAccess();
        advanceRunState(STOP);
        // 中断所有线程,这一步终止了所有workers而没有在意有没有执行结束
        interruptWorkers();
        tasks = drainQueue();
    } finally {
        mainLock.unlock();
    }
    tryTerminate();
    return tasks;
}
```

```java
private void interruptWorkers() {
    final ReentrantLock mainLock = this.mainLock;
    mainLock.lock();
    try {
        for (Worker w : workers)
          w.interruptIfStarted();
    } finally {
        mainLock.unlock();
    }
}
void interruptIfStarted() {
    Thread t;
    // 如果此Worker的state大于等于0，并且thread不为null，并且thread没有被中断
    if (getState() >= 0 && (t = thread) != null && !t.isInterrupted()) {
        try {
            // 那么中断thread
            t.interrupt();
        } catch (SecurityException ignore) {
        }
    }
}
```



#### hook方法

```java
protected void beforeExecute(Thread t, Runnable r);
protected void afterExecute(Runnable r, Throwable t);
protected void terminated();
```

我们通过实现这些方法给线程池



#### 动态设置线程池的核心参数

```java
public void setCorePoolSize(int corePoolSize) {
    if (corePoolSize < 0)
        throw new IllegalArgumentException();
    // 计算新值和旧值的差delta
    int delta = corePoolSize - this.corePoolSize;
    this.corePoolSize = corePoolSize;
    if (workerCountOf(ctl.get()) > corePoolSize)
        // 那么尝试中断所有空闲的线程，期待减少线程数量
        interruptIdleWorkers();
    else if (delta > 0) {
        int k = Math.min(delta, workQueue.size()); // 线程池增加两者最小值
        while (k-- > 0 && addWorker(null, true)) { // 增加最多k个
            if (workQueue.isEmpty())
                break;
        }
    }
}
public void setMaximumPoolSize(int maximumPoolSize) {
    if (maximumPoolSize <= 0 || maximumPoolSize < corePoolSize)
        throw new IllegalArgumentException();
  
    this.maximumPoolSize = maximumPoolSize;
    // 如果目前线程数大于新最大线程数
    if (workerCountOf(ctl.get()) > maximumPoolSize)
        // 那么尝试中断所有空闲的线程，期待减少线程数量
        interruptIdleWorkers();
}
```









### 分布式锁

-   未完待续











## JUC

JUC即java.util.concurrent包,该包的底层是LockSupport,Unsafe两个类.这两个类提供了大量方法,用于实现基本的原语级别的park,cas,以及后续的AQS,而利用CAS和AQS,JUC的其他工具锁才得以实现,另外请参考上面的AQS队列同步器来完善JUC完整的体系.

在开始之前我们介绍一个问题什么使用使用synchronized线程切换,我们先测试下使用各项的时间获得了相应的数据(单位nanosec).这非启动时间,也就是说CPU的指令集等做好了准备.此测试时无线程竞争情况下进行的.在多线程环境下在进行了几轮测试其基本大小如下

```shell
base:250
sync:687
lock:1937
yield:612
```

我们发现sync在某些情况下不会发生剧烈的线程切换即偏向锁,其性能比juc的lock要高,设置比直接yield线程切换还要高.JUC基于CAS实现,不需要进入内核(synchronized也改进了),

-   如果线程**竞争严重**CAS会快速的执行,整体而言多数线程在空转(loop-cas),且除了空转外,耗尽时间片依然会进行线程切换.
-   synchronized在1.6之后获得了锁升级,通过**Lock-Free,自旋后阻塞**获得了和CAS一样的性能.

另外关于线程激烈的理解就是,CAS空等的时间和synchronized重量级锁使用资源的时间是线程竞争激烈的时间之一.如果空等时间过短,那么CAS将有极高的性能,因为只需等一会就行,如果synchronized使的时间短的话,那么CAS就会占用大量CPU.不如挂起等待.

JUC主要分为以下部分

-   sun.misc.Unsafe
-   java.util.concurrent.locks的锁 专门实现各种锁
    -   LockSupport
    -   ReentrantLock
    -   Condition
    -   ReadWriteLcok
    -   StampedLock
    -   AbstractQueueSynchronized
-   java.util.concurrent.atomic包的原子类
    -   AtomicInteger 基本原子类
    -   AtomicIntegerArray 基本原子类数组
    -   AtomicIntergerFieldUpdater 更新字段
    -   LongAdder
    -   LongAccumulater
    -   引用类型
-   并发容器
    -   CocurrentLinkedQueue/CocurrentLinkedDeque
    -   ConcurrentHashMap
    -   LinkedBlockingQueue/LinkedBlockingDeque
    -   CopyOnWriteArraySet/CopyOnWriteArrayList
-   并发工具
    -   CountDownLatch
    -   Cyclibarrier
    -   Excutors 线程池
    -   Exchanger
    -   Semaphore

---

### TimeUnit

利用emun类的特性把sleep,wait,join给封装了下变成人类可读的形式

```java
TimeUnit.SECONDS.sleep(1000); // Thread.sleep
TimeUnit.SECONDS.timedWaited(obj,1000); // obj.wait
TimeUnit.SECONDS.timedJoin(thread,1000); // Thread.join
```



### 一切的基础 sun.misc.Unsafe

该类基本采用C++实现是java和c++交互的底层之一,该类主要实现了一些c++的常用接口,比如分配内存,比如CAS等,是JUC包的实现的工具,是实例化实现的工具,是重新分配/获取内存值的工具,是整个jvm中较为重要的类.

**因为不能够直接new,我们用反射暴力获取该类的对象才可以进行测试**

```java
Field f = Unsafe.class.getDeclaredField("theUnsafe");
f.setAccessible(true);
Unsafe unsafe = (Unsafe) f.get(null);
```

其方法声明如下

```java
//重新分配内存
public native long reallocateMemory(long address, long bytes);  

//分配内存  
public native long allocateMemory(long bytes);  

//释放内存  
public native void freeMemory(long address);  

//在给定的内存块中设置值  
public native void setMemory(Object o, long offset, long bytes, byte value);  

//从一个内存块拷贝到另一个内存块  
public native void copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes);  

//获取值，不管java的访问限制，其他有类似的getInt，getDouble，getLong，getChar等等  
public native Object getObject(Object o, long offset);  

//设置值，不管java的访问限制，其他有类似的putInt,putDouble，putLong，putChar等等 
public native void putObject(Object o, long offset);  

//从一个给定的内存地址获取本地指针，如果不是allocateMemory方法的，结果将不确定  
public native long getAddress(long address);  

//存储一个本地指针到一个给定的内存地址,如果地址不是allocateMemory方法的，结果将不确定 
public native void putAddress(long address, long x);  

//该方法返回给定field的内存地址偏移量，这个值对于给定的filed是唯一的且是固定不变的  
public native long staticFieldOffset(Field f);  

//报告一个给定的字段的位置，不管这个字段是private，public还是保护类型，和staticFieldBase结合使用  
public native long objectFieldOffset(Field f);  

//获取一个给定字段的位置  
public native Object staticFieldBase(Field f);  

//确保给定class被初始化，这往往需要结合基类的静态域（field）  
public native void ensureClassInitialized(Class c);  

//可以获取数组第一个元素的偏移地址  
public native int arrayBaseOffset(Class arrayClass);  

//可以获取数组的转换因子，也就是数组中元素的增量地址。将arrayBaseOffset与arrayIndexScale配合使用， 可以定位数组中每个元素在内存中的位置  
public native int arrayIndexScale(Class arrayClass);  

//获取本机内存的页数，这个值永远都是2的幂次方  
public native int pageSize();  

//告诉虚拟机定义了一个没有安全检查的类，默认情况下这个类加载器和保护域来着调用者类  
public native Class defineClass(String name, byte[] b, int off, int len, ClassLoader loader, ProtectionDomain protectionDomain);  

//定义一个类，但是不让它知道类加载器和系统字典  
public native Class defineAnonymousClass(Class hostClass, byte[] data, Object[] cpPatches);  

//锁定对象，必须是没有被锁的
public native void monitorEnter(Object o);  

//解锁对象  
public native void monitorExit(Object o);  

//试图锁定对象，返回true或false是否锁定成功，如果锁定，必须用monitorExit解锁  
public native boolean tryMonitorEnter(Object o);  

//引发异常，没有通知  
public native void throwException(Throwable ee);  

//CAS，如果对象偏移量上的值=期待值，更新为x,返回true.否则false.类似的有compareAndSwapInt,compareAndSwapLong,compareAndSwapBoolean,compareAndSwapChar等等。  
public final native boolean compareAndSwapObject(Object o, long offset,  Object expected, Object x);  

// 该方法获取对象中offset偏移地址对应的整型field的值,支持volatile load语义。类似的方法有getIntVolatile，getBooleanVolatile等等  
public native Object getObjectVolatile(Object o, long offset);   

//线程调用该方法，线程将一直阻塞直到超时，或者是中断条件出现。  
public native void park(boolean isAbsolute, long time);  

//终止挂起的线程，恢复正常.java.util.concurrent包中挂起操作都是在LockSupport类实现的，也正是使用这两个方法
public native void unpark(Object thread);  

//获取系统在不同时间系统的负载情况  
public native int getLoadAverage(double[] loadavg, int nelems);  

//创建一个类的实例，不需要调用它的构造函数、初使化代码、各种JVM安全检查以及其它的一些底层的东西。即使构造函数是私有，我们也可以通过这个方法创建它的实例,对于单例模式，简直是噩梦。 
public native Object allocateInstance(Class cls) throws InstantiationException;  
```

其可以进行一些C++才能进行的操作

```java
(A) unsafe.allocateInstance(A.class); // 创建A对象

// 绕过权限检查,直接给private字段ACCESS_ALLOWED赋值42
Field field = guard.getClass().getDeclaredField("ACCESS_ALLOWED");
unsafe.putInt(guard, unsafe.objectFieldOffset(field), 42); 

// 分配超大数组
class SuperArray {
  private final static int BYTE = 1;
  private long size;
  private long address;

  public SuperArray(long size) {
    this.size = size;
    address = getUnsafe().allocateMemory(size * BYTE);
  }
  public void set(long i, byte value) {
    getUnsafe().putByte(address + i * BYTE, value);
  }
  public int get(long idx) {
    return getUnsafe().getByte(address + idx * BYTE);
  }
  public long size() {
    return size;
  }
}
```

### java.util.concurrent.locks

![](https://img-blog.csdnimg.cn/201906251151037.jpg)

juc包的继承关系如上,我们可以看到AQS在此处占据着基本最重要的位置,如上对其进行了详细的解读.我们也可以看到其继承关系是如何构筑的,下面一一说明

#### Lock接口

Lock接口实际上是一种规范,所有JUC的锁都会实现Lock接口,其同一定义方法抽象,而不必在去定义学习特异方法,降低各个锁之间的学习成本

-   lock() 获取锁不可被中断
-   lockInterruptibly() 获取锁可以被中断
-   tryLock() 尝试一次获取锁
-   tryLock(long time,TimeUnit unit) 在指定时间内尝试获取锁
-   unlock()
-   newCondition()

其实上面这些方法我们在学AQS的时候已经基本接触到了

#### LockSupport

LockSupport是提供了最基本的block形式,实际上还是wait/notify/synchronized的一个高效的体态工具

LockSupport.park()/LockSupport.unpark(threadInstance)是我们使用最常见的两种形式.

-   park()
-   park(Object blocker)
-   parkNanos(Object blocker,long nanos) # 这里1000ns=1ms 参数相应要做变化
-   parkUntil(Object blocker,long deadline) # deadline = System.currentTimeMillis()+1000 停1s

通过查看源码我们可以直到`Unsafe.park`才是该方法的实现,这里我们还看到setBlocker,其实是用于给Thread里面字段注入值,而`park`是一个只与当前执行的代码块的线程有关的函数,该函数可以直接让Thread进入等待队列,而下面的unpark(threadInstance)是一个Thread实例,唤醒该Thread.

如下例子对比`Synchorized`实现

```java
public class binary_output_park_ver {
    static int i = 0;
    static Thread t1;
    static Thread t2;
    static final Integer count = 10000;
    static {
        t1 = new Thread(() -> {
            while (i < count) {
                if (i % 2 == 0) {
                    System.out.println(i);
                    i++;
                    LockSupport.unpark(t2);
                } else {
                    LockSupport.park();
                }
            }
        });
        t2 = new Thread(() -> {
            while (i < count) {
                if (i % 2 != 0) {
                    System.out.println(i);
                    i++;
                    LockSupport.unpark(t1);
                } else {
                    LockSupport.park();
                }
            }
        });
    }
    public static void main(String[] args) throws InterruptedException {
        t1.start();
        t2.start();
    }
}
```

从行为上看,其行为和wait基本一致,只是其不需要通过获取锁(synchronized)来实现.其实现在C++通过Thread的parker的_counter状态(称之为许可),通过linux提供的POISX线程的接口去实现该原语.**其在`jstack`出来的内存中以`TIME_WAITING`或`WAITING`的状态存在**,因为没有相应的锁所以分析起来会很难,因此在JDK1.5中可以传入一个Object用来表示blocker的线程或者代码块用于后续更好的分析.

##### park与线程状态

从wait的实现我们可以看到park是wait在c++层次的调用,所以其标志还是`WAITING`状态.用jstack对一`LockSupport.park()`的线程分析如下.

```shell
"park-test-Thread" #13 prio=5 os_prio=31 tid=0x00007ffe250c8000 nid=0x5603 waiting on condition [0x000070000e41c000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
	at com.threadtest.ReebtrantLockTest.lambda$test3$2(ReebtrantLockTest.java:83)
	at com.threadtest.ReebtrantLockTest$$Lambda$3/1910163204.run(Unknown Source)
	at java.lang.Thread.run(Thread.java:748)
```



#### **ReentrantLock 可重入锁**

可重入锁被设计出来是堆synchronized关键字的一种扩展,以下一段代码等价于

##### synchronized的乐观锁版本

```java
public void test(){
  lock.lock();
  try{
    doSomeThing(); // 保证这段区域的只能被一个线程使用,保证原子性
  }catch (Exception e){
    e.printStackTrace();
  }finally {
    lock.unlock();
  }
}
public void test(){
  synchronized(this){
    doSomeThing(); // 保证这段区域只能被一个线程使用,即保证原子性
  }
}
```

##### 多次加锁

既然是叫可重入锁,那么就是可以重新加锁的意思,synchronized也可以实现两次加锁,如下等价,但ReentrantLock的好处是开销更小

```java
static Thread t_sync, t_reentrant;
static final Object lock = new Object();
static final ReentrantLock relock = new ReentrantLock();
static int i = 0, j = 0;

static {
  t_sync = new Thread(() -> {
    synchronized (lock) {
      for (int k = 0; k < 100; k++) {
        i++;
        synchronized (lock) {
          for (int l = 0; l < 100; l++) {
            j++;
          }
        } // release lock
      }
      System.out.println(Thread.currentThread().getName() + " has sum i with i=" + i + " j=" + j);
    } // release lock
  });

  t_reentrant = new Thread(() -> {
    relock.lock();
    try {
      for (int k = 0; k < 100; k++) {
        i++;
        relock.lock();
        try {
          for (int l = 0; l < 100; l++) {
            j++;
          }
        } catch (Exception e) {
          e.printStackTrace();
        } finally {
          relock.unlock();
        }
      }
      System.out.println(Thread.currentThread().getName() + " has sum i with i=" + i + " j=" + j);
    } catch (Exception e) {
      e.printStackTrace();
    } finally {
      relock.unlock();
    }
  });
}


@Test
public void test() {
  Thread t1 = new Thread(t_sync);
  Thread t2 = new Thread(t_sync);
  Thread t3 = new Thread(t_sync);
  Thread t4 = new Thread(t_sync);
  t1.start();
  t2.start();
  t3.start();
  t4.start();
}

@Test
public void test2() {
  Thread t1 = new Thread(t_reentrant);
  Thread t2 = new Thread(t_reentrant);
  Thread t3 = new Thread(t_reentrant);
  Thread t4 = new Thread(t_reentrant);
  t1.start();
  t2.start();
  t3.start();
  t4.start();
}
```

##### 其他函数

-   new ReentrantLock(true) 默认为非公平锁队列,传入后为公平队列
-   tryLock() 
-   tryLock(long timeout,TimeUnit unit) 在指定时间内尝试获取锁
-   new ReentrantLock(boolean isFair) 构建是否是公平锁

##### Condition 条件

ReentranctLock是synchronized轻量级实现,在JUC之前,我们会使用synchronized+wait/notify去控制线程之间的通信.且Condition相比于wait/notify其使用方式更多.我们先实现下普通的wait/notify机制,Condition提供了await/signal方法.

Condition实际上是个接口,利用可重入锁的.newConditon()方法可以建立一个condition队列,每个condition都维护着自己的队列,而wait只有一个\_waitSet

```java
static final Object lock = new Object();
static Thread t1 = new Thread(() -> {
  synchronized (lock) {
    System.out.println("t1 wait");
    try {
      lock.wait();
      System.out.println("t1 wakeup");
    } catch (InterruptedException e) {
      e.printStackTrace();
    }
  }
});
static Thread t2 = new Thread(() -> {
  synchronized (lock) {
    System.out.println("t2 notifyAll");
    lock.notifyAll();
  }
});

static ReentrantLock reentrantLock = new ReentrantLock();
static Condition condition = reentrantLock.newCondition();
// 对应锁的条件要通过.newCondition()去获取
static Thread t3 = new Thread(() -> {
  reentrantLock.lock();
  try { // 这种写法固定
    System.out.println("t3 await");
    condition.await(); // 效果相当于wait,释放锁线程进入等待队列
    System.out.println("t3 wakeup");
  } catch (InterruptedException e) {
    e.printStackTrace();
  } finally {
    reentrantLock.unlock();
  }
});
static Thread t4 = new Thread(() -> {
  reentrantLock.lock();
  try {
    System.out.println("t4 signal");
    condition.signalAll(); // 效果相当于notifyAll
  } finally {
    reentrantLock.unlock();
  }
});
```

我们来看看两个等待队列的情况

```java
public class BoundedBuffer {
    static volatile int count = 0;
    static final int full = 5;
    static final int empty = 0;
    static Lock lock = new ReentrantLock();
    static Condition notEmpty = lock.newCondition();
    static Condition notFull = lock.newCondition();

    static final ExecutorService pool = Executors.newFixedThreadPool(4);

    @Test
    public void test() {
        for (int i = 0; i < 20; i++) {
            if (new Random().nextDouble() > .5) {
                pool.submit(BoundedBuffer::consume);
            } else {
                pool.submit(BoundedBuffer::produce);
            }
        }
    }

    public static void produce() {
        lock.lock();
        try {
            while (count == full) {
// 这里不用if的理由就是被唤醒的时候依然有其他程序可能在修改此时的count值,
// 因为是并发执行的,所以也可以weak性质的认为while的线程安全可靠性相对好点
                System.out.println("wait for notfull");
                notFull.await();
            }
            count += 1;
            log("produce");
            notEmpty.signal();
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            lock.unlock();
        }
    }

    public static void consume() {
        lock.lock();
        try {
            while (count == empty) {
                System.out.println("wait for notempty");
                notEmpty.await();
            }
            count -= 1;
            log("consume");
            notFull.signal();
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            lock.unlock();
        }
    }

    public static void log(String mode) {
        System.out.println(Thread.currentThread().getName() + " " + mode + "->" + count);
    }

}
```

这里稍微进去看下源码的话就会知道,其是由AQS实现的,不同于c++的\_entrySet和\_waitSet,其是由AQS里面的Node维护的CLH队列.其内部调用了LockSupport.park和LockSupport.unpark(thread),所以线程会挂起并进入等待队列和wait行为基本一致(不改变markword)

除了await(),signal(),signalAll()之外其也有一些重载方法

-   await(long time, TimeUnit unit)
-   awaitNanos(long nanosTimeout)
-   awaitUntil(Date date)

总之可以把其当成一个wait/notify的替代使用工具即可,其源码分析在前面的AQS后文中的reentrantlock的源码中有分析过此



#### ReadWriteLock 读写锁

这个锁需要我们关注读者写者问题,我们可以知道`读写,写写`的过程是互斥的,而`读读`的过程是共享的.为了解决这些问题,JUC提供了读写锁.

ReadWriteLock同样是个接口,其要求实现ReadLock和WriteLock

ReetrantReadWriteLock的理解可以分为两个部分,ReadLock/WriteLock和可重入部分,我们知道读写是互斥的写写是互斥的,读读是共享的,这其实对应AQS就有两种锁获得的实现,如下

|      | 读     | 写     |
| :--- | :----- | :----- |
| 读   | 共享锁 | 独占锁 |
| 写   | 独占锁 | 独占锁 |

对于一般读写线程我们可以直接用读写来规定,如下

```java
static ExecutorService pool=Executors.newFixedThreadPool(10);
static ReadWriteLock readWriteLock = new ReentrantReadWriteLock();
static Lock readLock = readWriteLock.readLock();
static Lock writeLock = readWriteLock.writeLock();
static String book = "b";

static void read() {
  readLock.lock();
  try {
    System.out.println(Thread.currentThread() + " is reading the book");
    System.out.println(book);
  } finally {
    readLock.unlock();
  }
}

static void write() {
  writeLock.lock();
  try {
    System.out.println(Thread.currentThread() + " is writing the book");
    book += "b";
    System.out.println(book);
  } finally {
    writeLock.unlock();
  }
}

@Test
public void test() {
  for (int i = 0; i < 40; i++) {
    if(new Random().nextDouble()>.5) {
      pool.submit(ReentrantReadWriteLockDemo::write);
    }else{
      pool.submit(ReentrantReadWriteLockDemo::read);
    }
  }
}
```

其使用相对简单,但其设计相对复杂,接下来我们来了解下其可重入部分的行为,关于如何设计实现请参考AQS的例子中的分析.

```java
@Test
public void test2() {
  readLock.lock();
  System.out.println("get read lock");
  writeLock.lock();
  System.out.println("get write lock"); // 线程阻塞不会被运行
}

@Test
public void test3() {
  writeLock.lock();
  System.out.println("get write lock");
  readLock.lock();
  System.out.println("get read lock");
}
```

如上现象为,获取了读锁但是没有获取写锁,但获取了写锁之后就可以再次获取到读锁.其实从刚开始读写互斥可以明白可重入不是对所有锁的.我们称之为`锁降级`,即写锁可以降级为读锁.

读锁和写锁可以理解为两种不同程度的锁,显然写锁具有更高的排他性,读锁不排斥读锁,而写锁排斥一切读写.在源码解析过程中会详细看到这种锁的实现.我们说下为何支持降级不支持升级,**假如有一个线程获取到了读锁,另一个线程要从读锁升级到写锁,那么就有可能会出现其他已经获取到读锁的进程被迫中止读,要么产生大量中断,要么读到错误数据.**

我们可以通过其源码了解其是如何设计这样的锁,下面介绍该锁的其他方法

-   new ReentrantReadWriteLock(true) 公平锁
-   writeLock.newContion() 可以像wait/notify一样使用await/signal readLock不可用



#### StampedLock

StampedLock,Stamp意为邮戳,JDK1.8引入,其可以视为读写锁ReadWriteLock的一个改进,其主要是允许了锁升级过程(即可以读锁后获取写锁写入)

我们上面使用的ReentrantReadWriteLock,StampLock是一个增强版本,前者是多个线程读锁共享(无写锁),写锁独享.但是如果读线程过多,写线程少的话就容易产生饥饿问题,尽管有公平锁的机制,但那是四横吞吐量为代价的.

分段锁的特点

-   所有获取锁的方法,都返回一个邮戳(Stamp),**Stamp为0表示获取失败**,其余都表示成功
-   所有释放锁的方法,都需要一个邮戳(Stamp),这个Stamp必须是和成功获取锁时得到的Stamp一致
-   StampedLock是不可重入的(如果一个线程已经持有了写锁,再去获取写锁的话就会造成死锁)

StampedLock有三种访问模式

-   Reading: 功能和ReentrantReadWriteLock的读锁类似
-   Writing: 功能和ReentrantReadWriteLock的写锁类似
-   Optimistic reading: 这是一种优化的读模式

StampedLock支持读锁和写锁的相互转换

```java
public class Point {
  private final StampedLock stampedLock = new StampedLock();

  private double x;
  private double y;

  public void move(double deltaX, double deltaY) {
    long stamp = stampedLock.writeLock(); // 获取写锁
    try {
      x += deltaX;
      y += deltaY;
    } finally {
      stampedLock.unlockWrite(stamp); // 释放写锁
    }
  }

  public double distanceFromOrigin() {
    long stamp = stampedLock.tryOptimisticRead(); // 获得一个乐观读锁
    double currentX = x;
    double currentY = y;
    
    if (!stampedLock.validate(stamp)) {
      stamp = stampedLock.readLock();
      try {
        currentX = x;
        currentY = y;
      } finally {
        stampedLock.unlockRead(stamp);
      }
    }
    // 如果x,y修改了的话stamp验证失败,就会直接执行到这,
    // 如果验证成功那就重新获取悲观读锁,在修改一次.
    return Math.sqrt(currentX * currentX + currentY * currentY);
  }
  
  void moveIfAtOrigin(double newX, double newY) {
    long stamp = stampedLock.readLock();
    try {
      while (x == 0.0 && y == 0.0) {
        long ws = stampedLock.tryConvertToWriteLock(stamp);  
        // 读锁升级为写锁
        if (ws != 0L) { // 写锁升级成功
          stamp = ws;
          x = newX;
          y = newY;
          break;
        } else { // 如果获取失败就释放读锁尝试获取写锁
          stampedLock.unlockRead(stamp);
          stamp = stampedLock.writeLock();
        }
      }
    } finally {
      stampedLock.unlock(stamp);
    }
  }
}
```

从上面的而是用情况可以看出,其重点是重新尝试获取到重新获取,而stamp作为一个内在的状态进行传递.可以通过如下代码看出来获取失败的效果

```java
static final StampedLock stampedLcok = new StampedLock();
ExecutorService pool = Executors.newFixedThreadPool(5);
static String book = "b";

@Test
public void test() {
  for (int i = 0; i < 20; i++) {
    if (new Random().nextDouble() > .2) {
      pool.submit(StampLockTest::write);
    } else {
      pool.submit(StampLockTest::read);
    }
  }
}

private static void read() {
  long stamp = stampedLcok.writeLock();
  try {
    System.out.println(Thread.currentThread().getName() + " is writing the book");
    book += "b";
    System.out.println(book);
  } finally {
    stampedLcok.unlockWrite(stamp);
  }
}

private static void write() {
  long stamp = stampedLcok.tryOptimisticRead();
  System.out.println(Thread.currentThread().getName()+" read the book" + book);
  if (stampedLcok.validate(stamp) == false) {
    System.out.println("optimisticRead do not work and acquired for a readLock");
    stamp = stampedLcok.readLock();
    try {
      System.out.println("read the book" + book);
    } finally {
      stampedLcok.unlockRead(stamp);
    }
  }

}
```

经过测试可知,ReentrantLock的性能稍微低于StampedLock.

### java.util.cocurrent.atomic

该包提供了很多基本类型**原子操作**,我们以AtomicInteger为例说明该包的使用方法及实现

#### AtomicInteger

```java
static final AtomicInteger i = new AtomicInteger(3);

@Test
public void test() {
  System.out.println(i.get());
  System.out.println(i.incrementAndGet());
  System.out.println(i.addAndGet(3));
  System.out.println(i.decrementAndGet());

  System.out.println(i.accumulateAndGet(1, (x, y) -> {return 2*x + y;}));
  System.out.println(i.getAndSet(16)+"---");
  System.out.println(i.getAndUpdate((x) -> {return x * x;}));
  System.out.println(i.get());

	System.out.println(i.doubleValue());
}
```

其操作主要如上全是基于CAS的原子性操作,如果熟悉其他函数式编程语言/C的函数指针,上面的代码其实会很简谐,我们总结下使用的方法

-   get
-   incrementAndGet/getAndIncrement/getAndDecrement 自增/减获取,唯一不同则是获取值先后
-   getAndSet 重新设值
-   getAndUpdate((x)->{return func(x);}) 根据现有值进行函数计算
-   accumulateAndGet((x,y)->{return func(x,y);}) 累加计算,其实就是二元函数
-   doubleValue() 类型转换

##### 实现原理

经过锁的研究之后Atomic的实现应该会相对简单一点,无论是包含函数的计算,还是重新设值,其实本质上都是通过**CAS**和**版本号**进行控制.所有拥有原子类的线程,无非是在原子类上自旋

AtomicInteger的大部分操作其真正的底层来自于Unsafe类提供的CAS方法和直接为对象偏移地址注入值

```java
private volatile int value; 
// 其核心数据结构,volatile限制了其读写是原子性的不会被中断,所以set和get的方法很简单

public final int getAndIncrement() {
  return unsafe.getAndAddInt(this, valueOffset, 1);
}
// 我们可以看到其实现是unsafe.getAndAddInt如下

public final int getAndAddInt(Object instance, long offset, int op) {
  int tmp;
  do {
    tmp = this.getIntVolatile(instance, offset); // 直接从内存读值
  } while(!this.compareAndSwapInt(instance, offset, tmp, tmp + op));
  return tmp;
}
// 可以看到其核心依然是CAS操作,我们把计算的部分拿出来看就是 tmp + op

public final int getAndAccumulate(int x,IntBinaryOperator accumulatorFunction) {
  int prev, next;
  do {
    prev = get();
    next = accumulatorFunction.applyAsInt(prev, x);
  } while (!compareAndSet(prev, next));
  return prev;
}
// 其计算也相对简单,就是利用CAS操作去修改值IntBinaryOperator,涉及匿名函数的设计
// 其实就很简单,一个类标注@FuntionalInterface,然后就可以定义函数的返回值等签名
// 然后调用的时候则使用匿名函数的调用方法即可调用1.8的语法,注解被JVM识别
```

#### AtomicIntegerArray

这里想首先说明的是数组的存储结构和原理,我们知道在jvm中`int[]`为一类型对应连续的空间其是在对象的实例数据区域,如果是基本类型数组则是直接代表值,如果不是则是4Byte大小的引用指向堆内存,而JUC对数组的一些操作进行了封装

```java
AtomicIntegerArray arr = new AtomicIntegerArray(new int[]{1,2,3});
AtomicIntegerArray arr = new AtomicIntegerArray(3);
arr.set(2,4);
arr.get(2);
arr.decrementAndGet(2); // 对index=2的地址进行自减
arr.incrementAndGet(2);

```

```java
// get和set实现本质上就是通过计算数组内偏移直接volatile设置值
private static final int base = unsafe.arrayBaseOffset(int[].class);
private static long byteOffset(int i) {
  return ((long) i << shift) + base;
}
private long checkedByteOffset(int i) {
  if (i < 0 || i >= array.length)
    throw new IndexOutOfBoundsException("index " + i);
  return byteOffset(i);
}
public final void set(int i, int newValue) {
  unsafe.putIntVolatile(array, checkedByteOffset(i), newValue);
}
```

其其他方法和原理和AtomicInteger类似,只不过CAS的地方变成了数组的相对地址



### 并发容器

该章节的源码会在另一文档中说明,此中仅介绍几种常见容器的的用法,这里介绍一些命名规则,一般命名为Concurrent的都是用CAS实现粒度很小的锁来实现高性能操作的数据结构,而其他的命名则是会用到JUC的同步工具来实现数据结构,从性能而言比之Concurrent要稍微低下一点.(例如BlockingQueue和ConcurrentQueue),他们又分别适应不同的场景.

#### ConcurrentHashMap

Concurrent采用分段锁的特性,能做到不同部分的数据进行加锁,其能保证**数据读写的安全,但不能保证加入前计算是安全的**(参考数据库连接池或其他多线程问题)

```java
ConcurrentHashMap<String,String> map = new ConcurrentHashMap<>();
map.put("key","value");
map.putIfAbsent("key","value2"); // 如果key存在返回value否则返回null
map.get("key");
map.remove("key");
```

其操作和hashmap基本一致其中有几点需要注意

-   get方法不涉及锁,获取对象没有使用锁
-   put/remove方法要用到锁,但不一定有锁征用
-   ConcurrentHashMap允许一边遍历一边删除元素(锁不互斥)



#### LinkedBlockingQueue

顾名思义是一个用在某些情况会阻塞的队列,其重要程度仅次于CocurrentHashMap.可以用来作为所有池技术的底层数据结构.其会在以下两种情况下进行阻塞

-   当队列满了的时候入队列,入队线程进行阻塞等待
-   当队列空了的时候出队列,出队线程进行阻塞等待

很显然线程池的任务队列用的就是这种BlockingQueue.该队列专门用在生产者消费者的缓冲区数据结构中,从操作我们就可以看出其为线程安全的,其内部有两把可重入锁及他们的Condition分别制约入队和出队.且每次入队出队的时候都选择使用相应的锁,对正常入队出队独占.

这里说一个点如果是Deque则是一把全局锁,两个Condition制约入队和出队.即我们也完全可以用wait/notify去实现(如下实现的生产者消费者).只是非JUC的Condition其粒度和功能都有限.

| -       | Throws Exception | Special Value | Blocks | Times Out                   |
| :------ | :--------------- | :------------ | :----- | :-------------------------- |
| Insert  | add(o)           | offer(o)      | put(o) | offer(o, timeout, timeunit) |
| Remove  | remove(o)        | poll()        | take() | poll(timeout, timeunit)     |
| Examine | element()        | peek()        |        |                             |

我们可以看到其除了常规的入队操作和出兑操作以外,还有阻塞的方法put和take.如上三种方法,如果失败他们的行为特征就会如上面的表头一样,所以我们想真正调度该队列用的是put和take.

```java
BlockingQueue queue = new LinkedBlockingQueue(128);
CountDownLatch cdl = new CountDownLatch(1);
new Thread(()->{cld.await();queue.take();}).start();
new Thread(()->{cld.await();queue.put("1");}).start();
cdl.countDown();
```

上面两个线程调度就能清晰看见其调度情况,一个线程是进入了阻塞.更详细的源码解读我们放到了另外的文档.另外一提,所谓的阻塞队列即是消息队列,在分布式系统中,又称发布订阅模式.BlockingQueue在基本所有环境下都是一种解耦合的强力存在,在web中有数据库削峰,异步处理日志记录等,在jdk中可以解耦合线程和任务,作为线程池的重要数据结构,其阻塞特性可以让其获得非常简单的多线程实现.该类的使用和实现在多线程中是非常重要的.



#### CocurrentLinkedQueue

ConcurrentQueue和ConcurrentHashMap的Concurrent一样,其是入队和出队安全的队列,其本质上使用了CAS去进行此处操作.

```java
ConcurrentLinkedQueue<String> queue = new ConcurrentLinkedQueue<>();
queue.offer("element"); // 入队
queue.poll(); // 出队
queue.peek(); //查看对头元素,但不出队
queue.remove("element"); // 移除出队伍
```

其和ConcurrentHashMap在操作数据结构上的行为很相似.和BlockingQueue就很明显是两种完全不同的队列了,和BlockingQueue对比,ConcurrentLinkedQueue用了CAS执行了高效的入队和出兑操作,其有一特点,当使用此数据结构的线程不多的时候其有着相当高的性能,但是对于BlockingQueue而言,其避免了CAS的缺点即CPU空转线程白等浪费,因此当多个线程同时使用且经常大于队列本身的大小的时候,BlockingQueue具有很大的优势,反观ConcurrentLinkedQueue则适合在一些需要高速存取修改队列元素的时候使用.

关于他们的源码解析会在另一文档中详细说明.



#### CopyOnWriteArrayList





### **ThreadLocal**

ThreadLocal可以理解为是给每个线程创建副本.至于为什么不使用原生堆内存变量,是因为堆内存的变量无论是串行的低速,还是抢占式访问可能会不同步的瞎修改.ThreadLocal直接根据线程的数量产生相应的副本,显然效率是要高上很多.理解为`ThreadLocalVariable`会比原来这个词要好点.

threadlocal有两种使用场景

-   每个线程需要一个独享的对象,通常是工具类比如simpleDateFromat,random等
-   每个线程需要保存一些独立的线程级别的全局的变量,线程在调用各个方法的时候,可以从方法中获取线程变量,避免参数过度传递

```java
public static ExecutorService THREAD_POOL = Executors.newFixedThreadPool(10);
static SimpleDateFormat DATE_FORMAT = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");

for(int i=0;i<1000;i++){
  int sec = i;
  THREAD_POOL.submit(()->{
    // 在这里使用synchronized性能会很低,不用就会出错
    // 如果在这里new SimpleDateFormat 会在堆中产生大量对象
    String date = date(sec);
    System.out.println(date);
  })
}

String date(int seconds) {
  Date date = new Date(1000 * seconds);
  return DATE_FORMAT.format(date); // 该方法不是线程安全的(共享变量存在)
}
```

ThreadLocal就是为了解决这个问题的,或者说ThreadLocal利用了一种高效的方法,把一个线程不安全的方法变成了线程安全的方法

```java
class ThreadSafeDateFormatter {
    public static ThreadLocal<SimpleDateFormat> dateFormatThreadLocal = new ThreadLocal<SimpleDateFormat>() {
        @Override
        protected SimpleDateFormat initialValue() {
            return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
        }
    };
}
/*
class ThreadSafeDateFormatter extends ThreadLocal<SimpleDateFormat>{ 
  @Override
  protected SimpleDateFormat initialValue() {
    return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
  }  
}
其实例和ThreadLocal一致,
*/
String date(int seconds) {
  Date date = new Date(1000 * seconds);
  SimpleDateFormat simpleDateFormat = 
    ThreadSafeDateFormatter.dateFormatThreadLocal.get();
  // 这里ThreadLocal的意思是每个线程都有一个变量副本,所以在线程内调用此方法的时候可以认为每个线程都有各自的simpleDateFormat,所以不会出现线程安全问题
  return simpleDateFormat.format(date);
}
```

对于`每个线程需要保存一些独立的线程级别的全局的变量,线程在调用各个方法的时候,可以从方法中获取线程变量,避免参数过度传递`而言,在web中,Service和DAO层,如果要获得某个类的单一属性,要么是DAO中有很多冗余函数,要么得用Data类的实例去做中间变量来回传递.

对此我们可以用ThreadLocal去解决,比如登录时持有同一User信息,某段业务又是同一线程去处理,我们可以在在堆内存里面申请一块空间放ThreadLocal(引用留在永久代),那么我们可以调用其实例的set方法,然后在其他地方使用.get完成线程级别的提取.

```java
// tools包下或在工具类的位置
class ThreadLocalProcessor {
	public static ThreadLocal<Student> studentThreadLocalVariable = 
    new ThreadLocal<>();
}

// controller比如登录时获取到student,然后加入到ThreadLocal里面
ThreadLocalProcessor.studentThreadLocalVariable.set(student);

// service下
class NameService{
  public String getName(){
  	return ThreadLocalProcessor.studentThreadLocalVariable.get().name;
  }
}
```

#### ThreadLocal原理

![](http://www.hollischuang.com/wp-content/uploads/2020/05/4.png)

我们需要注意的就是`ThreadLocal`,`ThreadLocalMap`,`Thread`三个变量,上面说明了三者的关系,所以我们看到了`Thread实例`内维护着`ThreadLocalMap`,而`ThreadLocalMap`又维护着相应的数据实例`Object`

ThreadLocalMap是ThreadLocal里面的一静态内部类.

Thread里面,threadLocals变量和inheritableThreadLocals变量都是实现ThreadLocal的重要数据结构.

ThreadLocal里面维护者一个`Entry[] table`

```java
// 默认的数组初始化容量
private static final int INITIAL_CAPACITY = 16;
private Entry[] table;
// 数组内部元素个数
private int size = 0;
// 数组扩容阈值，默认为0，创建了ThreadLocalMap对象后会被重新设置
private int threshold;
```

```java
static class Entry extends WeakReference<ThreadLocal<?>> {
  /** The value associated with this ThreadLocal. */
  Object value;
  Entry(ThreadLocal<?> k, Object v) {
    super(k);
    value = v;
  }
}
```

我们可以看下ThreadLocal初始化,其为一延迟加载

```java
ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {
    // 初始化Entry数组，大小 16
    table = new Entry[INITIAL_CAPACITY];
    // 用第一个键的哈希值对初始大小取模得到索引，和HashMap的位运算代替取模原理一样
    int i = firstKey.threadLocalHashCode & (INITIAL_CAPACITY - 1);
    // 将Entry对象存入数组指定位置
    table[i] = new Entry(firstKey, firstValue);
    size = 1;
    // 初始化扩容阈值，第一次设置为10
    setThreshold(INITIAL_CAPACITY);
}
```

```java
public T get() {
  Thread t = Thread.currentThread();
  ThreadLocalMap map = getMap(t); // 拿到t里面的.threadLocals成员变量
  if (map != null) {
    ThreadLocalMap.Entry e = map.getEntry(this); 
    // 获得当前threadLocal为key的一行
    if (e != null) {
      @SuppressWarnings("unchecked")
      T result = (T)e.value;
      return result;
    }
  }
  // 如果找不到变量就初始化一个
  return setInitialValue();
}
private T setInitialValue() {
  T value = initialValue(); // T value = null;
  Thread t = Thread.currentThread();
  ThreadLocalMap map = getMap(t);
  if (map != null)
    map.set(this, value); // 即本线程会初始化一个{threadLocal:null}的pair
  else
    createMap(t, value); // 否则就初始化Map
  return value;
}
```

get方法比较简单我们来看set的实现

```java
public void set(T value) {
  Thread t = Thread.currentThread();
  ThreadLocalMap map = getMap(t);
  if (map != null)
    map.set(this, value);
  else
    createMap(t, value);
}
// 初始化map
void createMap(Thread t, T firstValue) {
  t.threadLocals = new ThreadLocalMap(this, firstValue);
  // 这里初始化了线程内部的threadLocals变量,get传过来的一般是null,set传过来的看后续
}
private void set(ThreadLocal<?> key, Object value) {

  Entry[] tab = table;
  int len = tab.length;
  int i = key.threadLocalHashCode & (len-1); // 计算key的下标

  // 这个循环和map的遍历相似,因为有可能是冲突的,所以要一直找到空的位置填上去
  for (Entry e = tab[i];
       e != null;
       e = tab[i = nextIndex(i, len)]) {
    ThreadLocal<?> k = e.get();

    if (k == key) {
      e.value = value; // 如果已经存在且是当前对象
      return;
    }

    if (k == null) { // 找到了个可以填坑的位置(key失效了)
      replaceStaleEntry(key, value, i); // 填上去
      return;
    }
  }
  // 结束没填上去(填上去返回了),此时i是nextIndex,这里只有情况,e=null,因为后面找不到了nextIndex把其当成一个闭环来继续找,绝对找的到
  tab[i] = new Entry(key, value);
  int sz = ++size;
  if (!cleanSomeSlots(i, sz) && sz >= threshold) // 检查扩容
    rehash();
}
```

至此,我们再思考以下代码发生了什么事

```java
class ThreadSafeDateFormatter {
    public static ThreadLocal<SimpleDateFormat> dateFormatThreadLocal = new ThreadLocal<SimpleDateFormat>() {
        @Override
        protected SimpleDateFormat initialValue() {
            return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
        }
    };
}
String date(int seconds) {
  Date date = new Date(1000 * seconds);
  SimpleDateFormat simpleDateFormat = 
    ThreadSafeDateFormatter.dateFormatThreadLocal.get();
  // 这里ThreadLocal的意思是每个线程都有一个变量副本,所以在线程内调用此方法的时候可以认为每个线程都有各自的simpleDateFormat,所以不会出现线程安全问题
  return simpleDateFormat.format(date);
}
```

我们可以看到每个线程调用的时候还是用了`new SimpleDateFormat`的,但是每个线程调用的都是自己的独立部分,所以绝不会有线程安全问题,且这些ThreadLocal对象都保持弱引用,另外前文中提到的1000个对象也是不会创建的,**因为只有10个线程所以也就是10个对象**,在这期间就完成了缓存ThreadLocal,所以既不会发生线程安全问题,也不会失去过多内存

内存泄漏问题,通过代码我们知道ThreadLocalMap的弱引用ThreadLocal(key)有可能会变成null,而其value就不会(强引用),所以我们不调用remove方法有可能会导致内存泄漏.



### CountDownLatch 倒计时

用来控制线程,执行完成之后用.countDown()倒数,然后在某一线程中可以用.await()阻塞等待,其语义为等其他线程完成之后,才能进行.await()之后的操作,在AQS中我们可以看到其代码分析

```java
public class CDLTest {
    static final CountDownLatch cdl = new CountDownLatch(2);
    static Thread t1, t2, t3;
    static {
        t1 = genThread(1);
        t2 = genThread(2);
        t3 = genThread(3);
    }
    private static Thread genThread(long delay){
        return new Thread(()->{
            try {
                // compute
                TimeUnit.SECONDS.sleep(delay);
                // finish and count down
                System.out.println(delay +"-Thread had finished");
                cdl.countDown();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });
    }

    @Test
    public void test() throws InterruptedException {
        t1.start();
        t2.start();
        t3.start();
        cdl.await(); // if there is two finish could wakeup main Thread
        System.out.println("main thread finished");
    }
}
```

关于CountDownLatch的两种用法

-   在n个线程完成之后,在执行某个线程的代码 (在n个线程结束前countdown,在主线程await)
-   n个线程在同一时刻并发运行 (在n个线程里面await,在主线程里面countdown)

### Cyclibarrier 循环屏障

CyclicBarrier意思就是可以重复使用的屏障,其不像CountDownLatch那样复杂.但实现的功能和CountDownLatch很像,其和CountDownLatch最大的不同是,CountDownLatch是一次性使用的,使用完后内部维护的count不能更改.其内部成员变量.如下

```java
static final ExecutorService pool = Executors.newFixedThreadPool(3);
static final CyclicBarrier cyclicBarrier = new CyclicBarrier(3,()->{
  System.out.println("merge data");
});

@Test
public void test() throws InterruptedException {
  for (int i = 0; i < 6; i++) {
    pool.submit(() -> {
      try {
        Thread.sleep(1000);
        // compute sth
        System.out.println(Thread.currentThread().getName() + " compute over and waited");
        cyclicBarrier.await();
      } catch (InterruptedException e) {
        e.printStackTrace();
      } catch (BrokenBarrierException e) {
        e.printStackTrace();
      }
      System.out.println(Thread.currentThread().getName() + " wait done");
      // compute over
    });
  }
  Thread.sleep(100000);
}
```

从上面可以看到三个线程在`cyclicBarrier.await();`处进行了等待,直到有三个线程都执行了这句话,我们当然可以用CountDownLatch去实现,但是CyclicBarrier可以重复利用的特性就出来了.且可以传入Runnable接口,用于告诉线程执行完之后的操作,可以为null.

```java
private final ReentrantLock lock = new ReentrantLock();
private final Condition trip = lock.newCondition(); // 线程拦截器
private final int parties; // 每次拦截的线程数
private final Runnable barrierCommand;// 换代前执行的任务
private Generation generation = new Generation(); // 表示栅栏的当前代
// 计数器,初始化的时候和parties相同(每一代之后会重置)
private int count;
// 静态内部类Generation
private static class Generation {
  boolean broken = false;
}
```

其通过条件队列trip进行阻塞,

![](https://javadoop.com/blogimages/AbstractQueuedSynchronizer-3/cyclicbarrier-3.png)

```java
public int await() throws InterruptedException, BrokenBarrierException {
    try {
        return dowait(false, 0L);
    } catch (TimeoutException toe) {
        throw new Error(toe); // cannot happen
    }
}
private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException {
  final ReentrantLock lock = this.lock;
  lock.lock();
  try {
    final Generation g = generation;
    if (g.broken) // 一般为false
      throw new BrokenBarrierException();
    
    if (Thread.interrupted()) {
      breakBarrier();
      throw new InterruptedException();
    }
    
    
    int index = --count;
    // index == 0 到达屏障点,可以放行
    if (index == 0) {  // tripped
      
      boolean ranAction = false; // 表示回调是否执行成功
      try {
        final Runnable command = barrierCommand;
        if (command != null)
          command.run();
        // 如果没有抛出异常证明执行成功
        ranAction = true;
        nextGeneration(); // 重置一切,唤醒线程
        return 0;
      } finally {
        if (!ranAction)
          breakBarrier(); // 唤醒其他线程同时打破屏障(设为broken)
      }
    }
    
    // index!=0 即不可放行
    for(;;) {
      try {
        if (!timed) // 如果是不限时
          trip.await(); // 那么就等待了
        else if (nanos > 0L)
          nanos = trip.awaitNanos(nanos);
      } catch (InterruptedException ie) {
        if (g == generation && !g.broken) {
          breakBarrier(); // 打破屏障,唤醒线程
          throw ie;
        }else{
          // We're about to finish waiting even if we had not
          // been interrupted, so this interrupt is deemed to
          // "belong" to subsequent execution.
          Thread.currentThread().interrupt();
        }
      }
      // 检查有无打破
      if (g.broken)
        throw new BrokenBarrierException();
      if (g != generation)
        return index;
      if (timed && nanos <= 0L) { // 超时,需要打破
        breakBarrier();
        throw new TimeoutException();
      }
      // 到这里，说明屏障g既没有被打破也没有被替换，那么继续下一次循环，此时可能会继续等待,此时这里是虚假唤醒
    }
  } finally {
    lock.unlock();
  }
}
private void nextGeneration() {
  trip.signalAll();
  count = parties;
  generation = new Generation();
}
// broken线程会抛出异常.打破线程意味着唤醒其他线程,我们无法直接调用它.如果想重置的话
// 使用下面的reset方法
private void breakBarrier() {
  generation.broken = true;
  count = parties;
  trip.signalAll();
}

public void reset() {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        breakBarrier();   // break the current generation
      	// 其他线程执行await的话会抛出异常的,然后执行下面的逻辑
        nextGeneration(); // start a new generation
    } finally {
        lock.unlock();
    }
}
```



### Semaphore信号量

semaphore一般用于限流,即明确限制资源的数量.比如数据库连接池,同时进行连接的数量达到限制了之后就不能够在连接了,我们知道可以用wait/notify实现这种机制,但是信号量用于实现更加简单和便捷,当然CountDownLatch不能实现,因为信号量涉及到增加和减少,而CountDownLatch只适用于减少,而Cyclebarrier不能控制增加,所以也不使用,换句话说,信号量其实相比于CountDownLatch和Cyclebarrier的实现粒度要更加细了.

```java
final static Semaphore semaphore = new Semaphore(10);
final static ExecutorService pool = Executors.newFixedThreadPool(3);

@Test
public void test() throws InterruptedException {
  for (int i = 0; i < 10; i++) {
    pool.submit(() -> {
      try {
        if (semaphore.availablePermits() == 0) {
          System.out.println(Thread.currentThread().getName() + " 无资源,进入阻塞");
        }
        System.out.println(Thread.currentThread().getName() + " 申请资源");
        semaphore.acquire(2);
        System.out.println(Thread.currentThread().getName() + " 还剩" + semaphore.availablePermits());
        Thread.sleep(100);
        semaphore.release(2);
        System.out.println(Thread.currentThread().getName() + " 释放资源");
      } catch (InterruptedException e) {
        e.printStackTrace();
      }

    });
  }
  Thread.sleep(1000000);
}
```

其方法比较简单,且可以动态申请每次的资源量,例如上面不带参数就默认为1,其和Reentrant的设计理念差不多,有公平锁和非公平锁都在获取锁上得到体现.如下为其实现.公平模式和非公平模式是通过CLH队列的第二节点来实现的,非公平锁是CAS直接获取,而公平锁一定是要正在等待的节点才能获取锁,从吞吐量来讲,非公平锁更胜一筹,但是有可能导致线程饥饿问题.其粒度比起CycleBarrier更细直接使用了AQS实现Sync队列.

```java
private final Sync sync;

public Semaphore(int permits) {
    sync = new NonfairSync(permits);
}

public Semaphore(int permits, boolean fair) {
    sync = fair ? new FairSync(permits) : new NonfairSync(permits);
}
```

```java
public void acquire(int permits) throws InterruptedException {
    if (permits < 0) throw new IllegalArgumentException();
    sync.acquireSharedInterruptibly(permits);
}
// AQS内部方法
public final void acquireSharedInterruptibly(int arg) throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    if (tryAcquireShared(arg) < 0)
        doAcquireSharedInterruptibly(arg); // AQS内部方法不断循环尝试获取锁
}
```

由于其能被多个线程持有自然其实现的是共享锁.共享锁要求我们自己保证tryAcquireShared的线程安全性.所以我们看到无论是获取还是释放我们都使用了大量的loop-CAS操作.而独占锁的话不需要这一点.

```java
static final class FairSync extends Sync {
    protected int tryAcquireShared(int acquires) {
        for (;;) {
            if (hasQueuedPredecessors()) 
              // 自然其如果有等待线程
                return -1;
            int available = getState();
            int remaining = available - acquires; // 剩余
            if (remaining < 0 || compareAndSetState(available, remaining))
                return remaining;
        }
    }
}
static final class NonfairSync extends Sync {
    protected int tryAcquireShared(int acquires) {
        return nonfairTryAcquireShared(acquires);
    }
}
abstract static class Sync extends AbstractQueuedSynchronizer {
    final int nonfairTryAcquireShared(int acquires) {
        for (;;) {
            int available = getState();
            int remaining = available - acquires;
            if (remaining < 0 || compareAndSetState(available, remaining))
                return remaining;
        }
    }
}
```

我们来看其释放

```java
public void release(int permits) {
    if (permits < 0) throw new IllegalArgumentException();
    sync.releaseShared(permits);
}
// AQS内部方法
public final boolean releaseShared(int arg) {
    if (tryReleaseShared(arg)) {
        doReleaseShared(); // 这里面是如何释放锁的
        return true;
    }
    return false;
}
protected final boolean tryReleaseShared(int releases) {
    for (;;) {
        int current = getState();
        int next = current + releases;
        if (next < current) // overflow
            throw new Error("Maximum permit count exceeded");
        if (compareAndSetState(current, next))
            return true;
    }
}
```

---

实现一个综合的问题:

> 若一个工厂有5台机器,但是有8个工人,一台机器同时只能被一个工人使用,只有使用完了，其他工人才能继续使用,每个工人之多工作若干秒,工作两轮,每轮都统计工作量.

```java
static AtomicLong sumResult = new AtomicLong(0L);
static final Semaphore machines = new Semaphore(5);
static final ExecutorService pool = Executors.newFixedThreadPool(8);
// 这里的线程池个数不能小于8,因为是要等所有工人完成一轮之后都要统计才能继续,
// 如果这里线程小于8那么就会由于等待而不能继续往下,整个线程死锁
static final CyclicBarrier cyclicBarrier = new CyclicBarrier(8, () -> {
  System.out.println("工作时长:" + sumResult.get());
});

@Test
public void test() throws InterruptedException {
  for (int i = 0; i < 16; i++) {
    int finalI = i;
    pool.submit(() -> {
      try {
        machines.acquire();
        System.out.println("员工" + finalI + "使用机器");
        long workTime = (long) new Random().nextInt(3000);
        Thread.sleep(workTime);
        sumResult.addAndGet(workTime);
        System.out.println("员工" + finalI + "使用完了机器");
        machines.release();
        cyclicBarrier.await();
      } catch (InterruptedException | BrokenBarrierException e) {
        e.printStackTrace();
      }
    });
  }

  Thread.sleep(1000000);
}
```









## 多线程优化

---

### 核心数与多线程

单核多线程,只能够胜任并发,而不能胜任并行.因为单核心不断线程切换只会带来开销对性能提升上毫无意义.

多核多线程,多核多线程能够胜任并发和并行,多核心物理意义上的处理多线程,多线程的使用理论上可以通过无限个线程无限扩展性能.但因为克制等关系使得其并不能让线程充分利用CPU资源.

- 并发的思考多线程与并行的思考多线程

并发和并行的思考多线程是两个不一样的思考方式,并发的思考则是一个CPU通过不断的线程切换来使得多个程序共同执行,并行的思考方式是每个线程都运行在独立的CPU上,并行的思考方式显然更适合java多线程的思考.虽然初期在wait/notify时我们总会用并发的思考方式去思考,但是到了JUC的同步工具的时候,其实际执行应该是并行而不是并发,线程切换的几率也仅在部分阻塞的情况下才会需要发生.



### I/O与多线程

I/O应该是一大类需要耗时操作的东西,且如果不通过DMA技术(通道等技术)的话,单纯从现有的I/O来看,开启额外的线程在不同核心上进行等待能提高很大的性能,当等待数据传送的过程中又可以通过线程挂起等待I/O完成再来读取线程,而java的I/O内部是不允许中断的,而java也用了NIO来解决问题.



### 耗时计算与多线程

耗时计算与多线程,耗时计算不像I/O,I/O需要等待数据的不断传送,而耗时计算中间是需要CPU进行逻辑运行的,当然也可以交给其他机构(例如GPU去执行).这种情况下我们要做到的是尽量减少重复的计算,优化算法,对于重复的计算不要计算完了让结果抢占,而是一个线程去进行计算,其他线程等待,通过FutureTask或者全局变量可以解决这样的问题.另外值得注意的是系统的瓶颈可能不是由于并行度不够高引起的而是某些重复的耗时操作拉低了系统的性能.





## 锁的总结

---

### 锁的本质

#### 理解层次

说是锁其实理解为某一对象的使用权更加合适 我们从上面代码中已经看出来 锁就是一个对象的使用权 synchronized关键字配合wait notify一起使用 可以完成对象制约线程,我们可以把获得锁理解为获得了资源的使用权,把释放锁理解为放弃了资源的使用权.

在AQS等一些机制中,使用权开始变得模糊不清,一来是锁不单一的是1个对象的使用权那么简单了,有可能是一些状态指示的数量比如`CountDownLatch`里面的count,这个时候应该把锁理解成使用资源的条件,加锁/获得锁指的是完成了这些条件,释放锁则是创造了条件.或者我们可以理解为`锁资源`即`使用锁的资源`,获得锁即是消耗锁资源,释放锁则是生产锁资源.

对于AQS而言,获取(抢占)锁意味着可能造成获取不到进入等待队列,而释放锁意味着可能改变锁的状态而不能释放锁,但成功释放锁会唤醒在等待队列里面的线程.

锁的本质还是对某一段代码进行锁定,这个锁定的意思是只能让相应的线程(1个或者多个)获得这段代码的执行权.

#### 代码层次

从代码而言,锁其实就是同步信息,所谓的同步信息就是指特定对象的markword表示锁信息的倒数3bit的修改权,基于JUC包的理解就是AQS的state的修改权



### 锁的分类

-   乐观锁/悲观锁
-   公平锁/非公平锁
-   独占锁(排他锁)/共享锁
-   读写锁

### 乐观锁和悲观锁

乐观锁和悲观锁并不是具体意义上的一种锁,而是概念意义上的一类锁,一般来说在竞争不激烈的情况下,**乐观锁的效率要高于悲观锁**.

乐观锁是认为线程安全问题不太严重(循环争抢不挂起),所以不会向操作系统申请中断,其他多个线程则是等待,悲观锁则认为线程线程安全问题很大,必须只能让一个线程执行获取锁,所以向操作系统申请中断开销爆炸. 

**所以乐观锁和悲观锁的最主要区别应该是在CPU中断上**

乐观锁的处理方式是尝试修改资源,如果修改的不合法则保留原资源(CAS),另外一提在数据库中也有CAS的操作如下.

```sql
update tableName set field=#{field}, version=version+1 where id=#{id} and version=#{version};
```

悲观锁的处理方式是先获取资源的锁(使用权),然后在修改资源,然后释放锁(使用权)(synchronized)

通过上面两种我们可以知道获取锁的开销一般是要大于直接获取资源的(不绝对),所以给资源加锁和获取判定合法是乐观锁和悲观锁一些本质性的区别.

其实这个乐观和悲观还相对于数据而言,乐观锁认为资源不会被修改,而悲观锁认为资源会被所有人修改,针对不同场景使用不同的锁.两种锁性能上不同,但效果一致,都是让一个线程能获取到相应的资源.

所以我们可以看到**悲观锁其实就是独占锁**.

后续的读写锁中有提到一种观点是,读的过程中不允许写,那么这样的锁是悲观锁.其区别就是乐观锁是估计在读的过程中大概率不会有线程写入.而悲观锁的理解是读的过程中可以能会有线程写入(所以读的过程中不允许写).



### *公平锁和非公平锁

这也是相对而言的,如果每个线程都有相同机会拿到锁他就是个公平锁,如果有线程拿不到锁就是非公平锁.总而言之公平锁和非公平锁就是线程拿到锁的机会不同.

在公平锁中,按照申请锁的顺序去获取锁,线程会直接进入队列去排队,按顺序依次获取,但相应的开销会大很多,除了第一个线程,其他线程都会阻塞,cpu唤醒会产生巨大开销

在非公平锁中,多个线程会直接去尝试获取锁,获取不到在进入等待队列**(抢占)**,cpu会减少线程的唤醒数量**(线程抢占到锁了)**,但缺点是会导致**有些线程获取不到锁,在队列中被饿死**

如下为ReentrantLock非公平锁的抢占原理,

<img src="https://tva1.sinaimg.cn/large/00831rSTly1gcx940mwmjj30oa0himyc.jpg" alt="50" style="zoom:50%;" />

<img src="https://tva1.sinaimg.cn/large/00831rSTly1gcx963kjwxj30oa0jfq4d.jpg" alt="50" style="zoom:50%;" />

<img src="https://tva1.sinaimg.cn/large/00831rSTly1gcxa98ip6vj30oa0j70to.jpg" style="zoom:50%;" />

<img src="https://tva1.sinaimg.cn/large/00831rSTly1gcx9dp1w12j30oa0lu764.jpg" style="zoom:50%;" />

可以看到都是以CAS为成功的基准的,当B被唤醒的一刻就可以利用CAS参与抢占过程.state=0代表无线程占用此锁.state=1代表已经有线程获取到此锁.

而公平锁的获取比上面的过程就复杂了一点,**除了和非公平锁一样需要通过cas修改state还需要看看自己是不是等待队列的第一位**,如果不是就排队去,而A在释放锁之后也去唤醒队首而不会去唤醒其他线程.

<img src="https://tva1.sinaimg.cn/large/00831rSTly1gcxakx8im8j30oa0hgt9m.jpg" style="zoom:50%;" />

<img src="https://tva1.sinaimg.cn/large/00831rSTly1gcxakx8im8j30oa0hgt9m.jpg" style="zoom:50%;" />

<img src="https://tva1.sinaimg.cn/large/00831rSTly1gcxaofne5cj30oa0jx75m.jpg" style="zoom:50%;" />

<img src="https://tva1.sinaimg.cn/large/00831rSTly1gcxauojxshj30oa0o1q41.jpg" style="zoom:50%;" />

在源码中表现为多了一个`hasQueuedPredecessors()`来判断该节点是不是队首元素,如果是队首才能进行cpu资源的获取

我们可以看到公平锁和非公平锁在用CAS修改AQS的state的最大的不同就是,非公平锁只用负责唤醒队列中的线程和所有线程一起竞争,而公平锁只有等待队列队首的线程才能够获取到资源



### 独占锁和共享锁 Sync/AQS

AQS里面有两种实现,共享锁和独占锁,**独占锁(如ReentrantLock,Synchronized)只能同时被一个线程持有,而共享锁能同时被多个线程持有并改变状态(如CountDownLatch/ReadWriteLock的读锁)**



### 可重入锁

可重入锁的理解如同ReentrantLock和synchronized,这两者都是可以被同一线程反复获取的.如果不能被重复获取的话,会造成线程死锁.



### 读写锁

读写锁是专门为了读者写者问题而设计,读者写者问题指的是一个典型的多线程问题,其读者数量是远远高于写者的,所以读者的设计就设计为

-   读线程获取到读锁后,其他线程(包括本线程)只能够获取读锁不能获取写锁
-   写线程获取到写锁后,其他线程不能获取到读锁或写锁

这个设计思想对应的是少量写线程在给某一数据结构写数据,而大多数线程在读取数据结构.

其设计核心是如何用同一队列去标识两种状态,读写锁即同一等待队列上的两把锁,他们持有相同的状态和队列,AQS的设计是利用了独占锁和共享锁两种机制去解决这个问题,而state的高16位用来存储读锁状态,低16位用来存储写锁状态.共同构成读写锁



### 分段锁

分段锁是一种锁的设计而不是某个具体的锁,ConcurrentHashMap(其节点是个链表而不是`开放定址法`实现的)即是基于分段锁思想的一个实现.我们在put的时候只用把put的元素的相应分段给锁起来即可,只要是不同的分段,那就可以并行进行操作

但是其在读取size的时候需要,需要获取到所有分段的锁才可进行统计.

分段锁的本质是一种锁的粒度的细化,对真正需要操作的内存的地址空间进行加锁而不是对ConcurrentHashMap实例进行加锁(实际上是对Segment对象进行加锁,java做不到把堆内存的一块数据拿出来单独加锁)









## 实现基本的同步问题

生产者消费者问题和读者写者问题 一个直接映射着消息队列的设置 另一个直接关系到集群的读写分离模型设计问题 故单独作为讨论

### 生产者消费者

本质上就一个东西 生产者消费者共用一把锁就不会出现问题 要么只能生产要么只能消费

解决思路就是同一把锁一起使用就是了

```java
package com.test.sync;

import java.util.*;

public class Test {
    static Object lock = new Object();
    static int[] array = new int[10];

    static Integer count = 0;
    static {
        for (int i = 0; i < array.length; i++) {
            array[i] = -1;
            // 非法值填充
        }
    }

    public static void main(String[] args) {
        new Thread(()->{
            try {
                while(true) {
                    set();
                    Thread.sleep(90);
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();

        new Thread(()->{
            try {
                while(true) {
                    get();
                    Thread.sleep(100);
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();


    }
    public static void get() throws InterruptedException {
        synchronized (lock) {
            while(count<1){
              	// 为什么这里不用if用while 是因为阻塞的时候 回来执行的时候如果是if
              	// 那么就会执行get an element操作 而while的话 回来继续判断
              	// 不符合条件在次释放锁
                lock.wait();
            }
            // get an element
            for (int i = 0; i < array.length; i++) {
                if(array[i]!=-1) {
//                    System.out.println(array[i]);
                    array[i] = -1;
                    count--;
                    break;
                }
            }
            printArray(array);
            lock.notifyAll();
        }
    }
    public static void set() throws InterruptedException {
        synchronized (lock) {
            while(count>10){
                count.wait();
            }
            // set an element
            for (int i = 0; i < array.length; i++) {
                if(array[i]==-1) {
                    array[i] = rand();
                    count++;
                    break;
                }
            }
            printArray(array);
            lock.notifyAll();
        }
    }

    public static int rand() {
        return new Random().nextInt();
    }

    public static <T>void printArray(int[] array){
        System.out.print("[");
        for (int i = 0; i < array.length;i++){
            System.out.print(array[i]+",");
        }
        System.out.println("] count:"+count);
    }
}
```

### 读者写者

1.  允许多个读者同时执行读操作。 // 读者之前没有读者锁进行制约
2.  不允许读者、写者同时操作。 // 读写之间有公用锁进行制约
3.  不允许多个写者同时操作。 // 写者锁进行制约

这个设计思路就是两者之间用一把公共锁进行制约 然后读者有自己独立的锁就行

```java
package com.test.sync;

import java.util.Random;

public class testReaderWriter {
    final static Object readerLock = new Object();
    volatile static Integer writerCount = 0;
    final static Object writerLock = new Object();

    static Integer resource = -1;

    public static void main(String[] args) throws InterruptedException {
        for (int i = 0; i < 100; i++) {
            new Thread(() -> {
                try {
                    read();
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }).start();
            new Thread(() -> {
                try {
                    write();
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }).start();
        }
        Thread.sleep(0x2b67);

    }

    /**
     * 读者写者模式规则
     * 1.  允许多个读者同时执行读操作。 // 读者之前没有读者锁进行制约
     * 2.  不允许读者、写者同时操作。 // 读写之间有公用锁进行制约
     * 3.  不允许多个写者同时操作。 // 写者锁进行制约
     **/
    public static void read() throws InterruptedException {
        synchronized (readerLock) {
            while (writerCount > 0) {
                readerLock.wait();
            }
            System.out.println(Thread.currentThread().getName() + "read resource:" + resource);
        }
    }

    public static void write() throws InterruptedException {
        synchronized (readerLock) {
            // 读写同时只能有一个进入所以 写者也要获取读者的锁
            // 有写者在等待
            synchronized (writerLock) {
                // 写者之间进行互相制约
                while (writerCount > 0) {
                    writerLock.wait();
                }
                writerCount++;
                int i=rand();
                System.out.println(Thread.currentThread().getName() + "write resource:" + i);
                resource = i;
                writerCount--;
                writerLock.notifyAll();
            }
            readerLock.notifyAll();
        }
    }

    public static int rand() {
        return new Random().nextInt();
    }
}

```

### 消息队列

-   未完待续





## tomcat与多线程

tomcat的问题就是系统级别的多线程I/O问题,tomcat支持四种线程模型.

|      | 描述                                                         |
| ---- | ------------------------------------------------------------ |
| BIO  | 阻塞式IO，采用传统的java IO进行操作，该模式下每个请求都会创建一个线程，适用于并发量小的场景 |
| NIO  | 同步非阻塞，比传统BIO能更好的支持大并发，tomcat 8.0 后默认采用该模式 |
| APR  | tomcat 以JNI形式调用http服务器的核心动态链接库来处理文件读取或网络传输操作，需要编译安装APR库 |
| AIO  | 异步非阻塞，tomcat8.0后支持                                  |

### BIO模型

![](https://img-blog.csdn.net/20180419180425327?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZkMjAyNQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

我们看下其各个组件

-   mapper 实现http地址到servlet的映射
-   CoyoteAdapter container和connector的匹配
-   Http11Protocal http请求阻塞处理器
-   **JIoEndpoint** 其核心执行结构

其JIoEndpoint的处理逻辑如下,由多个Acceptor线程交付给exec线程去执行最终的servlet代码

![](https://img-blog.csdn.net/20180419180649104?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZkMjAyNQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

![](https://img-blog.csdn.net/20180419180940166?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZkMjAyNQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

-   LimitLatch 流量阀门,控制流量通断 基于AQS实现
-   ServerSocketFactory Socket和SSLSocket的生产工厂
-   SocketProcessor 把socket的内容封装成HttpRequest交付给servlet
-   Executor 执行任务的线程池

从上面的结构中Acceptor和Executor属于不同的线程,这里就能利用多线程去优化性能.BIO的模型相对原始,且性能受限,我们一般会采用NIO对其进行优化

### NIO模型

![](https://upload-images.jianshu.io/upload_images/4098122-edc5aadd31b333d7.png)

我们知道java的nio模型是不支持多线程使用selector的,tomcat是使用java的单线程nio实现的,所以tomcat的nio采用了折中的设计方式(实际上使用epoll实现的nio完全的多线程)**,仅用java的多线程nio+selector完成了读,而写会socket交给了传统的阻塞I/O去实现!**,这样做的好处是可以利用I/O多路复用的特性加快读的速度,至于socket写回依然要阻塞等待.

所以从上图可以看出其实现的核心并未发生过多改变,仅仅把原先一部分阻塞Accept的任务交给了Poller去实现,LimiitLatch和SocketProcessor依然参考之前的设计思路.

-   poller 负责轮序事件列表,由单独的线程池维护

其轮序大概类似于下图

![](https://img-blog.csdn.net/20180419181831924?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZkMjAyNQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### APR

 `APR（Apache Portable Runtime），即Apache 可移植运行库。`

利用JNI(java native interface)用c++去编写性能瓶颈的操作从而提高系统性能上限,和NIO来看,其使用了C++层面实现的io多路复用epoll去实现,而不是像java中的nio只支持单线程.java的io轮序是要进行线程中断的也就是poll的基本思路,而使用epoll以及完全采用操作系统的api去实现的socket的性能极高,但前提是得安装了ARP库才能够使用本种tomcat

### AIO模型

AIO模型和NIO的最主要区别是调度网卡的过程,即AIO不需要从用户空间拷贝数据到内核空间或者反过来,其是由操作系统内核空间通知应用程序去拷贝数据的.这个AIO就是APR的在升级,其实也是叫APR的,知识APR可以用来实现高性能的NIO也可以用来实现更高性能的AIO.但目前java有AIO操作的api.目前而言并不去使用此.



## springboot与多线程

这里我们分为两个点去讲明这个问题,一是spring/springboot本身的对象的线程模型,二是tomcat的线程模型.由上面的tomcat的线程及I/O我们可以知道不同的处理Socket存在不同的线程池里面,我们写的springboot代码相当于servlet/socketprocesser.所以运行不同的请求处理用的线程未必是一样的.在相同的方法中进行了测试得到了如下结果,可以断定其执行逻辑.

```shell
indexhttp-nio-8000-exec-1
indexhttp-nio-8000-exec-3
indexhttp-nio-8000-exec-4
```

通过对tomcat的理解我们可以知道,springboot的本质就是写servlet/socketProcessor,那么一个@Contoller对象就是被tomcat放到jvm堆内存中的.此时,因为tomcat启动时装载了spring(web.xml),所以spring的aop在此时动态代理的类的某些方法对其进行了增强,使得tomcat可以调用这些方法去处理相应的事件.tomcat在处理的时候找到了对应的路径,就把方法的执行封装成Runnable扔到线程池里.线程池再去执行我们的方法,封装成socket响应发送给服务端.所以我们看到了springboot的多线程模式,

如果我们在springboot中开启多线程要注意垃圾回收等问题,且springboot**每个@Controller是单例**的(通过普通代码块可以验证),该类是随着tomcat的启动而启动的.如果内部在开启线程的话一定要通过线程池不要手动开启.开启线程一般是为了去执行一些异步任务,普通情况下,所有的线程相关的处理请求的任务,连接数据库的任务等都交付给不同的线程池去完成处理.

另外一提@Autowired的本质是去spring维护的对象库里面找对象,至于是单例还是多例一般单例可以是多例,但@Service就是单例的毋庸置疑.

springboot通常需要进行一些转发请求的任务,比如存储图片,记录日志,发送短信和邮件,或是利用spring的特性web的特性等,开启多线程能极高的提高系统的性能

在这里同一回顾下多线程的开启顺序及性能提高情况

-   显式或是隐式的创建Runnabble的代码片段实例,在线程对象调用.start()方法时会加入JVM的就绪队列等待调度.
-   一般来讲,我们线程切换还需要额外开销,从并发的角度看就是牺牲时空效率换取并发功能,但对于有DMA的架构来说,我们使一些(空转或I/O)线程进入阻塞,等待其条件完成.这样处理器的资源就会被使用到其他县城上而无需等待I/O.

综合上述观点,我们在web中开启子线程的时候通常都是开启一些耗时的I/O任务,这些任务不需要过多的处理器资源,而需要DMA,以及系统的等待等.从这个角度看待中断和开启子线程,即是把耗时的任务交付给CPU,CPU可选择性交付给DMA,从而不让线程一直占用处理机资源从而提高了吞吐量.

---

在springboot中开启多线程的几种方式

- @Async
- 手动开启(不推荐)
- 定时任务

详细的代码部分在springboot的文档中有详细的介绍.



## 线程安全以及线程相关问题

---

本节涉及到javaweb/spring等一众框架和java多线程的基本使用的相关问题等.



###  **Servlet对象是单实例多线程，Servlet不是线程安全的**

在非分布式的系统中,Servlet是单例多线程的,而且很显然没有锁去制约之中请求关系,单例意味着servlet容器只会生成一个servlet实例,只是对于每一个请求都调用service()方法去交给一个线程处理

如何解决Servlet的线程安全问题,synchronized代码块,线程安全的数据结构HashTable,BlockQueue等



### Spring的bean是否是线程安全的

spring没有对bean进行多线程处理,但大多数情况下是无状态的(没有数据存储功能)那就不用去考虑线程安全的问题 如果是有状态 则需要去考虑Spring的线程安全问题

spring是默认单例模式 改成prototype则可以保证一定程度上的线程安全

再不成可以用ThreadLocal去保证线程安全问题





