# mysql优化

---

优化的方向有两个sql结构优化,索引,存储过程(因数据库迁移问题等已经弃用)



## JDBC的读取细节

---

我们先从JDBC的优化开始说起,要清楚JDBC的读取细节,先看下面代码

### PrepareStatement和Statement

```java
Connection conn=null;
PrepareStatement ps=null;

Class.forName(driver);
conn = DriverManager.getConnection(url, user, password);

String sql="insert into users_info values(?,?,?)";
ps=conn.prepareStatement(sql); // 预编译sql,防止sql注入

ps.setInt(1,id);
ps.setString(2,username);
ps.setDate(3, new java.sql.Date(java.util.Date().getTime()));

Boolean res = ps.executeUpdate() > 0;
// 注意Statement是能获取结果集的
// 如果想要获取结果集且用的是查询语句可以使用下面的代码
// ResultSet rs = ps.executeQuery(); 
// 这里不需要再写语句通过statement预编译传入sql,如果是普通的statement对象每次都要写
```

PrepareStatement承自Statement接口.处理任务时候效率更高,因为采用预编译的手段处理sql,PrepareStatement也叫**JDBC存储过程**,Statment用于一次性存取.PrepareStatement对象开销比Statement大,

我们平时用的比较多的是PrepareStatement,因为其除了执行固定化sql的功能之外,还能够防止sql注入,预编译能判断参数是否合法.

另外需要注意在JDBC存储过程中,应当尽量使用`executeUpdate`和`executeQuery`来完成系统的判别,execute有其他语义.



### 自动提交问题与setAutoCommit

在提及之前我们先看下下面两个性质

-   **默认情况下setAutoCommit的值为1(true)**
-   **MyISAM不支持事务,该属性针对InnoDB**
-   MyISAM只要执行sql就是锁全表

顾名思义我们能从api中看到其设置让session自动提交,下面介绍的都是基于InnoDB的锁.因为只有InnoDB有基于事务的特征



#### setAutoCommit(true) 不开启事务

其语义为**不使用事务**,每一句写sql使用表的时候都要加锁.默认情况,自动提交,每次执行sql的时候都会让数据库执行操作.所以也可以理解为**每一句sql都执行事务**.

自然我们知道不使用事务的mysql针对于每一句执行的sql而言是线程安全的,但是对于整体的sql块不是线程安全的.对于每一句sql,根据sql内容的不同InnoDB可能会采用表锁或者行级锁(需要索引).

不使用事务对于语句块来讲可能会发生**脏读幻读不可重复读**.下面有更为详细的介绍这三种形式,避免方式自然是开启事务,另外就算在MyISAM引擎中开启事务也没有作用,因为MyISAM不支持事务.

另外根据mysql的特性,**不使用for update InnoDB只会对写操作加锁**



#### setAutoCommit(false) 开启事务

单单用这一句无法完成事务,但其语义表明是**开启事务**即**关闭自动提交/手动提交**.

其逻辑如下

```java
try{
  conn.setAutoCommit(false);
  
  stmt = conn.createStatement(); 
  stmt.execute(sql1);
  stmt.execute(sql2);
  
  // 提交事务
  conn.commit();
}catch(SQLException sqle){
  conn.rollback();
}finally{
  // close
}
```

可以看到其使用了`.commit()`此种api,我们即可知道,其把每一句执行的sql都当成事务的不同不同,整体一次性提交保证了这些操作执行的数据一致性,根据mysql的事务级别,这里一般是不可重复读,并且使用了`.rollback()`进行回滚.一方面是要保证**数据的一致性**,另一方面回滚是**解除锁**.

一般来讲关掉conn即可释放锁,但是在采用数据库连接池的环境下,就可能会造成大规模的死锁,故一定要记得回滚.



### mysql实现的锁

所谓的锁,同步信息本质上一些数据.依照CAS抢占字段的逻辑,所谓的字段就是同步信息.mysql实现锁的思路就是利用mysql这个数据系统本身的数据一致性.我们只需要利用JDBC对数据库操作,就可以实现锁了.

我们借助InnoDB的执行引擎对数据行进行加锁,MyISAM不支持事务且不能单独对行进行加锁粒度大.我们借助JDBC事务实现锁.

我们看下加锁和解锁的逻辑

```sql
INSERT INTO database_lock(resource, description) VALUES (1, 'lock')
```

```sql
DELETE FROM database_lock WHERE resource=1
```

这两个逻辑加锁不能重复加,因为插入不止一次的话会报错,这里可以不用选择主键,主键只是一个展示可以加锁的逻辑字段.

我们利用JDBC把其变成应用程序,首先我们开启事务把操作变成原子性.

```java
static class MysqlLock {
  public static String url = "jdbc:mysql://127.0.0.1:3306/test?characterEncoding=UTF-8";
  public static String user = "root";
  public static String pass = "root";
  public static Connection conn = null;

  static {
    try {
      Class.forName("com.mysql.jdbc.Driver");
      conn = DriverManager.getConnection(url, user, pass);
    } catch (SQLException | ClassNotFoundException throwables) {
      throwables.printStackTrace();
    }
  }

  private final String method;

  MysqlLock(String method) {
    this.method = method;
  }

  MysqlLock() {
    this.method = "testLock";
  }

  public boolean tryLock() throws SQLException {
    PreparedStatement st = conn.prepareStatement("select * from `lock` where method_name = ? for update");
    st.setString(1, method);
    ResultSet rs = st.executeQuery();
    return !rs.next();

  }

  public void lock() {
    try {
      conn.setAutoCommit(false);
      while (true) {
        try {
          PreparedStatement statement = conn.prepareStatement("insert into `lock` (method_name,description) values (?,?)");
          statement.setString(1, method);
          statement.setString(2, "a lock for test");
          if (!tryLock()) {
            // 尝试获取锁失败(数据库有记录)就一直等待获取
            Thread.sleep(100);
            continue;
          }
          statement.executeUpdate(); // 写上锁记录
          conn.commit();
          break;
        } catch (SQLException | InterruptedException e) {
        }
      }
    } catch (SQLException e) {
      System.out.println("系统出错");
      e.printStackTrace();
    }
  }

  public void unlock() {
    // 逆向操作删除记录
    try {
      conn.setAutoCommit(false);
      PreparedStatement statement = conn.prepareStatement("delete from `lock` where method_name = ?");
      statement.setString(1, method);
      if (statement.executeUpdate() == 1) {

      } else { // equals 0
        throw new RuntimeException("没上锁不能解锁");
      }
      conn.commit();
    } catch (SQLException e) {
      e.printStackTrace();
    }
  }
}

public static final ExecutorService pool = Executors.newFixedThreadPool(4);
static int i = 0;
static final MysqlLock lock = new MysqlLock("test");
static final int n = 10000;
static final CountDownLatch latch = new CountDownLatch(n);

@Test
public void test() throws InterruptedException {
  for (int j = 0; j < n; j++) {
    pool.submit(() -> {
      lock.lock();
      try {
        //                    System.out.println(Thread.currentThread().getName() + "获取了锁");
        i++;
      } finally {
        //                    System.out.println(Thread.currentThread().getName() + "释放了锁");
        lock.unlock();
      }
      latch.countDown();
    });
  }
  latch.await();
  System.out.println(i);
}
```

上面的锁可以实现,但是由于其存储位置,效率比较低,加上存储于数据库我们更倾向于用zookeeper或者redis实现更高效更好用的分布式锁,但道理想通,下面介绍另一种设计方式,乐观锁设计.

```sql
CREATE TABLE `optimistic_lock` (
	`id` BIGINT NOT NULL AUTO_INCREMENT,
	`resource` int NOT NULL COMMENT '锁定的资源',
	`version` int NOT NULL COMMENT '版本信息',
	`created_at` datetime COMMENT '创建时间',
	`updated_at` datetime COMMENT '更新时间',
	`deleted_at` datetime COMMENT '删除时间', 
	PRIMARY KEY (`id`),
	UNIQUE KEY `uiq_idx_resource` (`resource`) 
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='数据库分布式锁表';
```

加锁和解锁的逻辑

```sql
INSERT INTO optimistic_lock(resource, version, created_at, updated_at) VALUES(20, 1, CURTIME(), CURTIME());
```

-   STEP1 - 获取资源:

    ```sql
    SELECT resource, version FROM optimistic_lock WHERE id = 1
    ```

-   STEP2 - 执行业务逻辑

-   STEP3 - 更新资源:

    ```sql
    UPDATE optimistic_lock SET 
    resource = resource -1, 
    version = version + 1 
    WHERE id = 1 AND version = oldVersion
    ```

我们看到这个逻辑和CAS加锁逻辑一致,只有一个线程能修改成功,修改不成功的没有任何反应,或者说在java端要判断,我们利用该锁,把mysql当成缓冲池,做一个生产者消费者模型

```java
static class MysqlLock {
  public static String url = "jdbc:mysql://127.0.0.1:3306/test?characterEncoding=UTF-8";
  public static String user = "root";
  public static String pass = "root";
  public static Connection conn = null;

  static {
    try {
      Class.forName("com.mysql.jdbc.Driver");
      conn = DriverManager.getConnection(url, user, pass);
    } catch (SQLException | ClassNotFoundException throwables) {
      throwables.printStackTrace();
    }
  }

  private final Integer id;

  MysqlLock(Integer resourse) {
    this.id = resourse;
  }

  MysqlLock() {
    this.id = 1;
  }

  /**
         * 这里表的结构,id全局标识了唯一的锁
         * version表示该字段的更改版本,也是CAS修改依据之一
         */
  static final String sql1 = "SELECT resource, version FROM optimistic_lock WHERE id = ?";
  static final String sql2 = "" +
    "UPDATE optimistic_lock " +
    "SET resource = resource - 1,version = version + 1 " +
    "WHERE id = ? AND version = ?";

  public boolean tryLock() throws SQLException {
    PreparedStatement statement = conn.prepareStatement(sql1);
    statement.setInt(1, id);
    ResultSet rs = statement.executeQuery();
    rs.next();
    int oldVersion = rs.getInt("version");
    int resource = rs.getInt("resource");
    PreparedStatement st = conn.prepareStatement(sql2);
    st.setInt(1, id);
    st.setInt(2, oldVersion);
    if (resource > 0) {
      // compute (in this case reduce resource) resource-=1
      return st.executeUpdate() > 0;
    } else {
      return false;
    }
  }

  private void safeSleep(long time) {
    try {
      Thread.sleep(time);
    } catch (InterruptedException ex) {
      ex.printStackTrace();
    }
  }

  public void consumer() {
    for (; ; ) {
      try {
        if (tryLock()) { // cas
          // 执行想要的操作
          break;
        } else {
          // 其他锁修改了资源,重新尝试
          safeSleep(10);
        }
      } catch (SQLException e) {
        // 上锁失败,有概率资源不够,wait
        safeSleep(100);
      }
    }
  }

  static final String sql3 = "" +
    "UPDATE optimistic_lock " +
    "SET resource = resource + 1,version = version + 1 " +
    "WHERE id = ? AND version = ?";

  public boolean tryUnlock() throws SQLException {
    PreparedStatement statement = conn.prepareStatement(sql1);
    statement.setInt(1, id);
    ResultSet rs = statement.executeQuery();
    rs.next();
    int oldVersion = rs.getInt("version");
    int resource = rs.getInt("resource");
    PreparedStatement st = conn.prepareStatement(sql3);
    st.setInt(1, id);
    st.setInt(2, oldVersion);
    // compute (resource++)
    return st.executeUpdate() > 0;
  }

  public void produce() {
    for (; ; ) {
      try {
        if (tryUnlock()) { // cas
          // 执行想要的操作
          break;
        } else {
          // 其他锁修改了资源,重新尝试
          safeSleep(10);
        }
      } catch (SQLException e) {
        // 上锁失败,有概率资源不够,wait
        safeSleep(100);
      }
    }
  }


}

public static final ExecutorService pool1 = Executors.newFixedThreadPool(4);
public static final ExecutorService pool2 = Executors.newFixedThreadPool(4);
static final int n = 1000;
static final CountDownLatch latch = new CountDownLatch(n);
public static final MysqlLock lock = new MysqlLock();

@Test
public void test() throws InterruptedException {
  for (int j = 0; j < 100; j++) {
    pool1.submit(() -> {
      System.out.println(Thread.currentThread().getName()+"消费");
      lock.consumer();
    });
  }
  for (int j = 0; j < 200; j++) {
    pool2.submit(() -> {
      System.out.println(Thread.currentThread().getName()+"生产");
      lock.produce();
    });
  }
  Thread.sleep(1000);
}
```





## 索引

---

索引本质上就是一种数据结构 用来存储某一个key的数据结构

常用的索引结构BST AVLTree 红黑树 B树等 为的是让查找次数更少

索引是根据表来的而不是根据数据库 引擎也是根据表来的 引擎决定了表的结构

建立索引意味着可以通过数据结构去找到相应的节点



## 索引覆盖(Using index)

---

覆盖索引指的是索引切实被用上了的意思,指的是查询数据的时候不用扫描行 扫描索引

看下论坛的解释如下

解释一： 就是select的数据列只用从索引中就能够取得，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖。

解释二： 索引是高效找到行的一个方法，当能通过检索索引就可以读取想要的数据，那就不需要再到数据表中读取行了。如果一个索引包含了（或覆盖了）满足查询语句中字段与条件的数据就叫做覆盖索引。

解释三：是非聚集组合索引的一种形式，它包括在查询里的Select、Join和Where子句用到的所有列（即建立索引的字段正好是覆盖查询语句[select子句]与查询条件[Where子句]中所涉及的字段，也即，索引包含了查询正在查找的所有数据.



## InnoDB MyISAM B+树

---

B+树数据结构特点:高度低 索引次数小 相比于B树其节点数据全在叶子节点上 使得中间索引能够放得下更多 mysql默认是分配16k 树的高度在不超过3的前提下 就能轻松索引千万级数据了

InnoDB: 其文件为聚集索引,及叶子节点的索引存储的是数据本身而非数据的地址

MyISAM: 其文件为非聚集索引,叶子节点存储的是数据的地址

B+树支持叶子节点的前驱后继指针非常良好的支持范围查找(where id>20) 减少磁盘I/O 

---

## 优化实践(建立索引)

多个单列索引:多个单列字段加上索引 mysql在分析的时候只取最有用的一个 而这种时候 根据where字句的情况完全可以用来判别 是应该采用联合索引还是单个索引

联合索引:多个字段有先后顺序的索引 但本质相当于一个索引 其本质内容就是 按照key1排序然后在按照key2排序然后在按照key3以此类推

## 索引类型

-   普通索引

    NORMAL

-   唯一索引(字段的值必须唯一)

    UNIQUE

-   全文索引(这个和我们认知差不多 mysql会预分词(国外)等索引的时候就按照词去索引就快了)

    FULLTEXT 只能标注在 char varchar上

-   空间索引(支持一些比较新的openGIS类型的空间数据的索引)

    SPATIAL

---

mysql 在建立表的时候已经为主键和外键建立了索引 剩下的查询字段我们自己手动建立索引

查看表的索引

show index from tablename;

创建索引 删除索引

```sql
# 创建普通索引
ALTER table tableName ADD INDEX indexName(columnName) USING BTREE;
# 创建联合索引
ALTER TABLE `test`.`user` ADD INDEX `combine_index`(`id`, `user_name`(3)) USING BTREE;
ALTER TABLE `test`.`user` 
DROP INDEX `combine_index`;
```

创建之后我们可以看到表的结构信息变了

```sql
| user  | CREATE TABLE `user` (
  `id` bigint(20) NOT NULL,
  `pass_word` varchar(255) NOT NULL,
  `user_name` varchar(255) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `name_index` (`user_name`(10)) USING BTREE, # 索引
  KEY `pass_index` (`pass_word`(3)) USING BTREE  # 索引
  KEY `combine_index` (`id`,`user_name`(3)) USING BTREE # 联合索引
) ENGINE=InnoDB DEFAULT CHARSET=utf8 |
```

查看运行分析

```java
EXPLAIN select * from users
```



## mysql的并发控制

---

### 事务实现原理

#### 事务

事务是一种控制读写的并发机制,事务的特性就是ACID

-   原子性Atomicity,即不可分割,发生错误会回滚
-   一致性Consistency,即所有读写的数据能够保持一致
-   隔离性Isolation,即事务之间隔离不互相依赖
-   持久性Durability,顾名思义一次性变化序列化到磁盘上

使用事务系统,就有可能会遇到三种现象

-   脏读,指其他事务在修改数据,本事务读到了其他事务的数据
-   幻读,即读到不存在的数据,其他事务增加或是删除数据,本事务读到了这些数据
-   不可重复读,本事务在事务途中进行两次相同的读取,却读到了不同的数据

四种事务隔离级别

-   READ_UNCOMMIT 读不提交,即不做任何操作,可能会
-   READ_COMMIT 读操作要在提交了之后才能执行,避免脏读
-   REPETABLE_READ 可重复读,可以避免脏读,幻读
-   SERIALIZABLE 序列化,可以避免脏读幻读不可重复读

#### JDBC事务

```java
try{
  conn.setAutoCommit(false);
  stmt = conn.createStatement(); 
  // 将 A 账户中的金额减少 500 
  stmt.execute("update t_account set amount = amount - 500 where account_id = 'A'");
  // 将 B 账户中的金额增加 500 
  stmt.execute("update t_account set amount = amount + 500 where account_id = 'B'");
  // 提交事务
  conn.commit();
}catch(SQLException sqle){
  conn.rollback();
  // close
}
```

可以看到JDBC事务是以Connection为基础进行回滚的.JDBC的特点是不能跨数据库进行,多数据或者分布式的话.JDBC事务就没啥用处了.



#### 日志

redo-log重做日志 / undo-log 回滚日志

redo-log分为两部分,在内存中的redo-log-buffer和磁盘中的redo-log,事务的提交之后所有修改信息会保存在日志中.例如有表

![](https://user-gold-cdn.xitu.io/2019/4/18/16a2ff3e4c3b8b46?w=2368&h=788&f=png&s=226339)

```sql
start transaction;
select balance from bank where name="zhangsan";
// 生成 重做日志 balance=600
update bank set balance = balance - 400; 
// 生成 重做日志 amount=400
update finance set amount = amount + 400;
commit;
```

其执行方式如下

![](https://user-gold-cdn.xitu.io/2019/4/18/16a2fdae04c7dc6f?w=4016&h=1892&f=png&s=1010471)

redo-log的作用是用来恢复数据的,在宕机的时候我们丢掉的只是红色部分的信息.这一日志用来保证系统的持久性.

---

undo-log 又叫回滚日志,顾名思义是用来回滚记录的.和redo-log记录数据不同,undo-log是用来记录对数据的操作的操作.

![](https://user-gold-cdn.xitu.io/2019/4/18/16a2fe552145e2c1?w=4652&h=1848&f=png&s=867671)

undo-log用来保证事务的原子性.



#### MVCC

MVCC(MultiVersion Concurrency Control)多版本并发控制.

>   InnoDB的 MVCC ,是通过在每行记录的后面保存两个隐藏的列来实现的.这两个列,一个保存了行的创建时间,一个保存了行的过期时间,存储的并不是实际的时间值,而是系统版本号.

#### 事务的实现

-   事务的原子性是通过 undo log 来实现的
-   事务的持久性性是通过 redo log 来实现的
-   事务的隔离性是通过(读写锁+MVCC)来实现的
-   事务的一致性是通过上面三个特性实现的

原子性由undo-log实现,显然是通过回滚操作去实现,每条写操作都要写入undo-log,我们可以通过相应操作的逆向操作rollback,那么对应的insert语句就是delete,delete是insert,update是update,即可以逆向操作.

持久性的实现是通过redo-log,一旦事务提交,所有的修改都会被持久化到数据库上,此时系统即使崩溃也不会丢失数据.显然我们看到了redo-buffer的作用,在持久化区域起到缓冲,所有的读写都会经过这个缓冲区.这种缓冲区虽然极大地提高了速度,但本身没有持久化的功能即redo-log解决了这一问题,记录操作和记录操作的数据显然操作需要的I/O更小,也能被接受.

隔离性的实现,我们平常看到的四种隔离级别

-   READ_UNCOMMIT
-   READ_COMMIT
-   REPEATABLE_READ
-   SERILIAZABLE

隔离性的重点就在于并发控制,我们可以看到其是用读写锁和MVCC实现的充满了Concurrent的味道.

READ_UNCOMMIT

![](https://user-gold-cdn.xitu.io/2019/4/18/16a2ed4dbd348a68?w=4284&h=1288&f=png&s=731191)

读未提交仅有写会加上锁,读不加锁所以就能够看到写到一半的数据就发生了脏读.

READ_COMMIT

![](https://user-gold-cdn.xitu.io/2019/4/18/16a2f05d63f388d0?w=3612&h=1512&f=png&s=816439)

InnoDB采用了此种机制,写的时候加上锁,读的时候通过MVCC来确定字段的修改,这种操作从读上来讲就相当于读没有修改的副本自然不会出现中间的状态,不会出现幻读,但是仍有可能出现不可重复读的现象(有点类似Copy-On-Write的设计思路).可以看到其读的不是并不是同一个副本.

REPEATABLE_READ (Mysql默认)

![](https://user-gold-cdn.xitu.io/2019/4/18/16a2c351eb03fc24?w=1082&h=290&f=png&s=120400)

这种默认的级别用两种方式可以实现,读写锁和MVCC,上面就是采用读写锁,即读共享锁,只要没有释放锁就可以读一样的数据,这样一来并发性能下降严重.一般是使用下面的方法实现,InnoDB就是利用下面方法实现的.

![](https://user-gold-cdn.xitu.io/2019/4/18/16a2f054474b394b?w=3584&h=1512&f=png&s=756027)

如上面和COW类似的机制,读取修改前的副本即可保证读不重复,即通过读副本的方式.其可以用空间换并发效率.该版本的实现依然会存在幻读问题.但能从另外的方式解决.

SERILIZABLE

![](https://user-gold-cdn.xitu.io/2019/4/18/16a2f56d34ff739e?w=3528&h=1060&f=png&s=414467)

即全部串行来读.全部采用独占锁.



### 锁定方式

-   表级锁定table-level

    表级别的锁定是mysql中粒度最大的锁定,使用表级MyISAM,csv,memory等引擎

-   行级锁定row-level

    行级锁定在并发处理上有最小的粒度,行级锁最容易发生死锁,在InnoDB上使用

-   页级锁定page-level

    这个级别是Mysql中特有的级别,其介于行级锁和表级锁之间,主要用于BerkeleyDB

他们的适用范围

表级锁适合于带有少量条件的查询,行级锁更适合有大量索引条件,且并发更新不同的数据,如在线处理事务系统.

### sql加锁

**在MyISAM中**,表级锁有两种共享读锁和独占写锁.其互斥形式和ReentrantReadWriteLock一致即读中不能写,写中不能读写.这个锁是**表级的锁**,MyISAM使用的是隐式加锁,即自动加锁,在select前面加读锁,在update,delete,insert之间加的是写锁.我们需要让MyISAM加锁的时间尽可能的小,其锁定级别不可轻易改变.我们也能看出来**MyISAM是写优先的**

mysql里面有专门两组变量计算锁的争用情况,分别表示锁定的次数和等待的次数.

```shell
mysql> show status like 'table%';
+----------------------------+---------+
| Variable_name              | Value   |
+----------------------------+---------+
| Table_locks_immediate      | 100     |
| Table_locks_waited         | 11      |
+----------------------------+---------+
```

而在其他引擎中,例如**NDBCluster(分布式)和InnoDB**中他们自己实现了行级锁,下面主要介绍InnoDB的控制方式.InnoDB是目前广泛使用的事务存储引擎.InnoDB的行级锁也分为共享锁和排他锁.中还要涉及到一个概念叫意向锁如下.

![](https://images2015.cnblogs.com/blog/1033231/201701/1033231-20170118181153984-1417117507.png)

如果是兼容的,那么InnoDB会给请求的事务授予锁,否则,则会等待前一把锁释放.加锁逻辑是

-   如果该资源没被加锁,可以加共享锁和排它锁
-   如果该资源被加共享锁,可以加共享锁但不能加排它锁
-   如果该资源被加了排他锁,就不能加共享锁,也不能加排它锁,但可以加意向锁

仅当被加资源排它锁之后,才会加意向锁,根据后续进程想要加的锁,分为共享意向锁,排他意向锁.意向共享锁可以存在多个,意向排他锁只能存在一个.意向锁是InnoDB自己加的,不需要用户干预.

-   **对于Select,InnoDB不会加共享锁**,在事务中利用MVCC(类似COW)机制控制并发
-   对于Update,Delete,Insert等,InnoDB会给加排它锁

我们可以利用下面的sql语句实现加锁

```sql
SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE # 加共享锁
SELECT * FROM table_name WHERE ... FOR UPDATE # 加排它锁
```

select加排他锁的语义是为了确保没有其他线程对其修改,InnoDB是通过给索引项加锁来实现行级锁的,只有索引索引条件才能使用行级锁,否则就相当于使用表锁.如果是**相同的索引键**就可能会发生冲突.且用EXPLAIN我们可以知道在一些小的表里面,mysql是会使用全表扫描的,必须通过索引才会触发行级锁,否则使用的都是表锁.

除此之外mysql还有一种间隙锁(Next Key).例如

```shell
mysql> select * from emp where empid > 100 for update;
```

mysql会对大于100的所有记录加锁,即如果只有101条记录,也会对不存在的其他记录加锁.这个锁的目的

-   防止幻读,如果其他事务插入了>100以上的数据,那么就会读到本不存在的数据,破坏事务的原子性,在下面我们会详细介绍事务

除此之外需要注意的是间隙锁可能会对性能造成很大的影响,当Query无法利用索引时就会使用全表锁,Query的过滤条件会导致某些数据无法正确插入

### 死锁

MyISAM是不会发生死锁的,因为他每次就用那一把锁,用完就释放,不存在其他行为,缺点就是性能低下.即deadlock free,显然InnoDB中获取到了对面事务资源需要的锁就会造成死锁.InnoDB自身可以检测到自己的死锁,并且回滚掉带较小的事务

>   但是有一点需要注意的就是，当产生死锁的场景中涉及到不止InnoDB存储引擎的时候，InnoDB是没办法检测到该死锁的，这时候就只能通过锁定超时限制参数InnoDB_lock_wait_timeout来解决。
>   需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。

这也告诉了我们在JUC包中获得锁设置等待事件的意义,如果没获取到锁尽早进入异常处理,提示系统繁忙是比直接傻等着获取锁要好很多,哪怕JDK1.8对synchronized做出了相应的优化,其在系统的可靠性上远远不及JUC工具中自己实现的可中断的等待队列.

我们可以使用如下方法来避免死锁

>-   在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。
>-   在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能。
>-   在事务中，如果要更新记录，应该**直接申请足够级别的锁**，即排他锁，而不应先申请共享锁，更新时再申请排他锁，因为当用户申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。
>-   在REPEATABLE-READ隔离级别下，如果两个线程同时对相同条件记录用SELECT...FOR UPDATE加排他锁，在没有符合该条件记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁。这种情况下，将隔离级别改成READ COMMITTED，就可避免问题。
>-   当隔离级别为READ COMMITTED时，如果两个线程都先执行SELECT...FOR UPDATE，判断是否存在符合条件的记录，如果没有，就插入记录。此时，只有一个线程能插入成功，另一个线程会出现锁等待，当第1个线程提交后，第2个线程会因主键重出错，但虽然这个线程出错了，却会获得一个排他锁。这时如果有第3个线程又来申请排他锁，也会出现死锁。对于这种情况，可以直接做插入操作，然后再捕获主键重异常，或者在遇到主键重错误时，总是执行ROLLBACK释放获得的排他锁。



### 乐观锁

这是一种加锁的方式,即CAS-loop的lock-free,可以参考AtomicInteger的设计思想.

mysql使用数据库版本号来控制

![mysql版本控制](https://upload-images.jianshu.io/upload_images/4461377-d7472568e615e335.png)

```sql
# 订单系统的基本cas加锁逻辑,但
select (quantity,version) from items where id=100; # 存version
insert into orders(id,item_id) values(null,100);
update items set quantity=quantity-1,version=version+1 where id=100 and version=#{version}; # 典型的CAS,失败就回滚
```

如果是主从分离的数据库select一般是用于访问从数据库的 但是如果把select放在了事务中 访问的是主数据库 另外 如果并发操作很高的时候 从数据库同步可能不及时也会导致查询失败

秒杀系统的核心代码(细粒度的乐观锁)

```sql
# step1: 查询出商品信息
select (inventory) from items where id=100;
# step2: 根据商品信息生成订单
insert into orders(id,item_id) values(null,100);
# step3: 修改商品的库存
update items set inventory=inventory-1 where id=100 and inventory-1>0;
# 如果库存数量不够就会失败,失败进行回滚的时候就可以通知用户下单失败
```

这种如果对行操作version字段保持着相当高的冲突,如果竞争强烈的话建议直接换成悲观锁.

我们可以采用更加细粒度的直接对字段加锁 一般数据库有类似quantity这样的高并发的字段的时候 我们可以命名quantity_cc 单独控制一个字段的高并发



### 悲观锁

认为所有操作都会修改数据库的数据 重量级锁全锁定读写

mysql想使用悲观锁得 set autocommit=0;

然后sql语句得写成这样

```sql
# step1: 查出商品状态
select quantity from items where id=100 for update;
# step2: 根据商品信息生成订单
insert into orders(id,item_id) values(null,100);
# step3: 修改商品的库存
update Items set quantity=quantity-2 where id=100;
```

这个for update 是mysql使用悲观锁的方式 其他事务得等到该事务提交之后才能使用

这个锁的是扫描过的所有字段 如果不加索引 相当于全表锁,



