# 多线程

---

[TOC]



## 文档使用说明

---

写于2020 java的多线程机制相对复杂 前提是了解JVM的机构和操作

本文档从内存说起 多线程涉及线程安全问题 内存屏障等机制的存在也是为了解决多线程问题

java的多线程内容十分庞大从原理到理解到实现到应用学习曲线都是非常不稳定的,因此拆分成以下部分

-   java线程的基础认识,分析手段(线程状态,创建和使用,jstack日志,JOL包)
-   多线程的重要特性(原子性,可见性,重排序)
-   jvm多线程实现基础 (CPU三级缓存,内存屏障,缓存行,CPU乱序执行,sychronized的实现,volidate的实现,字节码执行)
-   锁的分类和理解实现 (乐观锁/悲观锁,独享锁/共享锁,互斥锁/读写锁,可重入锁,公平锁/非公平锁,分段锁,偏向锁/轻量级锁/重量级锁,自旋锁,分布式锁)
-   多线程的底层机制 (CAS,AQS,锁的升级过程)
-   实现多线程的应用 (java.util.concurrent,hashmap等数据结构,线程池,DCL单例,读写模式)



## *jvm与内存结构

此章主要讲jvm的内存结构以及一些机制,如果不熟悉jvm的话在jvm的学习结束之前不要学习多线程原理相关的知识,分析多线程堆栈锁结构的时候会有相应的阻碍,本章已经在另一jvm文档详细说明了

### JVM普通内存结构

---

#### jvm内存结构

**heap 用于存放process级别数据** class内的变量等 new 出来的变量等 数组等

这一区域在jdk1.8前后发生了很大的变化谨慎起见下面的结构都是1.8以前的

**stack 存放thread/function级别数据** 局部变量操作数栈动态链接方法出口

-   vm stack虚拟机栈 线程私有,即对应thread级别的数据,一个线程的局部变量等
-   local method 本地方法栈 顾名思义是临时的方法调用所使用的栈

**方法区 process级数据** 常量池 static变量区 **类接口等加载**

**navtive 方法区 global级别数据** 被jvm环境使用 存放c++实现的方法 主要针对字节码操作

![](https://s2.ax1x.com/2019/05/26/VECQk4.png)

**pc程序计数器** 这个记载着每条指令的字节码地址,如果是本地方法则为空

更为详细的数据结构如下

![](https://img2018.cnblogs.com/blog/645365/201905/645365-20190515062344241-2072850649.png)



---

#### jdk1.7升级到1.8内存区域的变化

![](https://img-blog.csdnimg.cn/20190305150132242.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NTk4MDEx,size_16,color_FFFFFF,t_70)



### JMM内存模型

---

即多线程下内存模型 java memory model 我们要研究的主体为线程堆栈(thread stack)

#### 线程栈 Thread Stack

线程栈对于其他线程是不可见的,包含了线程的局部变量等

进程的栈和线程的栈也是不互通的 只有堆中的局部变量能够进行互相访问

而且堆中的内存都是拷贝的线程的栈中才能进行使用的

![JMM内存结构示意图](https://upload-images.jianshu.io/upload_images/15168036-12ead20bc89a8e9b.png)

**如果有对JVM的具体认识的话,上述图可以表达为方法区(元空间)和堆内存线程间共享,对于其他每个线程而言其有独立的stack**

-   方法区一般是常量池,static变量,和类的元信息(还有ClassLoader)
-   堆是需要new出来的对象

### 对象结构与锁

从jvm中我们知道锁的实现和对象的内存结构有关系

![](https://img-blog.csdnimg.cn/20190115141050902.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NDRE5fQ1A=,size_16,color_FFFFFF,t_70)

而markword是线程中控制锁的区域,markword各位置表达的意思如下

![](https://img-blog.csdnimg.cn/20190111092408622.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdWR1bl9jb29s,size_16,color_FFFFFF,t_70)

markword涉及到锁的升级过程,上面偏向锁`thread:54`指的是54位用于指向偏向的线程,`biased_lock`用于标志是否为偏向锁,`epoch`用于表示偏向锁的时间戳,关于markword和锁的升级过程在后续说明,此数据结构非常重要





## java 多线程基础

---

这一章讲多线程的基本操作和常识性的问题



### 线程安全问题

要保证线程安全就要考虑以下3个特性,这三个问题就是多线程最重要的特点

1.  原子性 在java中主要是锁机制 可以用原语或其他机制实现
2.  可见性 final volatile **内存屏障** **脏读问题** 
3.  有序性 **happen-before原则** **重排序**

 

### 常用线程安全集合

collections中的数据结构例如hashtable vector之类的是线程安全的,但是其实现的时候是通过锁住操作来完成的,效率低下,而concurrent包中的线程对此进行了改进,故优先使用,以下是我们平时会用到的一些数据结构

| interface | non-thread-safe         | concurrent-thread-safe                   | collections-thread-safe |
| --------- | ----------------------- | ---------------------------------------- | ----------------------- |
| List      | ArrayList               | CopyOnWriteArrayList                     | Vector(弃用)            |
| Map       | HashMap                 | ConcurrentHashMap                        | HashTable(弃用)         |
| Set       | HashSet / TreeSet       | CopyOnWriteArraySet                      |                         |
| Queue     | ArrayDeque / LinkedList | ArrayBlockingQueue / LinkedBlockingQueue |                         |
| Deque     | ArrayDeque / LinkedList | LinkedBlockingDeque                      |                         |



### 创建线程

```java
new Thread(()->{System.out.print(Thread.currentThread().getName())}).start();
```

-   线程对象

    线程对象我们相当于声明了一个对象,在调用`start()`方法之前系统只是在堆中创建了这么一个相应的数据结构(在方法区和堆中有相应的数据结构),而执行还得交由系统fork

-   线程

    和操作系统线程一致,为运行中的程序拥有`PCB`接受CPU调度

#### 继承Thread类

```java
class MyThread extends Thread{
  @Override
  public void run() {
    System.out.println("hello Thread");
  }
}
@Test
public void test(){
  new MyThread().start();
}
```

#### 实现Runnable接口

```java
class MyThread2 implements Runnable {
  @Override
  public void run() {
    System.out.println("hello Thread 2");
  }
}

@Test
public void test() {
  new Thread(new MyThread2()).start(); // 这方法有点扑街
}
```

#### Executors.线程池的execute和submit

```java
ScheduledExecutorService service = Executors.newScheduledThreadPool(4);
for (int i = 0; i < 200; i++) {
  service.submit(() -> {
    System.out.println("hello " + Thread.currentThread().getName());
  });
}
```

#### 关于Runnable和Callable

两者都是用于实现任务的接口 不同的是Runnable接口为没有返回值的接口 对应线程池中的execute方法 而Callable是有返回值的方法 通过拿到future对象可以获取返回值

#### 总结

可以看到创建线程是比较简单的,本质上都是借助了Thread的run方法,在堆内存和方法区中声明了相应的内存区域



### 线程的分析手段

线程的分析手段可以作为学习多线程的一个手段或者工具来了解线程的状态,我们这里介绍两种常见的手段

##### jstack

在jvm的调试中 `jstack <pid>`配合`jps`使用可以调试线程,是启动了个JUnit和线程池的测试程序,我们来分析下有用的片段

```java
public class createThread {
    @Test
    public void test() throws Exception{
        ScheduledExecutorService service = 
          Executors.newScheduledThreadPool(4);
        for (int i = 0; i < 200; i++) {
            service.submit(() -> {
                System.out.println("hello " + 
                                   Thread.currentThread().getName());
            });
        }
    }
}
```

我们利用jps和jstack找到相应的`<pid>`就可以分析日志了

```shell
"pool-1-thread-1" #11 prio=5 os_prio=31 tid=0x00007f82400c9800 nid=0x5903 waiting on condition [0x0000700008b56000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x000000076b33ee60> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
```

为了找寻这些对象我们看到下放的调用栈就可以知道对象`<0x000000076b33ee60>`

可能还需要用到`jmap -dump:live,format=b,file=dump.bin`和`jhat`来找到分析对象的内存状态

这个命令在服务器上debug一些线程的状态特别好用

##### VisualVM

这是一种简单的工具让我们来分析多线程的走向,其能看到线程的状态对象的情况,学习期间可以采用debug一步步分析线程在这中的进行和线程状态,图形化界面比较简单不再赘述

##### *idea debugger

idea的debugger是个相当好用的工具,无论是普通的debug还是多线程的debug



##### JOL包





### 线程的状态

---

![线程状态](https://img-blog.csdn.net/2018070117435683?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BhbmdlMTk5MQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

-   正在执行(Running) # 系统I/O属于正在执行状态(BIO)
-   就绪(Ready) # yield() 系统调度
-   不同的阻塞 
    -   阻塞(Blocked) # 等待进入synchronized
    -   等待(Waiting) # wait() **join()** LockSupport.park()
    -   超时等待(Timed_waiting) # wait() sleep() join() parkUntil() parkNanos()
-   新建(New)
-   终止(Terminate)

下列代码中`Thread`代表Thread类,`thread`代表Thread实例,obj同

```java
thread.start() 
// 加入jvm等待就绪队列 并不会立即执行 等待main线程执行结束之后
Thread.yield() // 让步 放入就绪队列队尾 要慎重使用 因为有准备时间 所以实际是running一会在回到就绪队列的慎用
Thread.sleep() // Time_waiting

synchronized(this){ // 获得堆中对象
  obj.wait() 
  // 释放锁对象 可传入参数 在参数的时间结束后开始等待
  // 可带参数 100 意味着100ms之后可以被notify
  // 当前线程释放该对象的锁,与该线程持有的其他对象无关
	// 随后该线程进入等待队列或者同步队列(看有无在次获取锁)
  obj.notify() 
  obj.notifyAll() // 唤醒所有想持有该对象的线程(同步队列的所有线程)
}
```

wait()的执行原理如下

![](https://img-blog.csdn.net/20180701221233161?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BhbmdlMTk5MQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

我们可以看到wait与当前线程有关和调用wait的对象有关,其实现为上图的等待队列和同步队列,配合后文中synchronized关键字获得的对象的锁,可以分析其代码所要完成的东西

```java
int i = 0; // 堆区共享数据 mutex
public void fun1(){
  synchronized(this){ // 获得当前对象的锁(使用权)
    if(i==0){
      // 操作1
    }
    i = 1;
    this.notifyAll(); 
    // 通知其他持有该对象锁(使用权)的线程(同步队列的所有线程)可以使用该对象了
  }
  // 释放了对象的锁
}
public void fun2(){
  synchronized(this){
    if(i!=0){
    	this.wait(); // 该线程等待其他线程使用 释放锁(使用权)
    }
  }
}
```

```java
otherThread.join()
// 当前线程调用其他线程实例的join(),当前线程进入waiting状态,而不是该对象的线程waiting
// 下方的wait的思路是这个join()的核心,平常我们可以认为是当前线程的一个让权函数
// join()方法原本的含义是等待otherThread执行完毕在执行接下来的代码
// join(1000) 表示等待其他线程执行1s后并发执行接下来的代码
  public final synchronized void join(long millis) throws InterruptedException{
  long base = System.currentTimeMillis();
  long now = 0;

  if (millis < 0) {
    throw new IllegalArgumentException("timeout value is negative");
  }

  if (millis == 0) {
    while (isAlive()) { // 如果(t1.join()的t1)线程还活着的话
      wait(0); 
			// 直接使用wait在同步代码块里,而同步的普通方法锁的是当前线程的实例对象
      // wait方法是当前线程释放持有的线程的实例对象
      // 当该方法被调用的时候当前线程(比如main),先获得实例的锁,然后在释放实例的锁
      // 随后进入等待队列或同步队列(看是否在次获取锁)
    }
  } else {
    while (isAlive()) {
      long delay = millis - now;
      if (delay <= 0) {
        break;
      }
      wait(delay);// 当前线程释放锁,其他线程(t1.join()的t1线程)获得锁和cpu使用权
      now = System.currentTimeMillis() - base;
    }
  }
}
```

### 线程的执行逻辑

线程的执行逻辑和操作系统一致,有等待队列有CPU时间片使用权等等,对java而言main函数本质上就是一个线程 而非进程,进程可视作jvm管理资源

每个线程执行之后会释放自己所持有的锁 同时this.notifyAll() 此处this指代线程对象

也就是说,释放本线程对象的锁(释放资源) 其他线程如果有等待该线程则会被notifyAll通知到

### ***synchronized关键字***

---

synchronized 关键字时java多线程中比较重要的东西 其可以实现原子性和可见性 可用于代替下面的volatile关键字

synchronized 保证代码块或者方法在运行时 同一时刻**只有一个对象(不是一个线程)可以进入到临界区**，同时它还可以保证共享变量的内存可见性

我们说的加了线程获取了对象的锁(使用权) 持有该对象的其他线程必须等待,synchronized关键字只是把对象的锁注入进了当前线程中仅此而已

1.  ### 普通同步方法（实例方法），锁是当前实例对象 ，进入同步代码前要获得当前实例的锁

2.  ### 静态同步方法，锁是当前类的class对象 ，进入同步代码前要获得当前类对象的锁

3.  ### 同步方法块，锁是括号里面的对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁

从上面三条性质不难看出实例方法由实例(堆)调用,要获得实例的锁,而静态方法由实例和类名调用,类名即是调用的本质,所以要获得类的对象(堆)的锁,而同步方法块是我们平时用的最多的,我们可以手动指定线程要获取堆中哪个对象的锁.

简单点来讲就是 我们想阻断i++交替访问 直接在方法上加锁就可以了

#### 普通方法加synchronized关键字

```java
public class synctest extends Thread{
    static int im = 0;

    @Override
    public synchronized void run() {
        for (int i = 0; i < 10000; ++i) {
            im++;
        }
      	System.out.println(im); 
      // 最后输出结果不是20000 但加上sync关键字后就变成了20000
      // 其原因就在于对对象加了锁 意味着只有一个对象能调用此函数
      // 我们也可以对static加锁 那就是对Class的对象加锁 一个
    }

    public static void main(String[] args) throws InterruptedException {
        synctest s1 = new synctest();
        Thread t1 = new Thread(s1);
      	Thread t2 = new Thread(s1); // 因为是普通方法所以引用得一样
        s1.start();
        s2.start();
    }
}
```

如果一个类中有两个不同的同步方法 必须等待其中一个执行完之后才能执行第二个

因为虽然说都是同一个类的不同方法但都获取了对象的锁 所以没办法实现 并发

这个就体现出该关键字设计的臃肿了 当然 也只有同步方法会要求锁 普通方法还是随意使用

**所以普通方法的关键点就是获取实例对象的锁 相同实例对象持有相同的锁 不同实例对象持有不同的锁**

#### 静态方法加synchronized关键字

```java
public static void main(String[] args) throws InterruptedException {        
  Thread t2 = new Thread(()->{
    for (int i = 0; i < 10000; i++) {
      stMethodTest.ins();
    }
  });
  Thread t1 = new Thread(()->{
    for (int i = 0; i < 10000; i++) {
      stMethodTest.ins();
    }
  });
  t1.start();
  t2.start();
  t1.join(); // 主线程进入等待/阻塞 子线程开始执行 
  t2.join(); // 主线程进入等待 子线程开始执行
  System.out.println(stMethodTest.i); 
  // 不会是20000 而加上sync关键字之后 只要是调用该(同一)类的方法(不是对象)就
  // 就会被阻塞 直到前一个类退出临界区为止
}
class stMethodTest{
    static int i=0;
    static void ins(){
        i++;
    }
}
```

可以看见 其因为持有类对象的锁所以并发性进一步减小 显得臃肿

#### 同步代码块

如果在一个大方法内执行全部同步代码显得操作及其耗时耗力 所以只用一小部分代码完成同步就可以实现并发了 基于这个思想 java有了同步代码快的机制 其可以写在方法里

```java
public void run(){
  synchronized(this){ // 作用域该对象 可以视为对普通方法进行同步
    for(int j=0;j<10000;j++){
      i++;
    }
  }
}
public void run(){
  synchronized(this.getClass()){ // 作用域该类 可以视为对静态方法进行同步
    for(int j=0;j<10000;j++){
      i++;
    }
  }
}
```

### final关键字

我们从java的基础知识中学过 final关键字用在变量和方法中的用途,其基本意思在只能赋值一次(值注入一次),而且从其特性上知道,final到引用是可改变引用的内存区域而不改变引用特性的.final类不允许继承,

在多线程中的应用也相对简单,其能一定程度保证可见性(ArrayList等引用不可保证)但是`final int x=3`等因为其已经不可变了,所以可以默认为是对所有线程可见



### volatile关键字(脏读问题)

其本质的实现保证的线程安全 主要实现的原理是 主内存(进程堆中的值立刻更新) 而不是更新堆栈的值 其保证了一个变量的可见性(能够立即读取更新值),从实现上来讲其禁止了写的重排序

可以用于解决脏读问题 但不可解决原子性问题所以依然可能会发生线程安全问题

```java
public class threadstest3 extends Thread{
    /**
     * 测试volatile关键字可读性
     * */
    boolean flag = false; 
  	// 不加关键字时 死循环依然在执行 因为主线程的操作并不可见(即主线程的flag未刷新到堆中)
 		// 加了关键字之后 因为主线程的vt.flag=true;操作在内存中可见就能被vt读取到
    int i = 0;
    @Override
    public void run() {
        while (!flag) {
            i++;
          	// System.out.println(i); // 解开这行代码就会停下
          	// 我们从这里知道volatile关键字的内存屏障是在任何情况可见且禁止重排序
          	// 而不加的时候我们可以看到,读内存的内容会刷新缓存导致看不到现象
        }
    }

    public static void main(String[] args) throws Exception {
        threadstest3 vt = new threadstest3();
        vt.start();
        Thread.sleep(2000);
        vt.flag = true;
        System.out.println("stop at " + vt.i);
    }
}
```

而保证了可见性并不代表是线程安全的 如下就是一个例子 如果操作不是原子性线程依然不安全

```java
package com.test.sync;

public class threadstest2 {
    /**
     * 证明了volatile破除了关键字 不一定能保证线程安全
     */

    public static void main(String[] args)throws Exception{
        TestClass tc = new TestClass();
        for (int i = 0; i < 1000; i++) {
            tc.startThread();
        }
    }
}

class TestClass {
    volatile Integer count = 0;
    // 不加关键字的时候 最后输出的结构随机
    // 加了关键字之后 依然没有能够完全按照我们的逻辑去执行
    // 其原因就是volatile只是线程间可见 但如果操作不是原子性的话依然有可能出错

    public void startThread() throws Exception{
        new Thread(() -> {
            count++;
            System.out.println(count);
        }).start();
    }
}
```

![JMM内存结构示意图](https://upload-images.jianshu.io/upload_images/15168036-12ead20bc89a8e9b.png)

回顾JMM的结构以及代码执行时候的结果 volatile关键字的现象是比较难以看见的

那么本地内存的变量缓存是何时刷新到主内存里取得呢?

```note
In essence, releasing a lock forces a flush of all writes from working memory employed by the thread, and acquiring a lock forces a (re)load of the values of accessible fields. While lock actions provide exclusion only for the operations performed within a synchronized method or block, these memory effects are defined to cover all fields used by the thread performing the action.
```

当线程释放一个锁时会强制性的将工作内存中之前所有的写操作都刷新到主内存中去，而获取一个锁则会强制性的加载可访问到的值到线程工作内存中来.

而我们常见的System.out.println()方法是一个同步方法 所以有获得锁会刷新内存

这就给了我们一个最基本的启示 尽量使用调试器去观察变量的值 而不是打印 因为打印会刷新缓存



---

## *多线程的底层机制

### JMM的硬件实现机制

JMM是java的内存模型,以下讨论的是JMM在具体物理硬件上的实现的机制,比如内存屏障,MESI协议等,这一章理解之后可以深刻理解上述关键字的设计思想

---

#### CPU 三级缓存与内存屏障

-   CPU一般有多级缓存系统,一般为L1,L2,L3分别代表三级缓存,不同的缓存离CPU的位置不同,造价和速度也不同,L1缓存分为指令缓存和数据缓存,都在CPU内部和CPU并行运行,因为各级缓存间的访存时间周期都差距很大,和主存差距更是巨大,缓存做的是性能匹配的工作
-   缓存和内存的修改时间并不一致,造成了数据的差异性.而并非所有硬件系统的CPU都能实时可见内存中的变化,CPU要通过一些特殊指令把缓存中的数据刷新到内存中(或者是设置内存中的数据无效位),这就是所谓的内存屏障.

内存屏障除了保证CPU的可见性之外还禁止指令的重排序,硬件层次的内存屏障一般分为**Load Barrier**,**Store Barrier**,从volatile关键字中我们可以看出来读写屏障是存在的.volatile关键字的存在使得程序员可以屏蔽硬件的内存屏障的实现.

-   Load Barrier 在指令前插入读屏障,可以让高速缓存中的数据失效,强制从主内存取。
-   Store Barrier 在指令后插入写屏障,可以让写指令立即刷新到内存

如果读完了下面的MESI协议我们可以得出以下实质上的操作

-   Load Barrier **告诉CPU在执行任何的加载前,所有已经在I状态的缓存写回主存操作**
-   Store Barrier **告诉CPU在执行这之后的指令之前,应用所有已经在本CPU缓存行中的数据**

 内存屏障的作用


-  阻止屏障两侧指令重排序
-  强制把写缓冲区/高速缓存中的脏数据等写回主内存,让缓存中相应的数据失效.

在我们使用volatile关键字的时候会在该变量的读写前后加入读写屏障,保证了可见性,而即使不加的情况,如果我们在一些关键操作上进行读写,那么JVM解释器/JIT编译器优化有可能也会帮我们刷新缓存但总不如我们加上直接保证可见性来的好(如volatile关键字例子所示)

#### 缓存行 Cache line

缓存行可以理解为CPU中缓存的最小单位,现在比较常见的是64Byte的缓存行,CPU一次性从缓存中最大容量就是缓存行(与寄存器大小有关),所以L1缓存可以分为多个缓存行,如L1缓存有512B则有512/64=8个缓存行,其实我们在计算机操作系统的Cache行优先读取(如下)上能看到这个结果(因为一次性把数组的元素加入缓存行)

```c
for(int i = 0; i < n; i++) {
    for(int j = 0; j < n; j++) {
        int num;   
        arr[i][j] = num; // 写入行,每个都命中cache,时间更快
    }
}
for(int i = 0; i < n; i++) {
    for(int j = 0; j < n; j++) {
        int   num;       
        arr[j][i] = num; // 调入cache基本次次不命中,调入缓存次数过多效率下降
    }
}
```

单核与缓存与总线结构示意图

![](https://img2018.cnblogs.com/blog/941117/201809/941117-20180904124240312-612747180.png)

但是我们都知道现在cpu都是多核的,多线程的出现使得cpu架构更加复杂

多核的工作流程会引发如下问题

-   CPU0 读取一个字节,该字节和其相邻的字节以缓存行的形式读入L1缓存
-   CPU1 重复同样的工作
-   CPU0 修改缓存中的数据
-   CPU1 修改缓存中的数据

但是CPU0和CPU1的缓存都没有刷新到RAM中,导致了数据不同步(可见性问题),为此CPU设计了如下MESI协议控制访存,其实设计思路也比较简单,当某一CPU修改缓存的时候通知其他CPU该缓存的数据已经失效



#### 硬件的MESI协议

保证缓存一致性MESI协议表示了缓存行的4个状态(MESI),一般使用2bit位表示.

如下表格,需要声明的一点是下列状态都是缓存行的状态,和java的锁并无关系

| 状态              | 描述                                                         | 监听任务                                                     |
| :---------------- | ------------------------------------------------------------ | :----------------------------------------------------------- |
| M 修改 (Modified) | 该Cache line**有效**,数据被修改了,和内存中的数据**不一致**,数据**只存在于本Cache中**. | 缓存行必须时刻监听所有试图读该缓存行相对就主存的操作,这种操作必须在缓存将该缓存行**写回**主存并将状态变成S(共享)状态之前被延迟执行. |
| E 独占(Exclusive) | 该Cache line**有效**,数据和内存中的数据一致,数据**只存在于本Cache**中. | 缓存行也必须监听其它缓存读主存中该缓存行的操作,一旦有读取内存/其他缓存,该缓存行需要变成S(共享)状态. |
| S 共享 (Shared)   | 该Cache line**有效**,数据和内存中的数据一致,数据**存在于很多Cache**中. | 缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求,并将该缓存行变成无效(Invalid) |
| I 无效 (Invalid)  | 该Cache line无效                                             | 无                                                           |

下图的状态是每个CPU Core自己的缓存行的变化

![](https://images2018.cnblogs.com/blog/1195582/201805/1195582-20180503162525310-2087402052.png)

需要注意的是修改状态E的缓存不需要通过总线事务

-   local read cpu读自己的缓存
-   local write cpu写自己的缓存
-   remote read 从其他缓存读或者主存读数据到自己缓存,**需要经过总线**
-   remote write 把本地缓存的数据写到远程的缓存或内存

如上图,比如CPU的缓存行是状态M,如果CPU要读写自己的缓存不需要改变状态M,如果是remote read,即要用内存读取数据(原来数据丢弃),那么该状态会变成S,如果是remote write,即要写回内存,故状态会变更为S

关于状态E,表示该Cache line**有效**,数据和内存中的数据**一致**,数据**只存在于本Cache**中.我们不应该像java的同步锁那样去理解该状态,其更像是一个中间状态,表明缓存行已经被该core**(只被该core)**被占用了,从状态上我们看到了remote write触发的时候会变成I,即不允许写回,因为是中间状态,很可能CPU要写东西进缓存行但还没写进来,更详细的变化情况如下表

|       State       |                         触发本地读取                         |                            write                             |                         remote read                          |                         remote write                         |
| :---------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|         M         |             本地cache:M 触发cache:M 其他cache:I              |             本地cache:M 触发cache:M 其他cache:I              | 本地cache:M→E→S 触发cache:I→S 其他cache:I→S 同步主内存后修改为E独享,同步触发、其他cache后本地、触发、其他cache修改为S共享 | 本地cache:M→E→S→I 触发cache:I→S→E→M 其他cache:I→S→I 同步和读取一样,同步完成后触发cache改为M，本地、其他cache改为I |
| **E状态（独享）** |             本地cache:E 触发cache:E 其他cache:I              | 本地cache:E→M 触发cache:E→M 其他cache:I 本地cache变更为M,其他cache状态应当是I（无效） | 本地cache:E→S 触发cache:I→S 其他cache:I→S 当其他cache要读取该数据时，其他、触发、本地cache都被设置为S(共享) | 本地cache:E→S→I 触发cache:I→S→E→M 其他cache:I→S→I 当触发cache修改本地cache独享数据时时，将本地、触发、其他cache修改为S共享.然后触发cache修改为独享，其他、本地cache修改为I（无效），触发cache再修改为M |
|  **S状态(共享)**  |             本地cache:S 触发cache:S 其他cache:S              | 本地cache:S→E→M 触发cache:S→E→M 其他cache:S→I 当本地cache修改时，将本地cache修改为E,其他cache修改为I,然后再将本地cache为M状态 |             本地cache:S 触发cache:S 其他cache:S              | 本地cache:S→I 触发cache：S→E→M 其他cache:S→I 当触发cache要修改本地共享数据时，触发cache修改为E（独享）,本地、其他cache修改为I（无效）,触发cache再次修改为M(修改) |
| **I状态（无效）** | 本地cache:I→S或者I→E 触发cache:I→S或者I →E 其他cache:E、M、I→S、I 本地、触发cache将从I无效修改为S共享或者E独享，其他cache将从E、M、I 变为S或者I |  本地cache:I→S→E→M 触发cache:I→S→E→M 其他cache:M、E、S→S→I   |           既然是本cache是I，其他cache操作与它无关            |           既然是本cache是I，其他cache操作与它无关            |

一些常见的CPU行为如下

##### 两个core读cpu内存

![](https://images2018.cnblogs.com/blog/1195582/201805/1195582-20180503162619534-683579600.png)

CPU A发出了一条指令，从主内存中读取x。
CPU A从主内存通过bus读取到 cache a中并将该cache line 设置为E状态。
CPU B发出了一条指令，从主内存中读取x。
CPU B试图从主内存中读取x时，CPU A检测到了地址冲突。这时CPU A对相关数据做出响应。此时x 存储于cache a和cache b中，x在chche a和cache b中都被设置为S状态(共享)。

##### 修改数据

![](https://images2018.cnblogs.com/blog/1195582/201805/1195582-20180503162633779-1465275811.png)

CPU A 计算完成后发指令需要修改x.
CPU A 将x设置为M状态（修改）并通知缓存了x的CPU B, CPU B将本地cache b中的x设置为I状态(无效)
CPU A 对x进行赋值。

##### 同步数据

从这里可以看到两个线程发生变量同步的时间在读或者写的瞬间

![](https://images2018.cnblogs.com/blog/1195582/201805/1195582-20180503162644640-382839091.png)

CPU B 发出了要读取x的指令。
CPU B 通知CPU A,CPU A将修改后的数据同步到主内存时cache a 修改为E（独享）
CPU A同步CPU B的x,将cache a和同步后cache b中的x设置为S状态（共享）

---

引入MESI协议之后,内存的数据一致性得到了保证,但状态切换也是需要时间的,CPU会一致等待缓存状态更新,造成少量性能下降

对MESI的优化在操作系统中也有提到过就是**延迟写回**,即其他线程对此缓存行中的数据由读写需求的时候才会花大开销写回内存,该种机制称为**Store Bufferes**,而在多线程中,写回的时间是无法保证的,比如

```java
value = 3；
void exeToCPUA(){
  value = 10;
  isFinsh = true;
}
void exeToCPUB(){
  if(isFinsh){
    assert value == 10;
  }
}
```

而影响`assert`结果的一个重要的东西就是重排序,即所见指令非CPU执行指令



#### 重排序 reordings

重排序是多线程中最难的点,重排序可能发生在编译期,运行时,JIT即时优化上.

所谓的重排序是编译器或解释器能在不改变语义的前提下把某些操作的顺序改变用来提高效率.这种重排序导致的问题就是如果优化的语句排到了后边(比如写操作)那么该操作对其他线程而言是不可见的.重排序不只是会移动到后面,也可能移动到前面.

此节点关联着`happen-before原则`但因为多线程的学习目的不是为了设计重排序,所以这里只是把机制说明,我们只要清楚内存屏障和锁能有效的阻止重排序防止多线程的歧义

-   编译优化重排序 编译器在不改变单线程程序语义的前提下,可以重新安排语句的执行顺序
-   指令并行重排序 现代处理器采用了指令级并行技术来将多条指令重叠执行.如果不存在数据依赖性,处理器可以改变语句对应机器指令的执行顺序
-   内存系统重排序 由于处理器使用缓存和读/写缓冲区,这使得加载和存储操作看上去可能是在乱序执行的

按照程序员的逻辑,代码的先后发生,拥有以下特性是不能被重排序的

-   数据依赖性 `a=3;b=4;c=a+b;`c需要依赖`a=3`和`b=4`的执行才能执行
-   控制依赖性 由`if`相关的代码,需要执行判断条件才能往下执行
-   



### 初始化`<clinit>`和`<init>`方法的线程安全问题

先说结论`<clinit>`方法是线程安全的`<init>`方法是线程不安全的

`<clinit>`是类的初始化方法,jvm会去收集static字段和static代码块进行执行和注入,因为其存储区域都在方法区,所以所有该类的实例共用,**jvm的规范中要对其初始化的类的Class的实例进行加锁**,所以该方法是线程安全的

`<init>`方法是实例的初始化方法,而new一个类时在堆区分配内存不存在竞争现象,故不需要加锁.

这个机制告诉了我们我们可以使用类的静态初始化当成加锁使用 比如如下代码其功能上等同

```java
private static class LazySomethingHolder {
  public static Something something = new Something();
}

public static Something getInstance() {
  return LazySomethingHolder.something;
}
// 等价于下面代码
public static synchronized Something getInstance(){
  return new Something();
}
// 等价于下面代码
public static Something getInstance(){
  synchronized(this.getClass()){
  	return new Something();
  }
}
```



### synchronized锁的升级过程

![](https://upload-images.jianshu.io/upload_images/10006199-318ad80ccb29abe4.png)





### CAS原子性保证

CAS Compare and Swap 又称自旋锁

CAS的伪代码实现如下

```
void CAS(memoryAddress,func){
  a = getValueFromMemory(memoryAddress);
  // compute a by function and cost time
  b = func(a)
  if(a == getValueFromMemory(memoryAddress)){
    // if
    setMemory(memoryAddress,b)
  }else{
    // do nothing
  }
}
```

这个循环的运行结果只有一种情况 其思想相当简单 如果旧数据被改那么我重新再执行一遍计算 如果没被改 我就能把计算的值放到里面去 由于CAS 只用执行一条CPU指令所以其为原子性操作(当然也有很特殊的情况默认为是原子性)

其是一种无锁算法

三个参数内存值V 旧的期望值A 新的期望值B 当A=V时 把V修改为B 否则什么也不做

### AQS 队列同步器

### volatile关键字的实现



### synchronized关键字的实现原理

monitorenter和monitorexit指令是synchronized关键字实现的重要算法



## 锁

---

### 锁的本质



说是锁其实理解为某一对象的使用权更加合适 我们从上面代码中已经看出来 锁就是一个对象的使用权 synchronized关键字配合wait notify一起使用 可以完成对象制约线程

java.util.concurrent 是一个解决线程安全问题的包 里面是一些并发操作并提供了Lock接口供显示锁的使用

### 锁的分类

### 锁的升级过程



### 独占锁synchronized

前面锁讲的synchronized就是一种独占锁 加锁和解锁的过程都需要 其实一种隐式锁

### 可重入锁ReentrantLock

其可以实现公平锁机制, 即哪个线程等待越长 优先相应等待久的线程

```java
Lock lock = new ReentrantLock(); // 传入true就行
lock.lock(); // 加锁
try{
    //临界区......
}finally{
    lock.unlock(); // 解锁
}
```

重入锁是可以对一个线程加多次锁,但是相应的也要解锁多次

### 通知机制Condition

synchronized 和wait,notify可以实现通知线程的机制

ReentrantLock和Condition可实现一样的机制

```java
class TaskQueue {
    private final Lock lock = new ReentrantLock();
    private final Condition condition = lock.newCondition();
    private Queue<String> queue = new LinkedList<>();
    public void addTask(String s) {
        lock.lock();
        try {
            queue.add(s);
            condition.signalAll();
        } finally {
            lock.unlock();
        }
    }
    public String getTask() {
        lock.lock();
        try {
            while (queue.isEmpty()) {
                condition.await();
            }
            return queue.remove();
        } finally {
            lock.unlock();
        }
    }
}
// 除此之外await还有如下形式 1s 之后没人通知自己醒来
condition.await(1, TimeUnit.SECOND);
```

### 读写锁(悲观锁) ReadWriteLock

就是为了解决读者写者问题的 允许一个线程写 多个线程读 且读写分离 即只能读或者写

```java
public class Counter {
    private final ReadWriteLock rwlock = new ReentrantReadWriteLock();
    private final Lock rlock = rwlock.readLock();
    private final Lock wlock = rwlock.writeLock();
    private int[] counts = new int[10];
    public void inc(int index) { // 写操作
        wlock.lock(); // 加写锁
        try {
            counts[index] += 1;
        } finally {
            wlock.unlock(); // 释放写锁
        }
    }
    public int[] get() { // 读操作
        rlock.lock(); // 加读锁
        try {
            return Arrays.copyOf(counts, counts.length);
        } finally {
            rlock.unlock(); // 释放读锁
        }
    }
```

### 读写锁(乐观锁) StampedLock

相比于悲观锁 其默认为为读的时候大概率不会有写入 所以我们需要判定有没有写入的线程在读

或者直接实现CAS机制用于线程间的同步

```java
public class Point {
    private final StampedLock stampedLock = new StampedLock();
    private double x;
    private double y;
    public void move(double deltaX, double deltaY) {
        long stamp = stampedLock.writeLock(); // 获取写锁
        try {
            x += deltaX;
            y += deltaY;
        } finally {
            stampedLock.unlockWrite(stamp); // 释放写锁
        }
    }
    public double distanceFromOrigin() {
        long stamp = stampedLock.tryOptimisticRead(); // 获得一个乐观读锁
        // 注意下面两行代码不是原子操作
        // 假设x,y = (100,200)
        double currentX = x;
        // 此处已读取到x=100，但x,y可能被写线程修改为(300,400)
        double currentY = y;
        // 此处已读取到y，如果没有写入，读取是正确的(100,200)
        // 如果有写入，读取是错误的(100,400)
        if (!stampedLock.validate(stamp)) { // 检查乐观读锁后是否有其他写锁发生
            stamp = stampedLock.readLock(); // 获取一个悲观读锁
            try {
                currentX = x;
                currentY = y;
            } finally {
                stampedLock.unlockRead(stamp); // 释放悲观读锁
            }
        }
        return Math.sqrt(currentX * currentX + currentY * currentY);
    }
}
```



## ***线程池***

---

我们平时自己写线程的时候可能会造成不必要的开销,为了监控负载,更合理的调用资源,更重要的是我们平时自己写的`new Thread(()->{})`会被垃圾回收

线程池有以下特点

1.  复用线程 控制最大并发数
2.  实现任务线程队列缓存策略和拒绝机制
3.  实现某些与时间相关的功能
4.  隔离线程环境

其优点在于

**降低资源消耗,提高响应速度,提高线程的可管理性**

其设计示意图如下

![设计示意图](https://images2018.cnblogs.com/blog/1425453/201807/1425453-20180729173817132-1865329285.jpg)

### 构造ThreadPoolExecutor

该类的和新方法是execute和addWorker

这个类是构造线程池用的,其间接继承了Excutor这个类,直接继承AbstractExcutorService

然后自定义**ThreadFactory**和**RejectedExecutionHandler**,其构造函数如下

```java
public ThreadPoolExecutor(int corePoolSize, // 核心(常驻)线程数
                          int maximumPoolSize, // 最大线程数
                          long keepAliveTime, // 线程失活时间
                          TimeUnit unit, // 线程失活单位
                          BlockingQueue<Runnable> workQueue, // 阻塞队列
                          ThreadFactory threadFactory, // 线程工厂
                          RejectedExecutionHandler handler) {
  if (corePoolSize < 0 ||
      maximumPoolSize <= 0 ||
      maximumPoolSize < corePoolSize ||
      keepAliveTime < 0)
    throw new IllegalArgumentException();
  if (workQueue == null || threadFactory == null || handler == null)
    throw new NullPointerException();
  this.acc = System.getSecurityManager() == null ?
    null :
  AccessController.getContext();
  this.corePoolSize = corePoolSize;
  this.maximumPoolSize = maximumPoolSize;
  this.workQueue = workQueue;
  this.keepAliveTime = unit.toNanos(keepAliveTime);
  this.threadFactory = threadFactory;
  this.handler = handler;
}
```

#### corePoolSize

核心线程数 如果为0则 则任务执行完之后 线程池关闭

如果不为0 则在执行完任务之后也不会销毁

过大会浪费资源 过小会频繁创建线程和加大资源开销

#### maximumPoolSize

最大并发数

#### keepAliveTime

空闲时间达到了keepAliveTime时,线程会被销毁 直到剩下corePoolSize为止

当线程池中线程数大于corePoolSize的时候keepAliveTime才起作用

也就是说 线程数常驻内存的只有corePoolSize个线程 其他的都有失活时间

#### unit

时间单位,通常是TimeUnit.SECONDS

#### workQueue

缓冲队列 像BlockingQueue和LinkedBlockingQueue,如果线程请求数大于maximumPoolSize则会进入缓冲队列进行阻塞,另外上面两个队列的入队和出队操作由锁机制保证了原子性

看类型参数里面是Runnable 如果是Callable需要加入到缓冲队列 会转换成Runnable类型

#### ***threadFactory***

它用来生产一组相同任务的线程,

#### handler

当workQueue的缓存区达到了上限的时候 我们可以拒绝线程的请求

这是一种简单的限流保护 这是请求的处理器

友好的拒绝策略如下

1.  保存到数据库进行削峰填谷;在空闲时再提取出来执行
2.  转向某个提示页面
3.  打印日志

默认策略是 AbortPolicy 则是对其任务直接抛弃并抛出异常

CallerRunsPolicy:只用提交任务所在线程来运行任务,有反馈机制,使任务提交的速度变慢

DiscardOldestPolicy:若没有发生shutdown,尝试丢弃队列里最近的一个任务,并执行当前任务, 丢弃任务缓存队列中最老的任务，并且尝试重新提交新的任务

DiscardPolicy:不处理,丢弃掉,拒绝执行,不抛异常

自定义拒绝策略可以通过实现RejectedExecutionHandler实现reject(),例如日志持久化

### 简单使用

```java
ExecutorService service = new ThreadPoolExecutor(8, 16, 8, TimeUnit.SECONDS, new LinkedBlockingQueue<>());
```

我们可以通过execcute方法或者submit方法向线程池提交任务,其后面的代码把其封装成一个Worker加入到Workers里面去 Worker是对线程的封装,线程池内部使用一个Set存储worker不会使得worker重复 `HashSet<Worker> workers=new HashSet<>();`

线程会重阻塞队列workQueue中poll()取出任务放到核心线程中去执行

#### execute 方法

该方法没有返回值所以无法确定有没有执行成功

```java
service.execute(new Runnable() {
  public void run() {
    System.out.println("提交任务");
  }
});
```

其内部是如果核心线程空闲addIfUnderCorePollSize

#### submit方法

该方法针对的是Callable对象

```java
Future<Integer> future = service.submit(new Callable<Integer>() {
  @Override
  public Integer call() throws Exception {
    System.out.println("submit方式");
    return 2;
  }
});
try {
  Integer number = future.get();
} catch (ExecutionException e) {
  // TODO Auto-generated catch block
  e.printStackTrace();
}
```

#### Future/FutureTask类的使用

```java
// 原生使用
// 我们假设这个线程要返回一个integer
Callable<Integer> thread = new Callable<Integer>() {
  @Override
  public Integer call() throws Exception {
    System.out.println(Thread.currentThread().getName() + " execute");
    return 3;
  }
};
// FutureTask 实现了 Future接口
Future<Integer> ft = new FutureTask<>(thread);
new Thread(ft).start();
long start = System.currentTimeMillis();
// 卡着 等虚拟机调度
while (!ft.isDone()) { // 可以用while(ft.isDone()){} 等待线程执行结束
  System.out.println("线程没执行结束 等着");
}
// ft.get(); // 这句话也可以直接阻塞等待线程执行结束
long end = System.currentTimeMillis();
Integer i = ft.get(); // 获取返回值
System.out.println(i + "系统调度用时" + (end - start) + "ms");
```

#### shutdown方法

.shutdown(); .shutdownNow(); // 两个方法上用于关闭线程池

shutdown(); // 线程不能接受新的任务 会等待当前线程执行结束

shutdownNow(); // 线程不能接受新的任务并且尝试终止现在的任务

#### 线程池运行状态监测

```java
pool.getPoolSize();
pool.getQueue().size(); // 等待队列的线程数目
pool.getCompletedTaskCount() // 已经完成的线程数
```

#### 线程池状态

线程池状态是线程池处于何种阶段的内部描述volatile runState

RUNNING,SHUTDOWN,STOP,TERMINATED

SHUTDOWN:调用shutdown后,线程池不能接受新任务,等待线程执行完成

STOP:调用shutdownNow后,线程池不能接受新任务,并尝试销毁其他任务

TERMINATED:当工作线程已经销毁,任务缓冲队列清空或执行结束之后

**队列、线程工厂、拒绝处理服务**都必须有实例对象,但编程中我们很少亲自实例化对象

```java
ExecutorService service = new ThreadPoolExecutor(8, 16, 8, TimeUnit.SECONDS, new LinkedBlockingQueue<>());
```

这样子的代码 java内部配置了许多已经实现好的的线程池类

### *线程池的实现类

#### 固定线程池newFixedThreadPool

#### 缓存线程池newCachedThreadPool

#### 定时调度线程池newScheduledThreadPool

#### 单线程池newSingleThreadExecutor

```java
Executors.newFixedThreadPool(4); 
// 指定核心线程数和最大并发数为4 失活时间默认为0
// 此时失活时间无意义
// 也就是说不会开辟新的线程去执行任务,一共就4个线程自己轮询执行任务
Executors.newCachedThreadPool();
// 核心线程数为0 最大并发数为Integer.MAX_VALUE 失活时间为60秒
// 而且没有缓冲(阻塞)队列 也就是说以缓存形式执行线程 不会加入队列
// 现有线程池无法接收任务时,会创建新的线程去接受执行任务
Executors.newScheduledThreadPool(4); 
// 指定核心线程数为4 最大并发数为Integer.MAX_VALUE 失活时间为0
// 失活时间为0意味着额外的线程一旦执行结束就立刻被回收

ScheduledExecutorService service = Executors.newScheduledThreadPool(4);
service.schedule(new Runnable() {
  public void run() {
    System.out.println(Thread.currentThread().getName()+"延迟三秒执行");
  }
}, 3, TimeUnit.SECONDS); // 延迟3秒
service.scheduleAtFixedRate(new Runnable() {
  public void run() {
    System.out.println(Thread.currentThread().getName()+"延迟三秒后每隔2秒执行");
  }
}, 3, 2, TimeUnit.SECONDS);

Executors.newSingleThreadExecutor();
// 核心线程和最大并发数都是1 失活时间为0
// 意味着所有该线程池执行的线程每次只有1个线程在运行 其他线程在等待
// 就是单线程模式 不会存在线程同步问题
```

### Executor接口

这是线程池继承链顶端的接口 如下

![线程池的继承链](https://uploadfiles.nowcoder.com/files/20190118/7380095_1547784444679_4685968-eaaaf8fd88497757.png)

### 分布式计算相关

#### map-reduce核心方法的实现

```java
package com.test.sync;
import javafx.util.Pair;
import java.util.*;
import java.util.concurrent.*;
import java.util.function.BiFunction;
import java.util.function.Function;
public class _MapReduce {
    // 任务队列
    static List<Callable> mapTaskList = null;
    // 任务队列
    static List<Callable> reduceTaskList = null;
    // map结果集
    static List<Future> mapResultSet = null;
    // reduce结果集
    static List<Future> reduceResultSet = null;

    static ExecutorService mapPool = Executors.newCachedThreadPool();
    static ExecutorService reducePool = Executors.newCachedThreadPool();
    // 这里的线程池没有进行好的配置 只是为了说明测试的效果

    public static void main(String[] args) throws Exception {
        // init tasklist and resultset
        initComputeEnvironment();
        try {
            // 简单的计算
            _map(new Integer[]{1, 2, 3}, (i) -> {
                return i * 2;
            });
            printMapResultSet();
            clearList(mapResultSet);

            // 简单的单词分割任务
            _map(new String[]{"hi hello", "world wolf", "pig"}, (str) -> {
                return Arrays.asList(str.split(" "));
            });
            printMapResultSet();
            clearList(mapResultSet);

            Integer result = _reduce(new Integer[]{1, 3, 5, 7, 9}, (x, y) -> {
                return x * y;
            });
            System.out.println("reduce output:" + result);

            String _result = _reduce(new String[]{"1", "2", "3", "4", "5"}, (str1, str2) -> {
                return str1 + str2;
            });
            System.out.println("reduce output:" + _result);
        } finally {
            clearComputeEnvironment();
        }
    }

    public static List getResultSet(List<Future> resultSet) throws ExecutionException, InterruptedException {
        List ls = new ArrayList<>();
        for (Future f : resultSet) {
            ls.add(f.get());
        }
        return ls;
    }

    public static void printMapResultSet() throws ExecutionException, InterruptedException {
        System.out.print("map result:");
        for (Future f : mapResultSet) {
            System.out.print(f.get() + " ");
        }
        System.out.println();
    }

    public static void printReduceResultSet() throws ExecutionException, InterruptedException {
        System.out.print("after reduce:");
        long start = System.currentTimeMillis();
        for (Future f : reduceResultSet) {
            System.out.print(f.get() + " ");
        }
        System.out.println(System.currentTimeMillis() - start + "ms for execute");
    }

    public static void clearList(List ls) {
        ls.clear();
    }

    public static void initComputeEnvironment() {
        /**
         * 任务队列 CopyOnWriteArrayList
         */
        mapTaskList = new CopyOnWriteArrayList<>();
        mapResultSet = new CopyOnWriteArrayList<>();
        reduceTaskList = new CopyOnWriteArrayList<>();
        reduceResultSet = new CopyOnWriteArrayList<>();
    }

    public static void clearComputeEnvironment() {
        /**
         * 清空任务队列
         */
        mapTaskList.clear();
        mapResultSet.clear();
        reduceTaskList.clear();
        reduceResultSet.clear();
    }

    public static <I, O> void _map(I[] datas, Function<I, O> func) throws ExecutionException, InterruptedException {
        /**
         * 加入任务队列
         * 执行队列任务
         */
        add2TaskList(datas, func, mapTaskList);
        submitTask(mapTaskList, mapResultSet);
    }

    public static <I, O> I _reduce(I[] datas, BiFunction<I, I, O> func) throws ExecutionException, InterruptedException {
        /**
         * 加入任务队列
         */
        I[] ls = reduceTasks(datas, func);
        return ls[0];
    }

    // //
    public static <I, O> I[] reduceTasks(I[] datas, BiFunction<I, I, O> func) throws ExecutionException, InterruptedException {
        System.out.println("reduce debug: " + Arrays.asList(datas) + " length:" + datas.length);
        if (datas.length > 1) {
            boolean isOdd = false;
            if (datas.length % 2 != 0) { // 奇数个的时候进行特殊处理
                isOdd = true;
            }
            for (int i = 0; i < datas.length - 1; i += 2) {
                // 这个遍历是 奇数个的时候是没有最后一个数的 偶数个的时候是能完全遍历的
                int finalI = i;
                reduceTaskList.add(new Callable<O>() {
                    @Override
                    public O call() throws Exception {
                        return func.apply(datas[finalI], datas[finalI + 1]);
                    }
                });
            }
            submitTask(reduceTaskList, reduceResultSet); // 提交任务到线程池
            List resultList = getResultSet(reduceResultSet);
            if (isOdd) {
                resultList.add(datas[datas.length - 1]);
            }
            I[] resultSet = (I[]) resultList.toArray(); // 获得结果集
            clearList(reduceResultSet);
            clearList(reduceTaskList);
            return reduceTasks(resultSet, func);
        } else { // 等于1
            return datas;
        }
    }

    public static <I, O> void add2TaskList(I[] datas, Function<I, O> func, List<Callable> taskList) {
        for (I data : datas) {
            taskList.add(new Callable() {
                @Override
                public O call() throws Exception {
                    return func.apply(data);
                }
            });
        }
    }
    public static void submitTask(List<Callable> taskList, List<Future> resultSet) {
        /**
         * 提交任务到线程池中
         */
        if (taskList.size() < 1) {
            throw new RuntimeException("没有要执行的任务");
        } else {
            for (Callable c : taskList) {
                resultSet.add(mapPool.submit(c));
            }
        }
    }
}
```



#### ForkJoin

forkjoin是一个线程框架 如果任务足够小就进行计算 如果不够小就拆分成若干小任务进行计算

其思想和mapreduce有相像之处

***工作窃取模式***

当执行新的任务时它可以将其拆分成更小的任务执行，并将小任务加到线程队列中，当没有任务执行时，再从一个随机线程的队列中偷一个并把它放在自己的队列中.相对于一般的线程池实现 ，fork/join 框架的优势体现在对其中包含的任务的处理方式上，在一般的线程池中，如果一个线程正在执行的任务由于某些原因无法继续运行,那么该线程会处于等待状态。而在fork/join 框架实现中，如果某个子问题由于等待另外一个子问题的完成而无法继续运行。那么处理该子问题的线程会主动寻找其他尚未运行的子问题（窃取过来）来执行，这种方式减少了线程的等待时间，提高了性能

Fork对应任务分解,Join对应任务合并,下面看一个并行求和的例子

其有缺点就是 瞬间内存需要特别大 而mapreduce并不需要那么高的内存

先定义一个类 继承 RecursiveTask 或者 RecursiveAction就行 不过后者不会返回结果

```java
class SumTask extends RecursiveTask<Long> { // 这个Long指的是返回值
    static final int THRESHOLD = 500;
    long[] array;
    int start;
    int end;

    SumTask(long[] array, int start, int end) {
        this.array = array;
        this.start = start;
        this.end = end;
    }

    @Override
    protected Long compute() {
        if (end - start <= THRESHOLD) {
            // 如果任务足够小,直接计算:
            long sum = 0;
            for (int i = start; i < end; i++) {
                sum += this.array[i];
            }
            return sum;
        }
        // 任务太大,一分为二:
        int middle = (end + start) / 2;
      	// 直接调用内部类了
        SumTask subtask1 = new SumTask(this.array, start, middle);
        SumTask subtask2 = new SumTask(this.array, middle, end);
        invokeAll(subtask1, subtask2); 
      	// 这里并没有用到拆分
      	// subTask.fork() 拆分任务加入队列 默认拆分
        Long subresult1 = subtask1.join();
        Long subresult2 = subtask2.join();
        Long result = subresult1 + subresult2; // 合并结果
        return result;
    }
}
```

计算调用

```java
// 求和数组为array
// fork/join:
ForkJoinTask<Long> task = new SumTask(array, 0, array.length);
long startTime = System.currentTimeMillis();
Long result = ForkJoinPool.commonPool().invoke(task);
long endTime = System.currentTimeMillis();
System.out.println("Fork/join sum: " + result + " in " + (endTime - startTime) + " ms.");
```

## 实现基本的同步问题

生产者消费者问题和读者写者问题 一个直接映射着消息队列的设置 另一个直接关系到集群的读写分离模型设计问题 故单独作为讨论

### 生产者消费者

本质上就一个东西 生产者消费者共用一把锁就不会出现问题 要么只能生产要么只能消费

解决思路就是同一把锁一起使用就是了

```java
package com.test.sync;

import java.util.*;

public class Test {
    static Object lock = new Object();
    static int[] array = new int[10];

    static Integer count = 0;
    static {
        for (int i = 0; i < array.length; i++) {
            array[i] = -1;
            // 非法值填充
        }
    }

    public static void main(String[] args) {
        new Thread(()->{
            try {
                while(true) {
                    set();
                    Thread.sleep(90);
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();

        new Thread(()->{
            try {
                while(true) {
                    get();
                    Thread.sleep(100);
                }
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();


    }
    public static void get() throws InterruptedException {
        synchronized (lock) {
            while(count<1){
              	// 为什么这里不用if用while 是因为阻塞的时候 回来执行的时候如果是if
              	// 那么就会执行get an element操作 而while的话 回来继续判断
              	// 不符合条件在次释放锁
                lock.wait();
            }
            // get an element
            for (int i = 0; i < array.length; i++) {
                if(array[i]!=-1) {
//                    System.out.println(array[i]);
                    array[i] = -1;
                    count--;
                    break;
                }
            }
            printArray(array);
            lock.notifyAll();
        }
    }
    public static void set() throws InterruptedException {
        synchronized (lock) {
            while(count>10){
                count.wait();
            }
            // set an element
            for (int i = 0; i < array.length; i++) {
                if(array[i]==-1) {
                    array[i] = rand();
                    count++;
                    break;
                }
            }
            printArray(array);
            lock.notifyAll();
        }
    }

    public static int rand() {
        return new Random().nextInt();
    }

    public static <T>void printArray(int[] array){
        System.out.print("[");
        for (int i = 0; i < array.length;i++){
            System.out.print(array[i]+",");
        }
        System.out.println("] count:"+count);
    }
}
```

### 读者写者

1.  允许多个读者同时执行读操作。 // 读者之前没有读者锁进行制约
2.  不允许读者、写者同时操作。 // 读写之间有公用锁进行制约
3.  不允许多个写者同时操作。 // 写者锁进行制约

这个设计思路就是两者之间用一把公共锁进行制约 然后读者有自己独立的锁就行

```java
package com.test.sync;

import java.util.Random;

public class testReaderWriter {
    final static Object readerLock = new Object();
    volatile static Integer writerCount = 0;
    final static Object writerLock = new Object();

    static Integer resource = -1;

    public static void main(String[] args) throws InterruptedException {
        for (int i = 0; i < 100; i++) {
            new Thread(() -> {
                try {
                    read();
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }).start();
            new Thread(() -> {
                try {
                    write();
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }).start();
        }
        Thread.sleep(0x2b67);

    }

    /**
     * 读者写者模式规则
     * 1.  允许多个读者同时执行读操作。 // 读者之前没有读者锁进行制约
     * 2.  不允许读者、写者同时操作。 // 读写之间有公用锁进行制约
     * 3.  不允许多个写者同时操作。 // 写者锁进行制约
     **/
    public static void read() throws InterruptedException {
        synchronized (readerLock) {
            while (writerCount > 0) {
                readerLock.wait();
            }
            System.out.println(Thread.currentThread().getName() + "read resource:" + resource);
        }
    }

    public static void write() throws InterruptedException {
        synchronized (readerLock) {
            // 读写同时只能有一个进入所以 写者也要获取读者的锁
            // 有写者在等待
            synchronized (writerLock) {
                // 写者之间进行互相制约
                while (writerCount > 0) {
                    writerLock.wait();
                }
                writerCount++;
                int i=rand();
                System.out.println(Thread.currentThread().getName() + "write resource:" + i);
                resource = i;
                writerCount--;
                writerLock.notifyAll();
            }
            readerLock.notifyAll();
        }
    }

    public static int rand() {
        return new Random().nextInt();
    }
}

```

## java.util.concurrent包等工具

### ThreadLocal

ThreadLocal 为每个线程提供了一个独立的变量副本去解决线程并发冲突问题,在很多情况下,ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单,更方便,且结果程序拥有更高的并发性

static变量放到ThreadLocal类型的对象中,使变量在每个线程中都有独立拷贝,不会出现一个线程读取变量时而被另一个线程修改的现象

本质上ThreadLocal 是对Thread 的**threadLocals属性(类型为ThreadLocalMap)**进行管理

其实其作用为隔离线程之间的共享变量,为每个线程创建一个副本

ThreadLocal中的方法

```java
public T get();
public void set(T value);
public void remove(); // 清楚
protected T initialValue();
```

```java
private static final ThreadLocal<String> tl = new ThreadLocal<String> ();

public static void main(String[] args) throws InterruptedException {
  Thread t1 = new Thread(()->{
    System.out.println(tl.get());
    tl.set("444");
    System.out.println(tl.get());
  });
  Thread t2 = new Thread(()->{
    System.out.println(tl.get());
    tl.set("333");
    System.out.println(tl.get());
  });
  t1.start();
  t1.join();
  t2.start();
}
```

ThreadLoaclMap<K,V>中 K就是线程的弱引用,而V就是我们设置值得强引用

其可能存在一些内存泄漏问题 如果创建的线程是堆entry的强引用(比如static) 那么就不能被GC 长期下来就有可能导致内存泄漏

---



## 线程安全以及线程相关问题

---

###  **Servlet对象是单实例多线程，Servlet不是线程安全的**

在非分布式的系统中,Servlet是单例多线程的,而且很显然没有锁去制约之中请求关系,单例意味着servlet容器只会生成一个servlet实例,只是对于每一个请求都调用service()方法去交给一个线程处理

如何解决Servlet的线程安全问题,synchronized代码块,线程安全的数据结构HashTable,BlockQueue等

### Spring的bean是否是线程安全的

spring没有对bean进行多线程处理,但大多数情况下是无状态的(没有数据存储功能)那就不用去考虑线程安全的问题 如果是有状态 则需要去考虑Spring的线程安全问题

spring是默认单例模式 改成prototype则可以保证一定程度上的线程安全

再不成可以用ThreadLocal去保证线程安全问题



## ***有序性的happen-before原则***

---

**它真正的意思是前面的操作对后续的操作都是可见的 可见意味着结果按执行先后的顺序可以确定下来 但是执行顺序却未必如同我们意料中的那样**

**无论如何重排序程序的语义不变,即程序的执行结果是一样的**

这一章的目的只是让我们了解如何设计重排优化的,实际上为了避免产生歧义,我们一般使用**synchronized**关键字的锁技术和**volatile**的内存屏障来禁止指令重排

再来,此原则有一前提是重排序不会影响线程前后的执行顺序,如果是确定了有先后顺序的才能够使用happen-before原则,不确定顺序且跨线程之间的重排序是没有的,我们应该如此理解下面的规则,是对顺序执行的指令**即是发生重排序依然存在的先后发生关系**,而不应该理解为不确定指令执行顺序时的规则,也不能理解为这些指令不发生重排序,而应该理解为**实际效果看上去和不发生重排序一样**.

---

**happen-before是jmm维护的内存关系用于保证可见性** 

A线程的读和B线程的写如果之间存在happen-before关系那么就保证了B的写对A的读可见,也一定意味着B的写在A之前执行,但是两个操作之间存在happens-before关系,并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行.如果重排序之后的执行结果,与按happens-before关系来执行的结果一致,那么这种重排序并不非法（也就是说，JMM允许这种重排序）

### 程序的顺序性规则

​	一个线程中的每个操作，happens-before于该线程中的任意后续操作

### ***监视器锁规则***

​	对一个锁的解锁(释放锁),happens-before于随后对这个锁的加锁(获得锁).

### ***volatile变量规则***

对一个volatile域的写,happens-before于任意后续对这个volatile域的读.

### 传递性

A happens-before B,且B happens-before C,那么A happens-before C

### ***start()规则***

如果线程A执行操作ThreadB.start() (启动线程B),那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作

### ***Join()规则***

如果线程A执行操作ThreadB.join()并成功返回,那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回

### 程序中断规则

对线程interrupted()方法的调用先行于被中断线程的代码检测到中断时间的发生

### 对象finalize规则

一个对象的初始化完成（构造函数执行结束）先行于发生它的finalize()方法的开始

### 利用上面的规则通过传递性等可以确定结果,但不一定可确定执行顺序