scikit-learn
内置数据集
from sklearn.dataset import *
	load_boston
	load_breast_cancer
	load_diabetes
	load_digits
	load_files
	load_iris
	load_linnerud
	load_mlcomp
	load_sample_image
	load_sample_images
	load_svmlight_file
	load_svmlight_files
	load_wine
	#以上从dir(sklearn.dataset)中节选部分
线性模型:
	model = LinearRegression(
		fit_intercept=True,# 是否计算截距
		normalize=False, # 正则化
		copy_X=True,
		n_jobs=1 # 线程数
	)
逻辑回归模型(LR):
	from sklearn.linear_model import LogisticRegression
	# 定义逻辑回归模型
	model = LogisticRegression(
		penalty=’12’, # 使用正则化
		dual=False, # samples > features
		tol=0.0001, # 程序终止条件
		C=1.0, # 正则化系数,值越小正则化越大
	    fit_intercept=True, 
	    intercept_scaling=1, 
	    class_weight=None, 
	    random_state=None, 
	    solver=’liblinear’, 
	    max_iter=100, 
	    multi_class=’ovr’, # ovr一对多 ovo 一对一 2分类
	    verbose=0, 
	    warm_start=False, 
	    n_jobs=1
	)
SVM:
	from sklearn.svm import SVC
	model = SVC(
		C=1.0, 
		kernel=’rbf’, 
		gamma=’auto’# 核函数相关系数 auto是 1/n_features
	)
决策树:
	from sklearn import tree 
	model = tree.DecisionTreeClassifier(
		criterion=’gini’, #特征选择准则 gini/entropy
		max_depth=None, # 最大深度
	    min_samples_split=2,#分类内部节点所需要的最小样本数 
	    min_samples_leaf=1, #叶子节点需要的最小样本数
	    min_weight_fraction_leaf=0.0,
	    max_features=None, #寻找最优分割点的最大特征数 
	    random_state=None,
	    max_leaf_nodes=None, #优先增长到最大叶子节点数
	    min_impurity_decrease=0.0, #如果这种分离导致杂质的减少大于或等于这个值，则节点将被拆分。
	    min_impurity_split=None,
	    class_weight=None, 
	    presort=False
	)
knn邻近:
	from sklearn import neighbors
	#定义kNN分类模型
	model = neighbors.KNeighborsClassifier(n_neighbors=5, n_jobs=1) # 分类
	model = neighbors.KNeighborsRegressor(n_neighbors=5, n_jobs=1) # 回归
多层感知机：
	from sklearn.neural_network import MLPClassifier
	# 定义多层感知机分类算法
	model = MLPClassifier(activation='relu', solver='adam', alpha=0.0001)
	hidden_layer_size # 传tuple
#机器学习和深度学习一些交汇概念：
	单层感知机(Single Layer Perceptron):一层神经网络或者一个计算神经元
	dnn和ann 深层神经网络和人工神经网络(artificial neural networks)
	区别在于深浅 ann也叫多层感知机(MLP) 
	Multi-Layer Perceptron 属于机器学习
	dnn开始则是深度学习的研究范畴
#一个基本的例子
	from sklearn.datasets import load_boston
	from sklearn.linear_model import LinearRegression
	def boston():
	    from sklearn.datasets import load_boston
	    boston = load_boston()
	    data = boston.data
	    tgt = boston.target
	    print(data)
	    print(tgt)
	    print(data.shape, tgt.shape)
	    return data,tgt

	def train(x,y):
		model = LinearRegression()
		model.fit(x,y)
		return model

	if __name__ == '__main__':
	    x,y = boston()
	    model = train(x,y)
	    res = model.predict(x[:4,:])
	    print(res, label[:4])
	    model.coef_ # 系数
	    model.intercept_ # 截距、
	    model.get_params() # 定义的参数
	    model.score(x,y)# 打分 r^2 coefficient of determination
	线性回归的评分是r square 分类是 accuracy
preproccessing:
	from sklearn import preprocessing
	x = preprocessing.scale(x) #归一化
	x = preprocessing.minmax_scale(x,feature_range(-1,1))
	#feature_range是缩放范围 默认0,1
分割数据集:
	from sklearn.svm import SVC
	#svc用来分类 svr用来做回归
	from sklearn.cross_validation import train_test_split 
	x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.3)
	clf = SVC()
	clf.fit(x_train,y_train)
