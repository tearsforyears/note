Keras
# 配置信息:
	
基础api:
	基于tensorflow或者基于theano(停止维护)
	修改keras.json可以改变backend
	C:\Users\hasse\.keras\keras.json
	from keras.models import Sequential # 顺序
	from keras.layers import Dense # 全连接层

	# define model
	# input_dim 基本所有cnn入口需要定义的参数
	model = Sequential()
	model.add(Dense(output_dim=,input_dim=)) # 加层
	model.add(Dense(output_dim=)) # 第二层时会自动获取第一层输出
	model.compile(loss='mse',optimizer='sgd')

	# train step
	cost=model.train_on_batch(x,y) 
	# 除此之外可以用fit去快速训练 rnn 也要利用这种方式

	# test
	cost=model.evaluate(x,y,batch_size=)

	# get weight
	W,b = model.layers[0].get_weights()
# mnist predict
	from keras.utils import np_utils
	from keras.models import Sequential
	from keras.layers import Dense,Activation
	from keras.optimizers import RMSprop
	from keras.datasets import mnist

	(x,y),(x_test,y_test)=mnist.load_data()
	# pre_processing
	y = np_utils.to_categorical(y,nb_classes=10) # numpy脚本进行one-hot编码

	# define model
	model = Sequential([
		Dense(32,input_dim=784) # output_dim=32
		Activation('relu'),
		Dense(10), # out_put=32
		Activation('softmax'),
	])

	rmsprop = RMSprop(lr=0.001,...)
	model.compile(
		optimizer=rmsprop,
		loss='categorical_crossentropy',
		metrics=['accuracy'], # 同时计算其他矩阵
	)
	# train
	model.fit(x,y,epoch=2,batch_size=32) # 这界面超鸡巴cool
	loss,accuracy = model.evaluate(x_test,y_test)
# cnn
	from keras.model import Sequential
	from keras.layers import Dense,Activation,\
	Convolution2D,MaxPooling2D,Flatten # cnn 特有
	from keras.optimizers import Adam
	
	model = Sequential()
	model.add(
		Convolution2D( # strides?
			filters=32, # channels
			kernel_size=[5,5]
			padding='same',
			input_shape=(1,28,28) # c h w
		),
	)
	model.add(Activation('relu'))
	model.add(
		MaxPooling2D(
			pool_size=(2,2),
			strides=(2,2),
			padding='same'
		)
	)
	model.add(Convolution2D(64,5,5,border_model='same'))
	model.add(Activation('relu'))
	model.add(MaxPooling2D(pool_size=(2,2),border_model='same'))
	model.add(Flatten())
	model.add(Dense(1024)) # 输出
	model.add(Activation('relu'))
	model.add(Dense(10)) 
	model.add(Activation('softmax'))
# rnn:
	# 注意:
		LSTM是一层网络 LSTMCell才是一个单元
		GPU SimpleRNN 等同
	# rnn分类
		# rnn 分类用的是最后的神经元去预测,而不是利用细胞状态去预测
		# 所谓用最后神经元去预测,其实就是利用rnn最后一个神经元的输出
		# 对下面这个问题 mnist 中一行相当于一个时间步
		# 对每一个样本而言,有28行,则输入维度是28
		# 也就是说最后这个input_size可变 只是对于mnist不变而已
		# 因为没有用state 所以就相当于 dnn
		from keras.models import Sequential
		from keras.layers import SimpleRNN,Activation,Dense
		from keras.optimizer import Adam
		
		TIME_STEPS = 28
		INPUT_SIZE = 28
		BATCH_SIZE = 50
		BATCH_INDEX = 0
		CELL_SIZE = 50
		LR = 0.001
		# rnn cell define 
			# tanh as deflaut activation function
			SimpleRNN( # 也有simple rnn cell 这是 rnn layer
				batch_input_shape=(BATCH_SIZE,TIME_STEPS,INPUT_SIZE),
				output_dim=CELL_SIZE,
			)
		# output layer
			model.add(Dense(10))
			model.add(Activation("softmax"))
		for i in range(steps):
			x_batch = x[:]
			y_batch = x[:]
			# 另一种batch的计算方法
			batch_index +=batch_size
			batch_index = 0 if batch_index>=60000 else batch_index
			# 60000 源于 mnist
	# rnn回归:
		# 用cos曲线去模拟sin
		# 对LSTM_layer传递的是 state output的向上的ht
		from keras.models import Sequential
		from keras.layers import LSTM,Activation,Dense,TimeDistributed
		from keras.optimizer import Adam
		model.add(LSTM(
			batch_input_shape = (batch_size,time_step,input_size),
			output_dim=CELL_SIZE, # CELL_SIZE 
			return_sequences=True, # 默认为False
			stateful=True, # 使用状态
		))
		model.add(TimeDistributed(Dense(output_size))) # 需要实时预测数据的shape
# auto encoder
	from keras.models import Model
	from keras.layers import Dense,Input

	encoding_dim = 2
	input = Input(shape=(784,))
	
	# input layers
	encoded = Dense(128,activation='relu')(input)
	encoded = Dense(64,activation='relu')(encoded)
	encoded = Dense(16,activation='relu')(encoded)
	encoder_output = Dense(encoding_dim)(encoded)

	# decoder layers
	decoded = Dense(16,activation='relu')(encoder_output)
	decoded = Dense(64,activation='relu')(decoded)
	decoded = Dense(128,activation='relu')(decoded)
	decoder_output = Dense(784,activation='tanh')(decoded) # 注意这层函数

	# build the model
	ae_model = Model(input=input,output=decoder_output)
	encoder = Model(input=input,output=encoder_output)

	# compile
	ae_model.compile(optimizer='adam',loss='mse')
	ae_model.fit(x,y,epoch=20,batch_size=256,shuffle=True)	
# save model
	model.save('my_model.h5') # .h5保存格式
	model.load('my_model.h5')

	model.save_weights('...h5')
	model.load_weights('...h5')

	from keras.models import model_from_json
	json_string = model.to_json()
	model = model_from_json(json_string)
